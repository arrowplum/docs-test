# - name        : Name of the location
#   description : Description of the location
locations:
  - name: "Statistics"
    description: |
      Statistics is a container for overall database health and service metrics,
      which can be accessed with:
      ```
      asinfo -h <host ip> -v 'statistics' -l
      ```
      or using [asadm](/docs/tools/asadm/index.html):
      ```
      Admin> show statistics service
      ```

  - name: "Namespace"
    description: |
      Namespace contains health metrics for a particular namespace, which can be
      accessed with:
      ```
      asinfo -h <host ip> -v 'namespace/<namespace name>'
      ```
      or using [asadm](/docs/tools/asadm/index.html), for all namespaces statistics:
      ```
      Admin> show statistics namespace
      ```
      or for a specific namespace:
      ```
      Admin> show statistics namespace for <namespace name>
      ```
      **For set statistics:**
      ```
      Admin> show statistics set
      or
      asinfo -v sets
      ```
      For set statistics for a specific namespace:
      ```
      Admin> show statistics set for <namespace id>
      or 
      asinfo -v sets/<namespace name>
      ```
      For a specific set statistics for a specific namespace:
      ```
      asinfo -v sets/<namespace name>/<set name>
      ```
      **For secondary index statistics:**
      ```
      Admin> show statistics sindex
      or 
      asinfo -v sindex -l
      ```
      For secondary index statistics for a specific namespace:
      ```
      Admin> show statistics sindex for <namespace name>
      or 
      asinfo -v sindex/<namespace name> -l
      ```
      For secondary index statistics for a specific namespace for a specific secondary index (partial name OK):
      ```
      Admin> show statistics sindex for <namespace name> for <sindex name>
      or 
      asinfo -v sindex/<namespace name>/<sindex name> -l
      ```

  - name: "XDR"
    description: |
      XDR contains health and service metrics for the Cross Data center
      Replication component, which can be accessed along with the service metrics with:
      ```
      asinfo -h <host ip> -v 'statistics'
      ```
      or using [asadm](/docs/tools/asadm/index.html), for all namespaces statistics:
      ```
      Admin> show statistics xdr
      ```
      **For XDR destination statistics:**
      ```
      Admin> show statistics dc
      ```
      or for a specific XDR destination:
      ```
      asinfo -v "dc/<DC name>" -l
      ```

# - name        : Name of the category
#   description : Description of the category
categories:
  - name: "Application"
    description: |
      Application metrics are KPIs that frequently indicate in the customer's
      application.
  - name: "Memory"
    description: |
      Memory metrics are KPIs that may be used to indicate abnormal memory
      utilization.
  - name: "Network"
    description: |
      Network metrics are KPIs that may indicate problems on the network layer.
  - name: "Storage"
    description: |
      Storage metrics are KPIs that may be used to indicate abnormal disk
      utilization.
  - name: "Service"
    description: |
      Service/Other metrics are KPIs are a mix between metrics that indicate
      abnormal Database operation (such as migrations outside of a maintenance
      event) or system problems that may cause abnormal Database operations (such
      as time skew).
  - name: "Trend"
    description: |
      Trend metrics are useful stats to allow operations deeper understanding of
      system behaviors leading up to a particular event.
# - name        : Name of the metric
#   location    : Where to access the metric [statistics, namespace, or xdr]
#   ee-only     : Metric applies to Aerospike Enterprise only
#   cumulative  : If yes then the value grows monotonically during the execution
#                 of the process, otherwise it represents a current system state
#   description : Description of the metric
#   usage       : Information on how one may use this stat for monitoring/trending.
#                 Only used on kpi: true
#   introduced  : Server version this stat was introduced
#   removed     : Version stat stopped being in used, use '"no"' if not removed
#   kpi         : Is this stat a key performance indicator, used by monitoring page
#   category    : For KPIs only

################################################################################
# Statistics Stats: asinfo -v "statistics"
################################################################################

contexts:
  - location: Statistics
    metrics:
      - name: aggr_scans_failed
        location: Statistics
        introduced: 3.6.0
        removed: "3.9"
        cumulative: true
        description: |
          'Number of scans aborted. Introduced in 3.6.0. Moved to namespace
          level and renamed to `scan_aggr_error` as of 3.9.'
      - name: aggr_scans_succeeded
        location: Statistics
        introduced: 3.6.0
        removed: "3.9"
        cumulative: true
        description:
          "Number of aggregation scans that completed successfully. Moved to
          namespace level and renamed to `scan_aggr_complete` as of 3.9."
        kpi: false
      - name: basic_scans_succeeded
        location: Statistics
        cumulative: true
        introduced: 3.6.0
        removed: "3.9"
        description:
          "Number of basic scans that completed successfully. Moved to namespace
          level and renamed to `scan_basic_complete` as of 3.9."
        kpi: false
      - name: basic_scans_failed
        location: Statistics
        introduced: 3.6.0
        removed: "3.9"
        cumulative: true
        description:
          "Number of basic scans that failed. Moved to namespace level and
          renamed to `scan_basic_error` as of 3.9."
      - name: batch_errors
        location: Statistics
        cumulative: true
        removed: "3.9"
        description:
          "Number of batch direct requests that 6were rejected because of errors.
          Replaced with `batch_error` in 3.9."
        kpi: false
      - name: batch_error
        location: Statistics
        cumulative: true
        introduced: "3.9"
        removed: "4.4"
        description: "Number of batch direct requests that were rejected because of errors."
        kpi: false
      - name: batch_index_complete
        location: Statistics
        cumulative: true
        description: "Number of batch index requests completed."
        kpi: false
        introduced: 3.6.0
      - name: batch_index_created_buffers
        location: Statistics
        cumulative: true
        description: |
          Number of 128KB response buffers created.  Response buffers are created when there are no buffers left in the pool.
          If this number consistently increases and there is available memory,
          then [`batch-max-unused-buffers`](/docs/reference/configuration/#batch-max-unused-buffers) should be increased.
        kpi: false
        introduced: 3.6.4
      - name: batch_index_delay
        location: Statistics
        cumulative: true
        description: |
          Number of times a batch index response buffer has been delayed (WOULDBLOCK on the send). This will not count the number
          of times a batch index transaction is abandoned because it went over its overall allocated time after a delay. Those would be counted
          under the [`batch_index_error`](/docs/reference/metrics#batch_index_error) and will have a WARNING log message associated.
        kpi: false
        introduced: "4.1"
      - name: batch_index_destroyed_buffers
        location: Statistics
        cumulative: true
        description: |
          Number of 128KB response buffers destroyed.  Response buffers are destroyed when there is no slot left to put the buffer back into the pool.
          The maximum response buffer pool size is [`batch-max-unused-buffers`](/docs/reference/configuration/#batch-max-unused-buffers).
        kpi: false
        introduced: 3.6.4
      - name: batch_index_errors
        location: Statistics
        cumulative: true
        description:
          "Number of batch index requests that were rejected because of errors.
          Replaced with [`batch_index_error`](/docs/reference/metrics#batch_index_error)
          in 3.9."
        kpi: false
        introduced: 3.6.0
        removed: "3.9"
      - name: batch_index_error
        location: Statistics
        cumulative: true
        description: |
          Number of batch index requests that completed with an error. For example, if the client has timed out but the server is
          still attempting to send response buffers back. Or if the server abandons the transaction due to encountering delays (WOULDBLOCK on send)
          of more than twice the total timeout set by the client (or 30 seconds if not set) when sending response buffers back.
        kpi: false
        introduced: "3.9"
      - name: batch_index_huge_buffers
        location: Statistics
        cumulative: true
        description: |
          Number temporary response buffers created that exceeded 128KB.  Huge buffers are created when one of the records is retrieved that is greater than 128KB.
          Huge records do not benefit from batching and can result in excessive memory thrashing on the server. The
          [`batch_index_created_buffers`](/docs/reference/metrics#batch_index_created_buffers) and
          [`batch_index_destroyed_buffers`](/docs/reference/metrics#batch_index_destroyed_buffers) do include the huge buffers created and destroyed.
        kpi: false
        introduced: 3.6.4
      - name: batch_index_initiate
        location: Statistics
        cumulative: true
        description: "Number of batch index requests received."
        kpi: false
        introduced: 3.6.0
      - name: batch_index_queue
        location: Statistics
        cumulative: false
        description: |
          Number of batch index requests (transactions count) processed and response buffer blocks used on each batch queue.
          Format: &lt;q1 requests&gt; :&lt;q1 buffers&gt; ,&lt;q2 requests&gt; :&lt;q2 buffers&gt;,...
          The buffer block counter is actually decremented on batch responses before the transaction count is decremented.
          Therefore, it is possible for a buffer slot becomes available on the queue and a new batch transaction count is incremented before the
          previous batch command count is decremented. It is also possible that multiple transactions came in for a thread for which none
          of the response buffers has been created yet. Finally, [`batch_index_huge_buffers`](/docs/reference/metrics#batch_index_huge_buffers)
          are counted as part of the buffer blocks used on each batch queue.
        kpi: false
        introduced: 3.6.0
      - name: batch_index_timeout
        location: Statistics
        cumulative: true
        description: |
          Number of batch index requests that timed-out on the server before being processed. Those would be caused by a batch sub transaction
          that has timed out for this batch index transaction. The overall time allowed for a batch-index transaction on the server is not bound, except if a
          delay is encountered (WOULDBLOCK on send). As of version 4.1, the overall batch index transaction max delay time is twice the total timeout set
          by the client or 30 seconds if there are no timeout set by the client.
        kpi: false
        introduced: 3.6.0
      - name: batch_index_unused_buffers
        location: Statistics
        cumulative: false
        description:
          "Number of available 128 KB response buffers currently in buffer
          pool."
        kpi: false
        introduced: 3.6.0
      - name: batch_initiate
        location: Statistics
        cumulative: true
        removed: "4.4"
        description: "Number of batch direct requests received."
        kpi: false
      - name: batch_queue
        location: Statistics
        cumulative: false
        removed: "4.4"
        description:
          "Number of batch direct requests remaining on the queue awaiting
          processing."
        kpi: false
      - name: batch_timeout
        location: Statistics
        cumulative: true
        removed: "4.4"
        description:
          "Number of batch direct requests that timed-out on the server before
          being processed."
        kpi: false
      - name: batch_tree_count
        location: Statistics
        cumulative: false
        description: "Number of tree lookups for all batch direct requests."
        kpi: false
        removed: "3.9"
      - name: client_connections
        location: Statistics
        cumulative: false
        description: "Number of active client connections to this node."
        kpi: false
        category: Application
        usage: |
          **IF** `client_connections` are below expected low value
          **THEN** May indicate a problem with network components between clients
          and server.

          **IF** `client_connections` are above expected high value<br/>
          **THEN** May indicate a problem with clients rapidly opening and closing
          sockets.

          **IF**`client_connections` are at or near `proto_fd_max` configuration
          value <br/>
          **THEN** Aerospike may soon or currently is unable to accept new connections.
      - name: cluster_clock_skew
        location: Statistics
        ee-only: true
        cumulative: false
        introduced: "4.0"
        removed: 4.0.0.4
        description: |
          Current maximum clock skew in milliseconds between nodes cluster. Would trigger stop writes
          when breaching the [`cluster_clock_skew_stop_writes_sec`](/docs/reference/metrics#cluster_clock_skew_stop_writes_sec)
          threshold. Replaced by [`cluster_clock_skew_ms`](/docs/reference/metrics#cluster_clock_skew_ms) as of version 4.0.0.4.
        kpi: false
      - name: cluster_clock_skew_ms
        location: Statistics
        ee-only: false
        cumulative: false
        introduced: 4.0.0.4
        description: |
          Current maximum clock skew in milliseconds between nodes cluster. Would trigger stop writes
          when breaching the [`cluster_clock_skew_stop_writes_sec`](/docs/reference/metrics#cluster_clock_skew_stop_writes_sec)
          [`strong-consistency`](/docs/reference/configuration#strong-consistency) threshold.<BR>
          This new methodology has a somewhat stronger dependence on clocks being synchronized across nodes in a cluster.<BR>
          As of Aerospike Server 4.5.1, for each [Available mode](/docs/architecture/consistency.html#available-mode) (AP) namespace where nsup is enabled 
          (i.e. [`nsup-period`](/docs/reference/configuration/index.html#nsup-period) not zero) writes will be suspended if cluster clock skew exceeds 40 seconds.
        kpi: false
      - name: cluster_clock_skew_stop_writes_sec
        location: Statistics
        ee-only: false
        cumulative: false
        introduced: "4.0"
        description: |
          The threshold at which any namespace that is set to [`strong-consistency`](/docs/reference/configuration#strong-consistency) will
          stop accepting writes due to clock skew ([`cluster_clock_skew_ms`](/docs/reference/metrics#cluster_clock_skew_ms)).<BR>
          This new methodology has a somewhat stronger dependence on clocks being synchronized across nodes in a cluster.<BR>
          As of Aerospike Server 4.5.1, for each [Available mode](/docs/architecture/consistency.html#available-mode) (AP) namespace where nsup is enabled 
          (i.e. [`nsup-period`](/docs/reference/configuration/index.html#nsup-period) not zero) writes will be suspended if cluster clock skew exceeds 40 seconds.
        kpi: false
      - name: cluster_integrity
        location: Statistics
        cumulative: false
        description:
          "When `false`, indicates integrity issues within the cluster, meaning
          that some nodes are either faulty or dead. \nA node in the succession list is
          deemed faulty if the node is alive and it reports to be an orphan or is part
          of some \nother cluster. Another condition for a faulty node would be for it
          to be alive but having a clustering protocol identifier \nthat does not match
          the rest of the cluster.\nWhen `true`, indicates that the cluster is in a whole
          and complete state (as far as the nodes that it sees and is able to connect
          to\nare all concerned). Information about a cluster integrity fault will also
          be logged to the server log file repeatedly.\n"
        kpi: false
      - name: cluster_key
        location: Statistics
        cumulative: false
        description: |
          Randomly generated 64 bit hexadecimal string used to name the last Paxos
          cluster state agreement.
        kpi: false
      - name: cluster_size
        location: Statistics
        cumulative: false
        description: |
          Size of the cluster. Can be checked to make sure the size of the cluster is the expected one after adding or removing a node.
          This should be checked across all nodes in a cluster.
        kpi: true
        category: Network
        usage: |
          **IF** [`cluster_size`](/docs/reference/metrics/#cluster_size) does not equal the expected cluster size and cluster
          in not undergoing maintenance **THEN** Operations need to investigate the
          cause.
      - name: cluster_generation
        location: Statistics
        cumulative: true
        introduced: "4.3"
        description: |
          A 64 bit unsigned integer incremented on a node for every successful cluster partition re-balance or transition to orphan state.
          This is a node local value and does not need to be the same across the cluster.
        kpi: false
        category: Network
      - name: cluster_principal
        location: Statistics
        cumulative: false
        introduced: "4.3"
        description:
          "This specifies the Node ID of the current cluster principal. Will
          be '0' on an orphan node."
        kpi: false
        category: Network
      - name: data-used-bytes-memory
        location: Statistics
        cumulative: false
        removed: "3.9"
        description:
          "Amount of memory occupied by record data. Removed in 3.9. Use namespace
          level statistics instead."
        kpi: false
      - name: demarshal_error
        location: Statistics
        cumulative: true
        introduced: "3.9"
        description: "Number of errors during the demarshal step."
        kpi: false
      - name: early_tsvc_batch_sub_error
        location: Statistics
        cumulative: true
        introduced: "3.9"
        description: |
          Number of errors early in the transaction for batch sub transactions. For example, bad/unknown namespace
          name or security authentication errors.
        kpi: false
      - name: early_tsvc_from_proxy_batch_sub_error
        location: Statistics
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of errors early in the transaction for batch sub transactions proxied from another node. For example, bad/unknown namespace
          name or security authentication errors.
        kpi: false
      - name: early_tsvc_client_error
        location: Statistics
        cumulative: true
        introduced: "3.9"
        description: |
          Number of errors early in the transaction for direct client requests. Those include transactions hitting the 
          [`proto-fd-max`](/docs/reference/configuration/index.html?show-removed=0#proto-fd-max), transactions with a bad/unknown namespace
          name or security authentication errors. 
        kpi: false
      - name: early_tsvc_from_proxy_error
        location: Statistics
        cumulative: true
        introduced: 4.5.1
        description:
          "Number of errors early in the transaction for transactions (other
          than batch sub transactions) proxied from another node. \nFor example, bad/unknown
          namespace name or security authentication errors.\n"
        kpi: false
      - name: early_tsvc_udf_sub_error
        location: Statistics
        cumulative: true
        introduced: "3.9"
        description: |
          Number of errors early in the transaction for udf sub transactions. For example, bad/unknown namespace
          name or security authentication errors.
        kpi: false
      - name: err_duplicate_proxy_request
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: "Number of duplicate proxy errors."
        kpi: false
      - name: err_out_of_space
        location: Statistics
        cumulative: true
        removed: "3.9"
        description:
          "Number of writes resulting in disk out of space errors. Use namespace
          level `stop_writes` instead."
        kpi: false
        category: Storage
        usage: |
          **IF** `err_out_of_space` is increasing **THEN** one or more storage
          devices have reached capacity and the Aerospike cannot write".
      - name: err_replica_non_null_node
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of errors during cluster state exchange because of unexpected
          replica node information.
        kpi: false
      - name: err_replica_null_node
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of errors during cluster state exchange because of missing replica
          node information.
        kpi: false
      - name: err_rw_cant_put_unique
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of write transactions aborted because write required unique and
          record existed already.
        kpi: false
      - name: err_rw_pending_limit
        location: Statistics
        cumulative: true
        removed: "3.9"
        description:
          "Number of read/write transactions failed on 'hot keys'. Replaced
          with `fail_key_busy` at namespace level in 3.9."
        kpi: false
        category: Application
        usage: |
          **IF** application is not expected to have hot keys and
          `err_rw_pending_limit` rate of change exceeds expectations **THEN**
          may indicate an application issue.
      - name: err_rw_request_not_found
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of read/write transactions started but could not find record in rw hash after
          the replica side of the transaction is processed (due to timeout that would remove
          the record from rw hash).
        kpi: false
      - name: err_storage_defrag_fd_get
        location: Statistics
        cumulative: true
        removed: "Yes"
        description: "Removed"
        kpi: false
      - name: err_storage_queue_full
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          As of version 3.9, included in [`client_write_error`](/docs/reference/metrics/#client_write_error) stat at the namespace level.
          Will also cause warning level errors in the log file.
          Number of non-read requests failed due to disk being too backed up. Will
          return 'DEVICE_OVERLOAD' failure to client. See also storage_max_write_cache.
          Refer to [this article](https://discuss.aerospike.com/t/understanding-client-write-errors/4442)
          for further details on the type of errors that will increment this statistic.
        kpi: false
      - name: err_sync_copy_null_master
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of errors during cluster state exchange because of missing master
          node information.
        kpi: false
      - name: err_sync_copy_null_node
        location: Statistics
        cumulative: true
        removed: "Yes"
        description: |
          Number of errors during cluster state exchange because of missing general
          node information.
        kpi: false
      - name: err_tsvc_requests
        location: Statistics
        removed: "3.9"
        cumulative: true
        description: |
          Number of failures where the execution is not even attempted. Some examples: partition imbalance, partition not found,
          transaction prepare error, write during set-delete or unknown namespace in protocol request. As of version 3.9, such
          errors are reported as [`tsvc_error`]([`client_write_error`](/docs/reference/metrics/#tsvc_error) or
          under the [`client_write_error`](/docs/reference/metrics/#client_write_error) at the namespace level.
        kpi: false
      - name: err_tsvc_requests_timeout
        location: Statistics
        removed: "3.9"
        cumulative: true
        description: |
          Number of failures where the execution times out while in the transaction queue. As of version 3.9,
          moved under the `client_tsvc_timeout` stat at the namespace level.
        kpi: false
      - name: err_write_fail_bin_exists
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of write requests resulting in error 'bin exists'.
          As of version 3.9, included in [`client_write_error`](/docs/reference/metrics/#client_write_error)
          stat at the namespace level. Will also cause warning level errors in the log file.
        kpi: false
      - name: err_write_fail_bin_name
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of write requests resulting in error 'bin name'.
          As of version 3.9, included in [`client_write_error`](/docs/reference/metrics/#client_write_error)
          stat at the namespace level. Will also cause warning level errors in the log file.
        kpi: false
      - name: err_write_fail_bin_notfound
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of write requests resulting in error 'bin not found'.
          As of version 3.9, included in [`client_write_error`](/docs/reference/metrics/#client_write_error)
          stat at the namespace level. Will also cause warning level errors in the log file.
        kpi: false
      - name: err_write_fail_forbidden
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of write requests failed because a write transaction is being attempted on a set still being deleted.
          As of version 3.9, moved to `fail_xdr_forbidden` stat at the namespace level that tracks only transactions failing
          due to configuration restrictions (see config options `allow-xdr-writes` and `allow-nonxdr-writes`).
        kpi: false
      - name: err_write_fail_generation
        location: Statistics
        cumulative: true
        removed: "3.9"
        description:
          "Number of write requests failed because of generation mismatch.
          As of version 3.9, moved to `fail_generation` stat at the namespace level."
        kpi: false
      - name: err_write_fail_generation_xdr
        location: Statistics
        cumulative: true
        removed: 3.8.1
        description:
          "Number of write requests from XDR that failed because of generation
          mismatch."
        kpi: false
      - name: err_write_fail_incompatible_type
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          For data-in-index configuration, Number of write requests which are not
          integer. As of version 3.9, included in [`client_write_error`](/docs/reference/metrics/#client_write_error)
          stat at the namespace level. Will also cause warning level errors in the log file.
        kpi: false
      - name: err_write_fail_key_exists
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of write transactions that failed because the key already exists.
          As of version 3.9, included in [`client_write_error`](/docs/reference/metrics/#client_write_error)
          stat at the namespace level. Will also cause warning level errors in the log file.
        kpi: false
      - name: err_write_fail_key_mismatch
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of failed requests due to key mismatch, occurs when key is stored
          in Aerospike and key check is requested on the transaction.
          As of version 3.9, included in [`client_write_error`](/docs/reference/metrics/#client_write_error)
          stat at the namespace level. Will also cause warning level errors in the log file.
        kpi: false
      - name: err_write_fail_not_found
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of write transactions that failed due to the key not found.
          As of version 3.9, included in [`client_write_error`](/docs/reference/metrics/#client_write_error)
          stat at the namespace level. Will also cause warning level errors in the log file.
        kpi: false
      - name: err_write_fail_noxdr
        location: Statistics
        ee-only: true
        cumulative: true
        removed: 3.8.1
        description: |
          Number of writes rejected because XDR was not running. (Only in effect
          when configuration [`xdr_stop_writes_noxdr`](/docs/reference/configuration/#xdr_stop_writes_noxdr) is on.
        kpi: false
      - name: err_write_fail_parameter
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of write transactions that failed because of a bad parameter from
          application code. As of version 3.9, included in `client_write_error` stat at the namespace level.
          Will also cause warning level errors in the log file.
        kpi: false
      - name: err_write_fail_prole_delete
        location: Statistics
        cumulative: true
        removed: "3.9"
        description:
          "Number of replica delete failures because the replica record is
          not found."
        kpi: false
      - name: err_write_fail_prole_generation
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: "Number of prole write failures because of generation mismatch."
        kpi: false
      - name: err_write_fail_prole_unknown
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: "Number of prole write failures with unknown errors."
        kpi: false
      - name: err_write_fail_record_too_big
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of write failures due to record being too big (bigger than [`write-block-size`](/docs/reference/configuration#write-block-size)).
          As of version 3.9, moved to `fail_record_too_big` stat at the namespace level.
        kpi: false
      - name: err_write_fail_unknown
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: "Number of write failures with unknown errors."
        kpi: false
      - name: fabric_connections
        location: Statistics
        cumulative: false
        introduced: "3.9"
        description: "Number of active fabric connections to this node."
        kpi: false
      - name: fabric_bulk_send_rate
        location: Statistics
        cumulative: false
        introduced: 3.11.1.1
        description: |
          Number of bytes sent by the fabric bulk channel
          (in bytes per seconds overaged over the ticker interval which is 10 seconds by default).
        kpi: false
      - name: fabric_bulk_recv_rate
        location: Statistics
        cumulative: false
        introduced: 3.11.1.1
        description: |
          Number of bytes received by the fabric bulk channel
          (in bytes per seconds overaged over the ticker interval which is 10 seconds by default)..
        kpi: false
      - name: fabric_ctrl_send_rate
        location: Statistics
        cumulative: false
        introduced: 3.11.1.1
        description: |
          Number of bytes sent by the fabric ctrl channel
          (in bytes per seconds overaged over the ticker interval which is 10 seconds by default)..
        kpi: false
      - name: fabric_ctrl_recv_rate
        location: Statistics
        cumulative: false
        introduced: 3.11.1.1
        description: |
          Number of bytes received by the fabric ctrl channel
          (in bytes per seconds overaged over the ticker interval which is 10 seconds by default)..
        kpi: false
      - name: fabric_meta_send_rate
        location: Statistics
        cumulative: false
        introduced: 3.11.1.1
        description: |
          Number of bytes sent by the fabric meta channel
          (in bytes per seconds overaged over the ticker interval which is 10 seconds by default)..
        kpi: false
      - name: fabric_meta_recv_rate
        location: Statistics
        cumulative: false
        introduced: 3.11.1.1
        description: |
          Number of bytes received by the fabric meta channel
          (in bytes per seconds overaged over the ticker interval which is 10 seconds by default)..
        kpi: false
      - name: fabric_rw_send_rate
        location: Statistics
        cumulative: false
        introduced: 3.11.1.1
        description: |
          Number of bytes sent by the fabric rw channel
          (in bytes per seconds overaged over the ticker interval which is 10 seconds by default)..
        kpi: false
      - name: fabric_rw_recv_rate
        location: Statistics
        cumulative: false
        introduced: 3.11.1.1
        description: |
          Number of bytes received by the fabric rw channel
          (in bytes per seconds overaged over the ticker interval which is 10 seconds by default)..
        kpi: false
      - name: fabric_msgs_rcvd
        location: Statistics
        cumulative: true
        removed: 3.11.1.1
        description: "Number of messages received via the fabric layer from other nodes."
        kpi: false
      - name: fabric_msgs_sent
        location: Statistics
        cumulative: true
        removed: 3.11.1.1
        description: "Number of messages sent via the fabric layer to other nodes."
        kpi: false
      - name: free-pct-disk
        location: Statistics
        cumulative: false
        removed: "3.9"
        description:
          "Percentage of disk available. As of version 3.9, moved to `device_free_pct`
          stat at the namespace level."
        kpi: false
        category: Storage
        usage: |
          **IF** `free-pct-disk` fall below 25% **THEN** Cluster is reaching
          capacity, should consider adding nodes or increasing per node capacity.
      - name: free-pct-memory
        location: Statistics
        cumulative: false
        removed: "3.9"
        description:
          "Percentage of memory available. As of version 3.9, moved to `memory_free_pct`
          stat at the namespace level."
        kpi: false
      - name: geo_region_query_cells
        location: Statistics
        cumulative: false
        removed: "3.9"
        description: "As of version 3.9, moved to the namespace level."
        kpi: false
      - name: geo_region_query_falspos
        location: Statistics
        cumulative: false
        removed: "3.9"
        description: "As of version 3.9, moved to the namespace level."
        kpi: false
      - name: geo_region_query_points
        location: Statistics
        cumulative: false
        removed: "3.9"
        description: "As of version 3.9, moved to the namespace level."
        kpi: false
      - name: geo_region_query_reqs
        location: Statistics
        cumulative: false
        removed: "3.9"
        description: "As of version 3.9, moved to the namespace level."
        kpi: false
      - name: heap_active_kbytes
        location: Statistics
        cumulative: false
        introduced: 3.10.1
        description:
          "The amount of memory in in-use pages, in KiB. An in-use page is
          a page that has some allocated memory (either partial or full)."
        kpi: false
      - name: heap_allocated_kbytes
        location: Statistics
        cumulative: false
        introduced: 3.10.1
        description: |
          The amount of memory, in KiB, allocated by the asd daemon. The `heap_allocated_kbytes` / `heap_active_kbytes` ratio and `heap_allocated_kbytes` /
          `heap_mapped_kbytes` ratio (also provided under `heap_efficiency_pct`) provide a picture of the fragmentation of the heap. This is for all
          memory usage except for the shared memory parts (for the primary index in the Enterprise Edition).
        kpi: false
      - name: heap_efficiency_pct
        location: Statistics
        cumulative: false
        introduced: 3.10.1
        description: |
          Provides an indication of the jemalloc heap fragmentation. This represents the `heap_allocated_kbytes` / `heap_mapped_kbytes` ratio.
          A lower number indicates a higher fragmentation rate.
        kpi: false
      - name: heap_mapped_kbytes
        location: Statistics
        cumulative: false
        introduced: 3.10.1
        description: |
          The amount of memory in mapped pages, in KiB, i.e., the amount of memory that JEM received from the Linux kernel. It should be a multiple of 4, as
          that would be the typical page size (4096 bytes).
        kpi: false
      - name: heartbeat_connections
        location: Statistics
        cumulative: false
        introduced: "3.9"
        description: "Number of active heartbeat connections to this node."
        kpi: false
      - name: heartbeat_received_foreign
        location: Statistics
        cumulative: true
        description: "Total number of heartbeats received from remote nodes."
        kpi: false
      - name: heartbeat_received_self
        location: Statistics
        cumulative: true
        description: |
          Total number of multicast heartbeats from this node received by this node.
          Will be 0 for mesh.
        kpi: false
      - name: index-used-bytes-memory
        location: Statistics
        cumulative: false
        removed: "3.9"
        description: |
          Amount of memory occupied by the index measured in bytes.
          Use `memory_used_index_bytes` at the namespace level as of version 3.9.
        kpi: false
      - name: info_complete
        location: Statistics
        cumulative: true
        introduced: "3.9"
        description: "Number of info requests completed."
        kpi: false
      - name: info_queue
        location: Statistics
        cumulative: false
        description: "Number of info requests pending in info queue."
        kpi: false
      - name: migrate_allowed
        location: Statistics
        cumulative: false
        description: |
          This indicates whether migrations are allowed or not on a node. `true` when allowed, `false` when not. When there is a change in a cluster, this statistic's value
          will change to false until the rebalance is completed across all namespaces. The rebalance is the step that figures out all partition migrations that need
          to be scheduled. The rebalance is not the migrations itself but the process that precedes the partitions migrations. [`migrate_allowed`](/docs/reference/metrics/#migrate_allowed)
          `true` indicates that all migrations related statistics have been set and can be leveraged programmatically,
          for example, [`migrate_partitions_remaining`](/docs/reference/metrics/#migrate_partitions_remaining) to check if migrations are ongoing or not).
        kpi: false
      - name: migrate_msgs_recv
        location: Statistics
        cumulative: true
        removed: 3.8.3
        description: "Number of migrate messages received."
        kpi: false
      - name: migrate_msgs_sent
        location: Statistics
        cumulative: true
        removed: 3.8.3
        description: "Number of migrate messages sent."
        kpi: false
      - name: migrate_num_incoming_accepted
        location: Statistics
        cumulative: true
        removed: 3.8.3
        description: "Number of migrate requests accepted from other nodes."
        kpi: false
      - name: migrate_num_incoming_refused
        location: Statistics
        cumulative: true
        removed: 3.8.3
        description: |
          Number of migrate requests refused from other nodes due to reaching
          'migrate-max-num-incoming' limit.
        kpi: false
      - name: migrate_partitions_remaining
        location: Statistics
        cumulative: false
        introduced: 3.8.3
        description: |
          This is the number of partitions remaining to migrate (in either direction). When [`migrate_allowed`](/docs/reference/metrics/#migrate_allowed) is `true`,
          this is the stat which will accurately determine if migrations are complete for a single node across all namespaces. There could be a short period after a reclustering event
          when this statistic shows `0` but the migrations have not started yet. During such time, [`migrate_allowed`](/docs/reference/metrics/#migrate_allowed) would
          return `false`.
        kpi: false
      - name: migrate_progress_recv
        location: Statistics
        cumulative: false
        removed: 3.8.3
        description: |
          Number of partitions currently being received on this node. Replaced by `migrate_rx_partitions_active`
          at the namespace level in version 3.9.
        kpi: false
      - name: migrate_progress_send
        location: Statistics
        cumulative: false
        removed: 3.8.3
        description: |
          Number of partitions currently being sent out from this node. Replaced by `migrate_tx_partitions_active`
          at the namespace level in version 3.9.
        kpi: false
      - name: migrate_rx_objs
        location: Statistics
        cumulative: false
        removed: 3.8.3
        description:
          "Number of partitions currently migrating to this node. Replaced
          by `migrate-rx-instance-count` in 3.8.3."
        kpi: false
      - name: migrate_tx_objs
        location: Statistics
        cumulative: false
        removed: 3.8.3
        description:
          "Number of partitions pending migration out of this node. Replaced
          by `migrate-tx-instance-count` in 3.8.3."
        kpi: false
      - name: objects
        location: Statistics
        cumulative: false
        description:
          "Total number of replicated objects on this node. Includes master
          and replica objects."
        kpi: false
        category: Trend
        usage:
          "Trending `objects` provides operations insight into object fluctuations
          over time."
      - name: ongoing_write_reqs
        location: Statistics
        cumulative: false
        removed: "3.9"
        description: "Number of records currently in write transactions."
        kpi: false
      - name: partition_absent
        location: Statistics
        cumulative: false
        removed: "3.9"
        description:
          "Number of partitions for which this node is not either master or
          replica."
        kpi: false
      - name: partition_actual
        location: Statistics
        cumulative: false
        removed: "3.9"
        description: "Number of partitions for which this node is acting as master."
        kpi: false
      - name: partition_desync
        location: Statistics
        cumulative: false
        removed: "3.9"
        description: |
          Number of partitions that are not yet synced with the rest of the cluster.
          nodes
        kpi: false
      - name: partition_object_count
        location: Statistics
        cumulative: false
        removed: "3.9"
        description:
          "Total number of objects. Removed as of version 3.9. Use partition-info
          for full partition info dump."
        kpi: false
      - name: partition_ref_count
        location: Statistics
        cumulative: false
        removed: "3.9"
        description: "Number of partitions that are currently being read."
        kpi: false
      - name: partition_replica
        location: Statistics
        cumulative: false
        removed: "3.9"
        description: "Number of partitions for which this node is acting as replica."
        kpi: false
      - name: paxos_principal
        location: Statistics
        cumulative: false
        description:
          "Identifier for the node in which this node believes to be the Paxos
          Principal."
        kpi: false
      - name: proxy_action
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: "Number of proxy requests received from other nodes."
        kpi: false
      - name: proxy_initiate
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of scan requests initiated. As of 3.9, this is tracked under the namespace level statistics
          `proxy_complete` and `proxy_error`.
        kpi: false
      - name: proxy_retry
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: "Number of retried proxy requests to other nodes."
        kpi: false
      - name: proxy_in_progress
        location: Statistics
        cumulative: false
        description: |
          Number of proxies in progress. Also called proxy hash.
          The transaction's ttl (client set timeout or [`transaction-max-ms`](/docs/reference/configuration#transaction-max-ms) is checked every 75ms
          when waiting in the proxy-hash.<br>
        introduced: 3.3.21
        kpi: false
      - name: proxy_retry_new_dest
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: "Number of proxy retries this node delivered to a new destination."
        kpi: false
      - name: proxy_retry_q_full
        location: Statistics
        removed: "3.9"
        cumulative: true
        description: "Number of proxy retries failed because fabric queue was full."
        kpi: false
      - name: proxy_retry_same_dest
        location: Statistics
        removed: "3.9"
        cumulative: true
        description: "Number of proxy retries this node delivered to the same destination."
        kpi: false
      - name: proxy_unproxy
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of re-executions (from scratch) because of unavailability of proxy.
          node
        kpi: false
      - name: query_abort
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of user aborted queries seen by this node. Refer to `query_agg_abort` and `query_lookup_abort` at
          the namespace level as of version 3.9.
        kpi: false
      - name: query_agg
        location: Statistics
        cumulative: true
        removed: "3.9"
        description:
          "Number of aggregations run on this node seen by this node. Moved
          to namespace level as of version 3.9."
        kpi: false
      - name: query_agg_abort
        location: Statistics
        cumulative: true
        removed: "3.9"
        description:
          "Number of aggregations aborted by the user seen by this node. Moved
          to namespace level as of version 3.9."
        kpi: false
      - name: query_agg_avg_rec_count
        location: Statistics
        cumulative: false
        removed: "3.9"
        description:
          "Average number of records returned by aggregations seen by this
          node. Moved to namespace level as of version 3.9."
        kpi: false
      - name: query_agg_err
        location: Statistics
        cumulative: true
        removed: "3.9"
        description:
          "Number of aggregations fail due to an internal error seen by this
          node. Moved to namespace level `query_agg_error` as of version 3.9."
        kpi: false
      - name: query_agg_success
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of aggregations which succeeded on this node without error seen by
          this node.  Moved to namespace level as of version 3.9.
        kpi: false
      - name: query_avg_rec_count
        location: Statistics
        cumulative: false
        removed: "3.9"
        description: |
          Average number of records returned of all queries which executed on this node. Refer to `query_agg_avg_rec_count` and
          `query_lookup_avg_rec_count` at the namespace level as of version 3.9.
        kpi: false
      - name: query_bad_records
        location: Statistics
        cumulative: true
        removed: "Yes"
        description: "Number of false positive entries in secondary index queries."
        kpi: false
      - name: query_fail
        location: Statistics
        cumulative: true
        removed: "3.9"
        description:
          "Number of queries which failed due to an internal error seen by
          this node. Moved to namespace level as of version 3.9."
        kpi: false
      - name: query_long_queue_full
        location: Statistics
        cumulative: true
        removed: "3.9"
        description:
          "Number of long running queries queue full errors. Moved to namespace
          level as of version 3.9."
        kpi: false
      - name: query_long_reqs
        location: Statistics
        cumulative: false
        removed: "3.9"
        description:
          "Number of long running queries currently in process. Moved to namespace
          level as of version 3.9."
        kpi: false
      - name: query_long_running
        location: Statistics
        cumulative: true
        description: |
          Number of long running queries ever attempted in the system (query selected record
          more than query_threshold).
        kpi: false
      - name: query_lookup_abort
        location: Statistics
        cumulative: true
        removed: "3.9"
        description:
          "Number of user aborted look-ups seen by this node. Moved to namespace
          level as of version 3.9."
        kpi: false
      - name: query_lookup_avg_rec_count
        location: Statistics
        cumulative: false
        removed: "3.9"
        description:
          "Average number of records returned by all look-ups seen by this
          node. Moved to namespace level as of version 3.9."
        kpi: false
      - name: query_lookup_err
        location: Statistics
        cumulative: true
        removed: "3.9"
        description:
          "Number of look-ups fail due to an error seen by this node. Moved
          to namespace level stat `query_lookup_error` as of version 3.9."
        kpi: false
      - name: query_lookup_success
        location: Statistics
        cumulative: true
        removed: "3.9"
        description:
          "Number of look-ups which succeeded on this node. Moved to namespace
          level as of version 3.9."
        kpi: false
      - name: query_lookups
        location: Statistics
        cumulative: true
        removed: "3.9"
        description:
          "Number of look-ups performed by this node. Moved to namespace level
          as of version 3.9."
        kpi: false
      - name: query_reqs
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of query requests received by this node. Even very early failures would be
          counted here, as opposed to `query_short_running` and `query_long_running` which would
          tick a bit later. Moved to namespace level as of version 3.9.
        kpi: false
      - name: query_short_queue_full
        location: Statistics
        cumulative: true
        removed: "3.9"
        description:
          "Number of short running queries queue full errors. Moved to namespace
          level as of version 3.9."
        kpi: false
      - name: query_short_reqs
        location: Statistics
        cumulative: false
        removed: "3.9"
        description:
          "Number of short running queries currently in process. Moved to namespace
          level as of version 3.9."
        kpi: false
      - name: query_short_running
        location: Statistics
        cumulative: true
        description: |
          Number of short running queries ever attempted in the system (query selected record
          less than query_threshold).
        kpi: false
      - name: query_success
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of queries succeeded on this node. As of version 3.9, broken down to namespace level stats
          `query_lookup_success`, `query_udf_bg_success` and `query_agg_success`.
        kpi: false
      - name: query_tracked
        location: Statistics
        cumulative: true
        description: |
          Number of queries tracked by the system. (Number of queries which ran more
          than query untracked_time (default 1 sec)).
        kpi: false
      - name: queue
        location: Statistics
        cumulative: false
        removed: "3.9"
        description:
          "Number of pending requests waiting to execute. Replaced with [`tsvc_queue`](/docs/reference/metrics/#tsvc_queue)
          as of version 3.9."
        kpi: false
      - name: read_dup_prole
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: "Number of requests sent for duplicate resolution."
        kpi: false
      - name: reaped_fds
        location: Statistics
        cumulative: true
        description: "Number of idle client connections closed."
        kpi: false
        category: Application
        usage: |
          **IF** `reaped_fds` are growing more rapidly than normal **THEN** May
          indicate client[s] are opening and closing sockets too rapidly --
          potential application issue.
      - name: record_locks
        location: Statistics
        cumulative: false
        removed: "3.9"
        description: "Number of record index locks currently active in the node."
        kpi: false
      - name: record_refs
        location: Statistics
        cumulative: false
        removed: "3.10"
        description: "Number of index records currently referenced."
        kpi: false
      - name: rw_err_ack_badnode
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: "Number of acknowledgments from unexpected nodes."
        kpi: false
      - name: rw_err_ack_internal
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: "Number of prole write acknowledgments failed due to internal errors."
        kpi: false
      - name: rw_err_ack_nomatch
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of prole write acknowledgments started but went amiss/have
          mismatched information.
        kpi: false
      - name: rw_err_dup_cluster_key
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of errors encountered during duplicate resolution because of
          cluster key mismatch.
        kpi: false
      - name: rw_err_dup_internal
        location: Statistics
        removed: "3.9"
        cumulative: true
        description: "Number of errors encountered during duplicate resolutions."
        kpi: false
      - name: rw_err_dup_send
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of errors encountered during duplicate resolutions because of
          failure to send fabric messages.
        kpi: false
      - name: rw_err_dup_write_cluster_key
        location: Statistics
        cumulative: true
        removed: "Yes"
        description: "Removed"
        kpi: false
      - name: rw_err_dup_write_internal
        location: Statistics
        cumulative: true
        removed: "Yes"
        description: "Removed"
        kpi: false
      - name: rw_err_write_cluster_key
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: "Number of replica write failures due to cluster key mismatch."
        kpi: false
      - name: rw_err_write_internal
        location: Statistics
        cumulative: true
        removed: "3.9"
        description:
          "Number of write requests failed because of internal errors (code
          errors)."
        kpi: false
      - name: rw_err_write_send
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of prole write acknowledgments fail because of failure in sending
          fabric message.
        kpi: false
      - name: rw_in_progress
        location: Statistics
        cumulative: false
        introduced: "3.9"
        description: |
          Number of rw transactions in progress. Also called rw hash. This tracks transaction parked on the
          rw hash while processing on other nodes (all write replicas, read duplicate resolutions).
          The transaction's ttl (client set timeout or [`transaction-max-ms`](/docs/reference/configuration#transaction-max-ms) is checked every 130ms
          when waiting in the rw-hash.<br>
        kpi: false
      - name: scans_active
        location: Statistics
        cumulative: false
        introduced: 3.6.0
        description: "Number of scans currently active."
        kpi: false
      - name: sindex_gc_activity_dur
        location: Statistics
        cumulative: true
        description: "Sum of sindex GC thread activity (millisecond)."
        introduced: 3.3.10
        removed: "3.14"
        kpi: false
      - name: sindex_gc_garbage_cleaned
        location: Statistics
        cumulative: true
        description: "Sum of secondary index garbage entries cleaned by sindex GC."
        introduced: 3.3.10
        kpi: false
      - name: sindex_gc_garbage_found
        location: Statistics
        cumulative: true
        description: "Sum of secondary index garbage entries found by sindex GC."
        introduced: 3.3.10
        kpi: false
      - name: sindex_gc_inactivity_dur
        location: Statistics
        cumulative: true
        removed: "3.14"
        description: "Sum of sindex GC thread inactivity (millisecond)."
        introduced: 3.3.10
        kpi: false
      - name: sindex_gc_list_creation_time
        location: Statistics
        cumulative: true
        removed: "3.14"
        description:
          "Sum of time spent in finding secondary index garbage entries by
          sindex GC (millisecond)."
        introduced: 3.3.10
        kpi: false
      - name: sindex_gc_list_deletion_time
        location: Statistics
        cumulative: true
        description:
          "Sum of time spent in cleaning sindex garbage entries by sindex GC
          (millisecond)."
        introduced: 3.3.10
        kpi: false
      - name: sindex_gc_locktimedout
        location: Statistics
        cumulative: true
        description:
          "Number of times sindex gc iteration timed out waiting for partition
          lock."
        introduced: 3.3.3
        kpi: false
      - name: sindex_gc_objects_validated
        location: Statistics
        cumulative: true
        description: "Number of secondary index entries processed by sindex GC."
        introduced: 3.3.10
        kpi: false
      - name: sindex_ucgarbage_found
        location: Statistics
        cumulative: true
        description:
          "Number of un-cleanable garbage entries in the sindexes encountered
          through queries."
        introduced: 3.3.3
        kpi: false
      - name: sindex-used-bytes-memory
        location: Statistics
        cumulative: false
        removed: "3.9"
        description: |
          Amount of memory being occupied by secondary indexes across all namespaces. Replaced with
          `memory_used_sindex_bytes` at the namespace level as of version 3.9.
        kpi: false
      - name: stat_cluster_key_err_ack_dup_trans_reenqueue
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: "Number of duplicate trans re-enqueued because of cluster key mismatch."
        kpi: false
      - name: stat_cluster_key_err_ack_rw_trans_reenqueue
        location: Statistics
        cumulative: true
        removed: "Yes"
        description: "Number of Read/Write trans re-enqueued because of cluster key mismatch."
        kpi: false
      - name: stat_cluster_key_partition_transaction_queue_count
        location: Statistics
        cumulative: true
        removed: "Yes"
        description: "Removed/unused"
        kpi: false
      - name: stat_cluster_key_prole_retry
        location: Statistics
        cumulative: true
        removed: "Yes"
        description: |
          Number of times a prole write was retried as a result of a cluster key
          mismatch.
        kpi: false
      - name: stat_cluster_key_regular_processed
        location: Statistics
        cumulative: true
        removed: "Yes"
        description: "Number of successful transactions that passed the cluster key test."
        kpi: false
      - name: stat_cluster_key_transaction_reenqueue
        location: Statistics
        cumulative: true
        removed: "Yes"
        description: "Removed/unused"
        kpi: false
      - name: stat_cluster_key_trans_to_proxy_retry
        location: Statistics
        cumulative: true
        removed: "Yes"
        description: "Number of times a proxy was redirected."
        kpi: false
      - name: stat_compressed_pkts_received
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: "Number of compressed packages received."
        kpi: false
      - name: stat_deleted_set_objects
        location: Statistics
        cumulative: true
        removed: "3.9"
        description:
          "Number of deleted set objects as result of a 'set-delete' command.
          Refer to the `set_deleted_objects` at the namespace level."
        kpi: false
      - name: stat_delete_success
        location: Statistics
        cumulative: true
        removed: "3.9"
        description:
          "Number of successful record deletes. Moved to `client_delete_success`
          stat at the namespace level as of version 3.9."
        kpi: false
      - name: stat_duplicate_operation
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: "Number of read/write transactions which require duplicate resolution."
        kpi: false
      - name: stat_evicted_objects
        location: Statistics
        cumulative: true
        description: "Number of objects evicted"
        kpi: false
        category: Trend
        removed: "3.9"
        usage: |
          Trending `stat_evicted_objects` provides operations insight into system
          eviction behavior over time. Moved to `evicted_objects` stat at the namespace level as of version 3.9.
      - name: stat_evicted_objects_time
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: "Average expiry time (TTL) of the objects evicted in the last iteration."
        kpi: false
      - name: stat_evicted_set_objects
        location: Statistics
        cumulative: true
        removed: "Yes"
        description:
          "Number of objects evicted from a Set due to set limits defined in
          Aerospike configuration."
        kpi: false
      - name: stat_expired_objects
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: "Number of objects expired."
        kpi: false
        category: Trend
        usage: |
          Trending `stat_expired_objects` provides operations insight into system
          expiration behavior over time. Moved to `expired_objects` stat at the namespace level as of version 3.9.
      - name: stat_ldt_proxy
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: "Number of proxies for LDT records."
        kpi: false
      - name: stat_nsup_deletes_not_shipped
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of deletes resulting from eviction/expiration etc. that are not
          shipped.
        kpi: false
      - name: stat_proxy_errs
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of proxy requests returning errors. Moved to `client_proxy_error`/`batch_sub_proxy_error`
          stats at the namespace level as of version 3.9.
        kpi: false
      - name: stat_proxy_reqs
        location: Statistics
        cumulative: true
        removed: "3.9"
        description:
          "Number of proxy requests attempted. Refer to the different `*_proxy_*`
          statistics at the namespace level as of version 3.9."
        kpi: false
      - name: stat_proxy_reqs_xdr
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: "Number of XDR operations that resulted in proxies."
        kpi: false
      - name: stat_proxy_success
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of proxy requests served successfully. Refer to the `client_proxy_complete`/`batch_sub_proxy_complete`
          stats at the namespace level as of version 3.9.
        kpi: false
      - name: stat_read_errs_notfound
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of read requests resulting in error : 'key not found'. Moved to `client_read_not_found`/`batch_sub_read_not_found`
          stats at the namespace level as of version 3.9.
        kpi: false
      - name: stat_read_errs_other
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of read requests resulting in other errors. Moved to `client_read_error`/`batch_sub_read_error`
          stats at the namespace level as of version 3.9.
        kpi: false
      - name: stat_read_reqs
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of total read requests attempted. Refer to the different `*_read_*` statistics at the namespace level as of version 3.9
          for different read statistics from client, batch, and their different breakdown (success, error, not found, timeout).
        kpi: false
      - name: stat_read_reqs_xdr
        location: Statistics
        cumulative: true
        removed: "3.9"
        description:
          "Number of XDR read requests attempted. Refer to the different `xdr_read_*`
          stats as of version 3.9."
        kpi: false
      - name: stat_read_success
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of read requests successful. As of version 3.8.3, this stat will not include reads initiated by XDR.
          As of version 3.9, refer to the `client_read_success`/`batch_sub_read_success` stats at the namespace level.
        kpi: false
      - name: stat_rw_timeout
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of read and write requests failed because of timeout on the server.
          As of version 3.9, refer to the more specific stats at the namespace level.
        kpi: false
        category: Network
      - name: stat_single_bin_records
        location: Statistics
        cumulative: true
        removed: "Yes"
        description: "Removed: Number of single bin records."
        kpi: false
      - name: stat_slow_trans_queue_batch_pop
        location: Statistics
        cumulative: true
        removed: "Yes"
        description:
          "Number of times we moved a batch of trans from slow queue to fast
          queue."
        kpi: false
      - name: stat_slow_trans_queue_pop
        location: Statistics
        cumulative: true
        removed: "Yes"
        description: "Number of trans that were moved from slow queue to fast queue."
        kpi: false
      - name: stat_slow_trans_queue_push
        location: Statistics
        cumulative: true
        removed: "Yes"
        description: "Number of trans that we pushed onto the slow queue."
        kpi: false
      - name: stat_write_errs
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of write requests resulting in errors.
          As of version 3.9, refer to the [`client_write_error`](/docs/reference/metrics/#client_write_error) stat at the namespace level.
        kpi: false
      - name: stat_write_errs_notfound
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of errors returning key not found on a write request.
          As of version 3.9, this is included in the [`client_write_error`](/docs/reference/metrics/#client_write_error) stat at the namespace level.
        kpi: false
      - name: stat_write_errs_other
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of non 'not found' errors on a write requests.
          As of version 3.9, this is included in the [`client_write_error`](/docs/reference/metrics/#client_write_error) stat at the namespace level.
        kpi: false
      - name: stat_write_reqs
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of total writes requests attempted.
          As of version 3.9, refer to the `client_write_*` stats at the namespace level.
        kpi: false
      - name: stat_write_reqs_xdr
        location: Statistics
        ee-only: true
        cumulative: true
        removed: "3.9"
        description: |
          Number of write requests from XDR.
          As of version 3.9, refer to the `xdr_write_*` stats at the namespace level.
        kpi: false
      - name: stat_write_success
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of write requests successful.
          As of version 3.9, refer to the `client_write_success` stat at the namespace level.
        kpi: false
      - name: stat_xdr_pipe_miss
        location: Statistics
        ee-only: true
        cumulative: true
        removed: 3.8.1
        description: |
          Number of log records that couldn't be written to the named pipe by the
          server. Generally happens when XDR end of pipe is closed.
        kpi: false
      - name: stat_xdr_pipe_writes
        location: Statistics
        ee-only: true
        cumulative: true
        removed: 3.8.1
        description:
          "Number of log records that were written to the named pipe by the
          server."
        kpi: false
      - name: stat_zero_bin_records
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: "Number of write_requests that failed because of zero bin records."
        kpi: false
      - name: storage_defrag_corrupt_record
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: "Number of times the defrag thread encountered invalid records."
        kpi: false
      - name: storage_defrag_wait
        location: Statistics
        cumulative: true
        removed: "Yes"
        description: "Number of times the defrag waited (called sleep)."
        kpi: false
      - name: sub-records
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: "Number of sub objects. Replace with `sub_objects` stat in 3.9."
        kpi: false
      - name: sub_objects
        location: Statistics
        cumulative: true
        introduced: "3.9"
        description:
          "Number of LDT sub objects. Aggregated over the `sub_objects` stat
          at the namespace level."
        kpi: false
      - name: system_free_mem_pct
        location: Statistics
        cumulative: false
        description: |
          Percentage of free system memory. For versions prior to 3.16.0.4, the amount of shared memory used is wrongly reported as free.
          This was addressed as part of AER-5810.
        kpi: false
        category: Memory
        usage: |
          **IF** `system_free_mem_pct` is abnormally low **THEN** May indicate
          server reaching the limits of the available RAM, operations should
          investigate and potentially add nodes or increase per node RAM.
      - name: system_swapping
        location: Statistics
        cumulative: false
        removed: 4.4.0.4
        description:
          "Boolean state, true indicate that the system is currently swapping
          RAM to disk"
        kpi: false
        category: Memory
        usage: |
          **IF** `system_swapping` is ever true **THEN** Operations need to
          investigate the issue, swapping will cause drastic performance
          fluctuations.
      - name: time_since_rebalance
        location: Statistics
        cumulative: false
        description: |
          Number of seconds since the last reclustering event, either triggered via
          the [`recluster`](/docs/reference/info/#recluster) info command or by a
          cluster disruption (such as a node being add/removed or a network
          disruption).
        kpi: false
        introduced: 4.3.1
      - name: total-bytes-disk
        location: Statistics
        cumulative: false
        removed: "3.9"
        description:
          "Total size of disk (bytes). Refer to the namespace level `device_total_bytes`
          stat as of 3.9."
        kpi: false
      - name: total-bytes-memory
        location: Statistics
        cumulative: false
        removed: "3.9"
        description:
          "Total Size of memory (bytes). Refer to the `memory-size` configuration
          parameter."
        kpi: false
      - name: transactions
        location: Statistics
        cumulative: true
        removed: "3.9"
        description:
          "Total number of transactions executed by this node -- includes all
          reads, writes, and info commands."
        kpi: false
      - name: tree_count
        location: Statistics
        cumulative: false
        removed: "3.9"
        description: "Number of index trees currently active in the node"
        kpi: false
      - name: tree_gc_queue
        location: Statistics
        cumulative: false
        introduced: "3.10"
        description: |
          This is the number of trees queued up, ready to be completely removed (partitions drop).
          Corresponds to the `tree-gc-q` entry in the log ticker.
        kpi: false
      - name: tscan_aborted
        location: Statistics
        cumulative: true
        removed: "Yes"
        description: "Number of scans that were aborted. Removed as of 3.6.0."
        kpi: false
      - name: tscan_initiate
        location: Statistics
        cumulative: true
        removed: "Yes"
        description: "Number of new scan requests initiated. Removed as of 3.6.0."
        kpi: false
      - name: tscan_pending
        location: Statistics
        cumulative: false
        removed: "Yes"
        description: "Number of scan requests pending. Removed as of 3.6.0."
        kpi: false
      - name: tscan_succeeded
        location: Statistics
        cumulative: true
        removed: "Yes"
        description:
          "Number of scan requests that have successfully finished. Removed
          as of 3.6.0."
        kpi: false
      - name: tsvc_queue
        location: Statistics
        cumulative: false
        introduced: "3.9"
        description: |
          Number of pending requests waiting to execute in the transaction queue. An increase in this metric
          would indicate that the server is not keeping up with the workload, typically due to a starving of
          transaction threads ([transaction-threads-per-queue](/docs/reference/configuration/#transaction-threads-per-queue)).
          A common cause would be high latencies on disk i/o. When picked up from the transaction queue,
          transactions are checked against the timeout (set by the client, or, if not set, configured under
          [transaction-max-ms](/docs/reference/configuration#transaction-max-ms)) and if over, will return a
          timeout and tick the [client_tsvc_timeout](/docs/reference/metrics/#client_tsvc_timeout) metric.
        kpi: false
      - name: udf_bg_scans_failed
        location: Statistics
        introduced: 3.6.0
        removed: "3.9"
        cumulative: true
        description: |
          Number of scan background udf jobs that failed.
          Moved to `scan_udf_bg_error` at the namespace level as of version 3.9.
      - name: udf_bg_scans_succeeded
        location: Statistics
        introduced: 3.6.0
        removed: "3.9"
        cumulative: true
        description: |
          Number of scan background udf jobs that completed.
          Moved to `scan_udf_bg_complete` at the namespace level as of version 3.9.
      - name: udf_delete_err_others
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: "Number of errors encountered during UDF delete."
        extra-note: |
          As of version 3.9, UDF related statistics have been moved to the namespace level
          and broken down as follows:<br>
          - the `client_udf_*` stats for the udf call itself.<br>
          - the `client_lang_*` stats for the underlying operation statuses.<br>
          As of version 4.5.1, stats for proxied udf calls are also included:<br>
          - the `from_proxy_udf_*` stats for proxied udf calls themselves.<br>
          - the `from_proxy_lang_*` stats for the underlying operation statuses for proxied udf calls.<br>
          Similarly, for scan background udf and query background udf jobs:<br>
          - the `scan_udf_bg_abort/complete/error` and `query_udf_bg_success/failure` for the overall job.<br>
          - the `udf_sub_udf_*` stats for the udf calls triggered by those jobs.<br>
          - the `udf_sub_lang_*` stats for the underlying operation statuses of the udf calls triggered by those jobs.
        kpi: false
      - name: udf_delete_reqs
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of UDF delete requests attempted.
          Refer to the new stats breakdown at the namespace level as of version 3.9:
          `client_lang_delete_success` and `client_lang_error/timeout` for the underlying operation
          itself and `client_udf_*` for the udf call itself.
        extra-note: |
          As of version 3.9, UDF related statistics have been moved to the namespace level
          and broken down as follows:<br>
          - the `client_udf_*` stats for the udf call itself.<br>
          - the `client_lang_*` stats for the underlying operation statuses.<br>
          As of version 4.5.1, stats for proxied udf calls are also included:<br>
          - the `from_proxy_udf_*` stats for proxied udf calls themselves.<br>
          - the `from_proxy_lang_*` stats for the underlying operation statuses for proxied udf calls.<br>
          Similarly, for scan background udf and query background udf jobs:<br>
          - the `scan_udf_bg_abort/complete/error` and `query_udf_bg_success/failure` for the overall job.<br>
          - the `udf_sub_udf_*` stats for the udf calls triggered by those jobs.<br>
          - the `udf_sub_lang_*` stats for the underlying operation statuses of the udf calls triggered by those jobs.
        kpi: false
      - name: udf_delete_success
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of successful UDF delete operations.
          Refer to `client_lang_delete_success` at the namespace level as of version 3.9.
        extra-note: |
          As of version 3.9, UDF related statistics have been moved to the namespace level
          and broken down as follows:<br>
          - the `client_udf_*` stats for the udf call itself.<br>
          - the `client_lang_*` stats for the underlying operation statuses.<br>
          As of version 4.5.1, stats for proxied udf calls are also included:<br>
          - the `from_proxy_udf_*` stats for proxied udf calls themselves.<br>
          - the `from_proxy_lang_*` stats for the underlying operation statuses for proxied udf calls.<br>
          Similarly, for scan background udf and query background udf jobs:<br>
          - the `scan_udf_bg_abort/complete/error` and `query_udf_bg_success/failure` for the overall job.<br>
          - the `udf_sub_udf_*` stats for the udf calls triggered by those jobs.<br>
          - the `udf_sub_lang_*` stats for the underlying operation statuses of the udf calls triggered by those jobs.
        kpi: false
      - name: udf_lua_errs
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of overall Lua errors.
          Refer to statistic `client_lang_error` at the namespace level as of version 3.9.
        extra-note: |
          As of version 3.9, UDF related statistics have been moved to the namespace level
          and broken down as follows:<br>
          - the `client_udf_*` stats for the udf call itself.<br>
          - the `client_lang_*` stats for the underlying operation statuses.<br>
          As of version 4.5.1, stats for proxied udf calls are also included:<br>
          - the `from_proxy_udf_*` stats for proxied udf calls themselves.<br>
          - the `from_proxy_lang_*` stats for the underlying operation statuses for proxied udf calls.<br>
          Similarly, for scan background udf and query background udf jobs:<br>
          - the `scan_udf_bg_abort/complete/error` and `query_udf_bg_success/failure` for the overall job.<br>
          - the `udf_sub_udf_*` stats for the udf calls triggered by those jobs.<br>
          - the `udf_sub_lang_*` stats for the underlying operation statuses of the udf calls triggered by those jobs.
        kpi: false
      - name: udf_query_rec_reqs
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of record UDF calls in a query background udf job.
          Refer to `query_udf_bg_success` and `query_udf_bg_failure` at the namespace level as of version 3.9.
        extra-note: |
          As of version 3.9, UDF related statistics for scan background udf and query background udf jobs
          have been moved to the namespace level and broken down as follows:<br>
          - the `scan_udf_bg_abort/complete/error` and `query_udf_bg_success/failure` for the overall job.<br>
          - the `udf_sub_udf_*` stats for the udf calls triggered by those jobs.<br>
          - the `udf_sub_lang_*` stats for the underlying operation statuses of the udf calls triggered by those jobs.
        kpi: false
      - name: udf_read_errs_other
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: "Number of unsuccessful UDF read operations."
        extra-note: |
          As of version 3.9, UDF related statistics have been moved to the namespace level
          and broken down as follows:<br>
          - the `client_udf_*` stats for the udf call itself.<br>
          - the `client_lang_*` stats for the underlying operation statuses.<br>
          As of version 4.5.1, stats for proxied udf calls are also included:<br>
          - the `from_proxy_udf_*` stats for proxied udf calls themselves.<br>
          - the `from_proxy_lang_*` stats for the underlying operation statuses for proxied udf calls.<br>
          Similarly, for scan background udf and query background udf jobs:<br>
          - the `scan_udf_bg_abort/complete/error` and `query_udf_bg_success/failure` for the overall job.<br>
          - the `udf_sub_udf_*` stats for the udf calls triggered by those jobs.<br>
          - the `udf_sub_lang_*` stats for the underlying operation statuses of the udf calls triggered by those jobs.
        kpi: false
      - name: udf_read_reqs
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of UDF read requests attempted.
          Refer to the new stats breakdown at the namespace level as of version 3.9:
          `client_lang_read_success` and `client_lang_error/timeout` for the underlying operation
          itself and `client_udf_*` for the udf call itself.
        extra-note: |
          As of version 3.9, UDF related statistics have been moved to the namespace level
          and broken down as follows:<br>
          - the `client_udf_*` stats for the udf call itself.<br>
          - the `client_lang_*` stats for the underlying operation statuses.<br>
          As of version 4.5.1, stats for proxied udf calls are also included:<br>
          - the `from_proxy_udf_*` stats for proxied udf calls themselves.<br>
          - the `from_proxy_lang_*` stats for the underlying operation statuses for proxied udf calls.<br>
          Similarly, for scan background udf and query background udf jobs:<br>
          - the `scan_udf_bg_abort/complete/error` and `query_udf_bg_success/failure` for the overall job.<br>
          - the `udf_sub_udf_*` stats for the udf calls triggered by those jobs.<br>
          - the `udf_sub_lang_*` stats for the underlying operation statuses of the udf calls triggered by those jobs.
        kpi: false
      - name: udf_read_success
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of successful UDF read operations.
          Refer to the `client_lang_read_success` stat at the namespace level as of version 3.9.
        extra-note: |
          As of version 3.9, UDF related statistics have been moved to the namespace level
          and broken down as follows:<br>
          - the `client_udf_*` stats for the udf call itself.<br>
          - the `client_lang_*` stats for the underlying operation statuses.<br>
          As of version 4.5.1, stats for proxied udf calls are also included:<br>
          - the `from_proxy_udf_*` stats for proxied udf calls themselves.<br>
          - the `from_proxy_lang_*` stats for the underlying operation statuses for proxied udf calls.<br>
          Similarly, for scan background udf and query background udf jobs:<br>
          - the `scan_udf_bg_abort/complete/error` and `query_udf_bg_success/failure` for the overall job.<br>
          - the `udf_sub_udf_*` stats for the udf calls triggered by those jobs.<br>
          - the `udf_sub_lang_*` stats for the underlying operation statuses of the udf calls triggered by those jobs.
        kpi: false
      - name: udf_replica_writes
        location: Statistics
        cumulative: true
        removed: "3.9"
        description:
          "Number of UDF replica writes. This statistic is not reported anymore
          as of version 3.9."
        kpi: false
      - name: udf_scan_rec_reqs
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of record UDF calls in a scan background udf job.
          Refer to `scan_udf_bg_complete`, `scan_udf_bg_abort` and `scan_udf_bg_error` at the namespace level as of version 3.9.
        extra-note: |
          As of version 3.9, UDF related statistics for scan background udf and query background udf jobs
          have been moved to the namespace level and broken down as follows:<br>
          - the `scan_udf_bg_abort/complete/error` and `query_udf_bg_success/failure` for the overall job.<br>
          - the `udf_sub_udf_*` stats for the udf calls triggered by those jobs.<br>
          - the `udf_sub_lang_*` stats for the underlying operation statuses of the udf calls triggered by those jobs.
        kpi: false
      - name: udf_write_err_others
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: "Number of unsuccessful UDF write operations."
        extra-note: |
          As of version 3.9, UDF related statistics have been moved to the namespace level
          and broken down as follows:<br>
          - the `client_udf_*` stats for the udf call itself.<br>
          - the `client_lang_*` stats for the underlying operation statuses.<br>
          As of version 4.5.1, stats for proxied udf calls are also included:<br>
          - the `from_proxy_udf_*` stats for proxied udf calls themselves.<br>
          - the `from_proxy_lang_*` stats for the underlying operation statuses for proxied udf calls.<br>
          Similarly, for scan background udf and query background udf jobs:<br>
          - the `scan_udf_bg_abort/complete/error` and `query_udf_bg_success/failure` for the overall job.<br>
          - the `udf_sub_udf_*` stats for the udf calls triggered by those jobs.<br>
          - the `udf_sub_lang_*` stats for the underlying operation statuses of the udf calls triggered by those jobs.
        kpi: false
      - name: udf_write_reqs
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of UDF write requests attempted.
          Refer to the new stats breakdown at the namespace level as of version 3.9:
          `client_lang_write_success` and `client_lang_error/timeout` for the underlying operation
          itself and `client_udf_*` for the udf call itself.
        extra-note: |
          As of version 3.9, UDF related statistics have been moved to the namespace level
          and broken down as follows:<br>
          - the `client_udf_*` stats for the udf call itself.<br>
          - the `client_lang_*` stats for the underlying operation statuses.<br>
          As of version 4.5.1, stats for proxied udf calls are also included:<br>
          - the `from_proxy_udf_*` stats for proxied udf calls themselves.<br>
          - the `from_proxy_lang_*` stats for the underlying operation statuses for proxied udf calls.<br>
          Similarly, for scan background udf and query background udf jobs:<br>
          - the `scan_udf_bg_abort/complete/error` and `query_udf_bg_success/failure` for the overall job.<br>
          - the `udf_sub_udf_*` stats for the udf calls triggered by those jobs.<br>
          - the `udf_sub_lang_*` stats for the underlying operation statuses of the udf calls triggered by those jobs.
        kpi: false
      - name: udf_write_success
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: |
          Number of successful UDF write operations.
          Refer to the `client_lang_write_success` stat at the namespace level as of version 3.9.
        extra-note: |
          As of version 3.9, UDF related statistics have been moved to the namespace level
          and broken down as follows:<br>
          - the `client_udf_*` stats for the udf call itself.<br>
          - the `client_lang_*` stats for the underlying operation statuses.<br>
          As of version 4.5.1, stats for proxied udf calls are also included:<br>
          - the `from_proxy_udf_*` stats for proxied udf calls themselves.<br>
          - the `from_proxy_lang_*` stats for the underlying operation statuses for proxied udf calls.<br>
          Similarly, for scan background udf and query background udf jobs:<br>
          - the `scan_udf_bg_abort/complete/error` and `query_udf_bg_success/failure` for the overall job.<br>
          - the `udf_sub_udf_*` stats for the udf calls triggered by those jobs.<br>
          - the `udf_sub_lang_*` stats for the underlying operation statuses of the udf calls triggered by those jobs.
        kpi: false
      - name: uptime
        location: Statistics
        cumulative: false
        description: "Time in seconds since last server restart."
        kpi: false
        category: Service
        usage: |
          **IF** `uptime` is below 300 and the cluster is not undergoing maintenance
          **THEN** This node restarted within the last 5 minutes, operations
          investigate.
      - name: used-bytes-disk
        location: Statistics
        cumulative: false
        removed: "3.9"
        description:
          "Size of disk in use measured in bytes. Refer to `device_used_bytes`
          at the namespace level as of version 3.9."
        kpi: false
        category: Trend
        usage: |
          Trending provides operations insight into how `used-bytes-disk` changes
          over time.
      - name: used-bytes-memory
        location: Statistics
        cumulative: false
        removed: "3.9"
        description:
          "Size of memory in use measured in bytes. Refer to `memory_used_bytes`
          at the namespace level as of version 3.9."
        kpi: false
      - name: waiting_transactions
        location: Statistics
        cumulative: false
        removed: "3.9"
        description: "Number of read/write transactions currently queued."
        kpi: false
      - name: write_master
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: "Number of master writes performed by this node."
        kpi: false
      - name: write_prole
        location: Statistics
        cumulative: true
        removed: "3.9"
        description: "Number of prole (replica) writes performed by this node."
        kpi: false
  - location: Namespace
    metrics:
      - name: geo_region_query_count
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Num of geo queries on the system since the uptime of the node."
      - name: geo_region_query_cells
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Num of cell coverings for query region queried."
      - name: geo_region_query_points
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description:
          "Num of points results that's within-region, geo_region_query_points
          + geo_region_query_falsepos would be the total query result points."
      - name: geo_region_query_falsepos
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description:
          "Num of points results that's outside-region, geo_region_query_points
          + geo_region_query_falsepos would be the total query result points."
      - name: appeals_records_exonerated
        location: Namespace
        ee-only: true
        cumulative: true
        introduced: "4.0"
        description: |
          Number of records that were marked replicated as result of an appeal.
          Partition appeals will happen for namespaces operating under the
          [`strong-consistency`](/docs/reference/configuration#strong-consistency) mode when a node
          needs to validate the records it has when joining the cluster.
        kpi: false
      - name: appeals_rx_active
        location: Namespace
        ee-only: true
        cumulative: false
        introduced: "4.0"
        description: |
          Number of partition appeals currently being received. Partition appeals will happen for namespaces operating under the
          [`strong-consistency`](/docs/reference/configuration#strong-consistency) mode when a node
          needs to validate the records it has when joining the cluster.
        kpi: false
      - name: appeals_tx_active
        location: Namespace
        ee-only: true
        cumulative: false
        introduced: "4.0"
        description: |
          Number of partition appeals not yet sent. Partition appeals will happen for namespaces operating under the
          [`strong-consistency`](/docs/reference/configuration#strong-consistency) mode when a node
          needs to validate the records it has when joining the cluster.
        kpi: false
      - name: appeals_tx_remaining
        location: Namespace
        ee-only: true
        cumulative: false
        introduced: "4.0"
        description: |
          Number of partition appeals currently being sent. Partition appeals will happen for namespaces operating under the
          [`strong-consistency`](/docs/reference/configuration#strong-consistency) mode when a node
          needs to validate the records it has when joining the cluster. Appeals occur after a node has been cold-started.
          The replication state of each record is lost on cold-start and all records must assume an unreplicated state.
          An appeal resolves replication state from the partition's acting master. These are important for performance;
          an unreplicated record will need to re-replicate to be read which adds latency. During a rolling cold-restart,
          an operator may want to wait for the appeal phase to complete after each restart to minimize the performance impact of the procedure.
        kpi: false
      - name: available-bin-names
        location: Namespace
        cumulative: false
        removed: "3.9"
        description: |
          Remaining number of unique bins that the user can create for this namespace.
          Replaced with `available_bin_names` as of version 3.9.
        kpi: false
      - name: available_bin_names
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description:
          "Remaining number of unique bins that the user can create for this
          namespace."
        kpi: false
      - name: available_pct
        location: Namespace
        cumulative: false
        removed: "3.9"
        description: |
          Measures the minimum contiguous disk space for all disks in a namespace.
          Replaced by [`device_available_pct`](/docs/reference/metrics/#device_available_pct) as of version 3.9.
        kpi: false
        category: Storage
        usage: |
          **IF** `available_pct` drops below 20% **THEN** may indicate that defrag
          is unable to keep up with the current load, warn operations

          **IF** `available_pct` drops below 15% **THEN** critical alert to
          operations, usable disk resources are critically low may result in a
          *stop-writes* if situation if `available_pct` drops below 5%.
      - name        : "device_compression_ratio"
        location    : "Namespace"
        ee-only     : true
        cumulative  : false
        introduced  : "4.5.0.1"
        description : |
          Measures the average *compressed size* to *uncompressed size* ratio. Thus `1.000` indicates no compression and `0.100` indicates a `1:10` 
          compression ratio (90% reduction is size). Note that `device_compression_ratio` will not be included if the 
          `compression` configuration parameter is set to `none`.
        detail      : |
          The compression ratio is a moving average. It is calculated based on the most recently written records. 
          Read records do not factor into the ratio. If the written data changes over time then the compression ratio 
          will change with it. In case of a sudden change in data, the indicated compression ratio may lag behind a bit. 
          As a rule of thumb, assume that the compression ratio covers the most recently written 100,000 to 1,000,000 records.
        kpi         : false
        category    : "Storage"
      - name: batch_sub_proxy_complete
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of proxied batch-index sub transactions that completed."
        kpi: false
      - name: batch_sub_proxy_error
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description:
          "Number of proxied batch-index sub transactions that failed with
          an error."
        kpi: false
      - name: batch_sub_proxy_timeout
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of proxied batch-index sub transactions that timed out."
        kpi: false
      - name: batch_sub_read_error
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of batch-index read sub transaction that failed with an error."
        kpi: false
      - name: batch_sub_read_not_found
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description:
          "Number of batch-index read sub transaction that resulted in not
          found."
        kpi: false
      - name: batch_sub_read_success
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of records successfully read by batch-index sub transactions."
        kpi: false
      - name: batch_sub_read_timeout
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of batch-index read sub transactions that timed out."
        kpi: false
      - name: batch_sub_tsvc_error
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description:
          "Number of batch-index read sub transactions that failed with an
          error in the transaction service,\nbefore attempting to handle the transaction.
          For example protocol errors or security permission mismatch. \nIn [`strong-consistency`](/docs/reference/configuration/#strong-consistency)
          enabled namespaces, this will \ninclude transactions against [`unavailable_partitions`](/docs/reference/metrics/?show-removed=1#unavailable_partitions)
          and \n[`dead_partitions`](/docs/reference/metrics/?show-removed=1#dead_partitions).\n"
        kpi: false
      - name: batch_sub_tsvc_timeout
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: |
          Number of batch-index read sub transactions that timed out in the transaction service,
          before attempting to handle the transaction.
        kpi: false
      - name: cache-read-pct
        location: Namespace
        cumulative: false
        removed: "3.9"
        description: |
          Percentage of read transactions that are hitting the post write queue and will save an io to
          the underlying storage device. Replaced by `cache_read_pct` as of version 3.9.
        kpi: false
      - name: cache_read_pct
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description:
          "Percentage of read transactions that are hitting the post write
          queue and will save an io to\nthe underlying storage device.\nRefer to the [`post-write-queue`](/docs/reference/configuration/#post-write-queue)
          and \n[`read-page-cache`](/docs/reference/configuration/#read-page-cache) configuration
          parameters\nfor ways to improve read intensive workloads latency by leveraging
          those 2 different \ncaching options.\n"
        kpi: false
      - name: client_delete_error
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of client delete transactions that failed with an error."
        kpi: false
      - name: client_delete_not_found
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of client delete transactions that resulted in a not found."
        kpi: false
      - name: client_delete_success
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of successful client delete transactions."
        kpi: false
      - name: client_delete_timeout
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of client delete transactions that timed out."
        kpi: false
      - name: client_lang_delete_success
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description:
          "Number of client initiated udf transactions that successfully deleted
          a record."
        kpi: false
      - name: client_lang_error
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: |
          Number of client initiated udf transactions that failed with a language (Lua) error during
          udf execution.
        kpi: false
      - name: client_lang_read_success
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of successful client initiated udf read transactions."
        kpi: false
      - name: client_lang_write_success
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of successful client initiated udf write transactions."
        kpi: false
      - name: client_proxy_complete
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of completed proxy transactions initiated by a client request."
        kpi: false
      - name: client_proxy_error
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description:
          "Number of proxy transactions initiated by a client request that
          failed with an error."
        kpi: false
      - name: client_proxy_timeout
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description:
          "Number of proxy transactions initiated by a client request that
          timed out."
        kpi: false
      - name: client_read_error
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of client read transaction errors."
        kpi: false
      - name: client_read_not_found
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of client read transaction that resulted in not found."
        kpi: false
      - name: client_read_success
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: |
          Number of successful client read transactions. Does not include records
          read by batch-reads, which have the separate [`batch_sub_read_success`](/docs/reference/metrics/#batch_sub_read_success)
          metric.
        kpi: false
      - name: client_read_timeout
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of client read transaction that timed out."
        kpi: false
      - name: client_tsvc_error
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description:
          "Number of client transactions that failed in the transaction service,\nbefore
          attempting to handle the transaction. For example protocol errors or security
          permission mismatch. \nIn [`strong-consistency`](/docs/reference/configuration/#strong-consistency)
          enabled namespaces, this will \ninclude transactions against [`unavailable_partitions`](/docs/reference/metrics/?show-removed=1#unavailable_partitions)
          and \n[`dead_partitions`](/docs/reference/metrics/?show-removed=1#dead_partitions).\n"
        kpi: false
      - name: client_tsvc_timeout
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: |
          Number of client transactions that timed out while in the transaction service,
          before attempting to handle the transaction. At this stage the transaction has
          not yet been identified as a read or a write, but the namespace is known. Likely
          cause is a congestion in the transaction queue (transaction threads not able to
          process efficiently enough), or it could also be that the timeout set by the
          client is too aggressive.
        kpi: false
      - name: client_udf_complete
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of completed udf transactions initiated by the client."
        kpi: false
      - name: client_udf_error
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: |
          Number of failed udf transactions initiated by the client. Does not include
          timeouts. See the server log file for more information about the error.
          Note that the error is also returned to the client.
        kpi: false
      - name: client_udf_timeout
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: |
          Number of udf transactions initiated by the client that timed out.
          The timeout error is returned to the client.
        kpi: false
      - name: client_write_error
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: |
          Number of client write transactions that failed with an error. Would include
          common errors like [`fail_generation`](/docs/reference/metrics#fail_generation),
          [`fail_key_busy`](/docs/reference/metrics#fail_key_busy), [`fail_record_too_big`](/docs/reference/metrics#fail_record_too_big),
          [`fail_xdr_forbidden`](/docs/reference/metrics#fail_xdr_forbidden) as well as some other less common ones.
          Refer to [this article](https://discuss.aerospike.com/t/understanding-client-write-errors/4442)
          for further details on the type of errors that will increment this statistic.
        kpi: false
      - name: client_write_success
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of successful client write transactions. This includes [`xdr_write_success`](/docs/reference/metrics#xdr_write_success)."
        kpi: false
      - name: client_write_timeout
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of client write transactions that timed out."
        kpi: false
      - name: clock_skew_stop_writes
        location: Namespace
        ee-only: false
        cumulative: false
        introduced: "4.0"
        description: |
          Will be true if clock skew is outside of tolerance for strong-consistency.<BR>
          This new methodology has a somewhat stronger dependence on clocks being synchronized across nodes in a cluster.<BR>
          As of Aerospike Server 4.5.1, for each [Available mode](/docs/architecture/consistency.html#available-mode) (AP) namespace where nsup is enabled
          (i.e. [`nsup-period`](/docs/reference/configuration/index.html#nsup-period) not zero) writes will be suspended if cluster clock skew exceeds 40 seconds.
        category: Service
        kpi: true
        usage:
          "**IF** [`clock_skew_stop_writes`](/docs/reference/metrics/#clock_skew_stop_writes)
          is true **THEN** critical alert to operations. \nEnsure clocks are in sync across
          the cluster.\n"
      - name: current-time
        location: Namespace
        cumulative: false
        removed: "3.9"
        description: "Current time represented as Aerospike epoch time."
        kpi: false
        category: Service
        usage: |
          **IF** the cluster_max(`current-time`) and cluster_min(`current-time`)
          differ by more than 10 seconds **THEN** critical alert to operations of
          the server time skew, may indicate that NTP or similar service is not
          running on this node.
      - name: current_time
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description: "Current time represented as Aerospike epoch time."
        kpi: false
        category: Service
        usage: |
          **IF** the cluster_max(`current_time`) and cluster_min(`current_time`)
          differ by more than 10 seconds **THEN** critical alert to operations of
          the server time skew, may indicate that NTP or similar service is not
          running on this node.
      - name: device_available_pct
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description: |
          Measures the minimum contiguous disk space across all devices in a namespace.
          Replaces `available_pct` as of version 3.9. The namespace will be read only
          (stop writes) if this value falls below [`min-avail-pct`](/docs/reference/configuration/#min-avail-pct).
          It is important for all configured devices in a namespace to have the same size,
          otherwise, the `device_available_pct` could be low even when a lot of space is available across
          other devices.
        detail: |
          Not to be confused with [`device_free_pct`](/docs/reference/metrics/#device_free_pct) which
          represents the amount of free space across all devices in a namespace and does not take account of the
          fragmentation.<br>
          Here is an example to represent the difference between [`device_free_pct`](/docs/reference/metrics/#device_free_pct) and
          [`device_available_pct`](/docs/reference/metrics/#device_available_pct). Let's assume 5 devices of 100MB each for a given namespace,
          where each device has 25MB of data that are spread across 50 write blocks (let's assume a 1MB write-block-size):<br>
          - The [`device_free_pct`](/docs/reference/metrics/#device_free_pct) would be 75%.
          - The [`device_available_pct`](/docs/reference/metrics/#device_available_pct) would be 50%.
          - If the distribution is not uniform (it usually is not perfectly uniform) the [`device_available_pct`](/docs/reference/metrics/#device_available_pct)
          would represent the device that has the least free blocks.
        kpi: true
        category: Storage
        usage: |
          **IF** [`device_available_pct`](/docs/reference/metrics/#device_available_pct) drops below 20% **THEN** may indicate that defrag
          is unable to keep up with the current load, warn operations.

          **IF** [`device_available_pct`](/docs/reference/metrics/#device_available_pct) drops below 15% **THEN** critical alert to
          operations, usable disk resources are critically low may result in a
          *stop-writes* if situation if [`device_available_pct`](/docs/reference/metrics/#device_available_pct) drops below 5%.
      - name: data-used-bytes-memory
        location: Namespace
        cumulative: false
        removed: "3.9"
        description:
          "Amount of memory occupied by data. Replaced with `memory_used_data_bytes`
          as of 3.9."
        kpi: false
      - name: dead_partitions
        location: Namespace
        ee-only: true
        cumulative: false
        introduced: "4.0"
        description: |
          Number of dead partitions for this namespace (when using [`strong-consistency`](/docs/reference/configuration#strong-consistency)).
          This is the number of partitions that are unavailable when all roster nodes are present.
          Will require the use of the [`revive`](/docs/reference/info#revive) command to make them available again.
        category: Service
        kpi: true
        usage:
          "**IF** [`dead_partitions`](/docs/reference/metrics/#dead_partitions) non
          0 **THEN** critical alert to operations. \nConsider issuing [`revive`](/docs/reference/info/#revive)
          and [`recluster`](/docs/reference/info/#recluster) commands \nif potential inconsistencies
          are known to not exist or acceptable to have.\n"
        extra-note:
          "A typical scenario where partitions would be marked as dead for a
          [`strong-consistency`](/docs/reference/configuration#strong-consistency) \nenabled
          namespace would be when a number of nodes greater than [`replication-factor`](/docs/reference/configuration/#replication-factor)
          are \ntaken out of the cluster without a clean shutdown, or have their storage
          erased (even if migrations complete between each node). Eventhough the \ndata
          is fully present in the cluter, the remaining nodes in the cluster wouldn't
          know whether the departed nodes potentially did accept \nany write transactions
          and therefore cannot guarantee the integrity of the partitions that had all
          their replicas across those nodes. \n<br><br>For example, for a replication
          factor 2 namespace configured as strong consistent on a 10 node cluster, shutting
          down one node, waiting for \nmigrations to complete, then shutting down a second
          node, erasing storage and bringing both nodes back in will result in approximately
          90 \npartitions [2x(4096/(10x9))] being marked as dead. Of course, invoking
          the [`revive`](/docs/reference/info#revive) and \n[`recluster`](/docs/reference/info#recluster)
          commands will provide 100% availability, and, in this particular case, no data
          inconsistencies.\n<br><br>Dead partitions will turn into [`unavailable_partitions`](/docs/reference/metrics/#unavailable_partitions)
          everytime the roster \nis not complete for a namespace.\n<br><br>Refer to the
          [Configuring Strong Consistency](/docs/operations/configure/consistency/index.html)
          and\n[Consistency Management](/docs/operations/manage/consistency/index.html)
          pages for further details.\n"
      - name: deleted_last_bin
        location: Namespace
        cumulative: true
        introduced: 3.9.1
        description: "Number of objects deleted because their last bin was deleted."
        kpi: false
      - name: device_free_pct
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description: |
          Percentage of disk capacity free for this namespace. This is the amount of free
          storage across all devices in the namespace. Evictions will be triggered when the used percentage across all devices
          (which is represented by 100 - [`device_free_pct`](/docs/reference/metrics/#device_free_pct))
          crosses the configured [`high-water-disk-pct`](/docs/reference/configuration/#high-water-disk-pct).
        detail: |
          Not to be confused with [`device_available_pct`](/docs/reference/metrics/#device_available_pct) which
          represents the amount of free contiguous space on the device that has the least contiguous free space across the namespace.<br>
          Here is an example to represent the difference between [`device_free_pct`](/docs/reference/metrics/#device_free_pct) and
          [`device_available_pct`](/docs/reference/metrics/#device_available_pct). Let's assume 5 devices of 100MB each for a given namespace,
          where each device has 25MB of data that are spread across 50 write blocks (let's assume a 1MB write-block-size):<br>
          - The [`device_free_pct`](/docs/reference/metrics/#device_free_pct) would be 75%.
          - The [`device_available_pct`](/docs/reference/metrics/#device_available_pct) would be 50%.
          - If the distribution is not uniform (it usually is not perfectly uniform) the [`device_available_pct`](/docs/reference/metrics/#device_available_pct)
          would represent the device that has the least free blocks.
        kpi: false
      - name: device_total_bytes
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description: "Total bytes of disk space allocated to this namespace on this node."
        kpi: false
      - name: device_used_bytes
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description: "Total bytes of disk space used by this namespace on this node."
        kpi: false
        category: Trend
        usage: |
          Trending `used-bytes-disk` provides operations insight into how disk usage
          changes over time for this namespace.
      - name: effective_replication_factor
        location: Namespace
        cumulative: false
        introduced: 3.15.1.3
        description: |
          The effective replication factor for the namespace. The configured namespace replication factor is
          returned as part of the namespace configuration under [`replication-factor`](/docs/reference/configuration/#replication-factor)
          for server versions 3.15.1.3 and above and under `repl-factor` for earlier versions. The effective replication
          factor is less than the set replication factor if the cluster size is smaller than the set replication factor (in which case
          the effective replication factor would match the cluster size) or
          if the [`paxos-single-replica-limit`](/docs/reference/configuration/#paxos-single-replica-limit) size is reached
          (in which case the effective replication factor is 1).
        kpi: false
      - name: evicted-objects
        location: Namespace
        cumulative: true
        removed: "3.9"
        description: |
          Number of objects evicted from this namespace on this node since the server started.
          Replaced with `evicted_objects` as of version 3.9.
        kpi: false
      - name: evicted_objects
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: |
          Number of objects evicted from this namespace on this node since the server
          started.
        kpi: false
      - name: evict_ttl
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description:
          "The current eviction depth, or the highest ttl of records that have
          been evicted, in seconds."
        kpi: false
      - name: evict_void_time
        location: Namespace
        cumulative: false
        introduced: 4.5.1
        description:
          "The current eviction depth, expressed as a void time in seconds
          since 1 January 2010 UTC."
        kpi: false
      - name: smd_evict_void_time
        location: Namespace
        cumulative: false
        introduced: 4.5.1
        description: |
          The cluster-wide specified eviction depth, expressed as a void time in seconds since 1 January 2010 UTC.
          This is distributed to all nodes via SMD.  This may be larger than evict_void_time -- evict_void_time
          will eventually advance to this value.
        kpi: false
      - name: expired-objects
        location: Namespace
        cumulative: true
        removed: "3.9"
        description: |
          Number of objects expired from this namespace on this node since the server started.
          Replaced with `expired_objects` as of version 3.9.
        kpi: false
      - name: expired_objects
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: |
          Number of objects expired from this namespace on this node since the server
          started.
        kpi: false
      - name: fail_generation
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: |
          Number of read/write transactions failed on generation check.
          Replaces `err_write_fail_generation` as of version 3.9.
        kpi: false
        category: Application
      - name: fail_key_busy
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: |
          Number of read/write transactions failed on 'hot keys', meaning there were already a number of transactions higher than
          [`transaction-pending-limit`](/docs/reference/configuration/#transaction-pending-limit) for the same record waiting in the
          rw-hash or [`rw_in_progress`](/docs/reference/metrics/#rw_in_progress). For read this can only happen when duplicate resolution
          is necessary. Replaces `err_rw_pending_limit` as of version 3.9.
        detail: |
          Detail level logging for the `rw` context will log transactions (digest) triggering this error. Read transactions
          would only fail
        kpi: false
        category: Application
        usage: |
          **IF** application is not expected to have hot keys and
          `fail_key_busy` rate of change exceeds expectations **THEN**
          may indicate an application issue.
      - name: fail_record_too_big
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: |
          Number of write transactions failed due to record too big (above the [`write-block-size`](/docs/reference/configuration#write-block-size) limit).
          Only counts client writes failures (on master side). Replaces `err_write_fail_record_too_big` as of version 3.9.
        detail: |
          Detail level logging for the `rw` context will log transactions (digest) triggering this error (originating from client side master writes).
          Enabling detail level logging for the `drv_ssd` context will log all attempts at writing records that are too big, including replica-writes,
          immigration (migrations) writes and applying duplicate resolution winners. Refer to the [FAQ - Write Block Size](https://discuss.aerospike.com/t/faq-write-block-size/681)
          knowledge base article for other details.
        kpi: false
        category: Application
      - name: fail_xdr_forbidden
        location: Namespace
        ee-only: true
        cumulative: true
        introduced: "3.9"
        description: |
          Number of read/write transactions failed due to configuration restriction. Error code 22 would be returned.
          This will count any of the traffic that would be rejected due to either:<br>
          - incoming xdr traffic (xdr-write stat) and [`allow-xdr-writes`](/docs/reference/configuration#allow-xdr-writes) set to false.<br>
          - non XDR write traffic and [`allow-nonxdr-writes`](/docs/reference/configuration#allow-nonxdr-writes) set to false.
        kpi: false
        category: Application
      - name: free-pct-disk
        location: Namespace
        cumulative: false
        removed: "3.9"
        description:
          "Percentage of disk capacity free for this namespace. Replaced with
          `device_free_pct` as of 3.9."
        kpi: false
      - name: free-pct-memory
        location: Namespace
        cumulative: false
        removed: "3.9"
        description:
          "Percentage of memory capacity free for this namespace. Replaced
          with `memory_free_pct` as of 3.9."
        kpi: false
      - name: from_proxy_tsvc_error
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of transactions proxied from another node that failed in the transaction service,
          before attempting to handle the transaction. For example protocol errors or security permission mismatch.
          In [`strong-consistency`](/docs/reference/configuration/#strong-consistency) enabled namespaces, this will
          include transactions against [`unavailable_partitions`](/docs/reference/metrics/?show-removed=1#unavailable_partitions) and
          [`dead_partitions`](/docs/reference/metrics/?show-removed=1#dead_partitions).
        kpi: false
      - name: from_proxy_tsvc_timeout
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of transactions proxied from another node that timed out while in the transaction service,
          before attempting to handle the transaction. At this stage the transaction has
          not yet been identified as a read or a write, but the namespace is known. Likely
          cause is a congestion in the transaction queue (transaction threads not able to
          process efficiently enough), or it could also be that the timeout set by the
          client is too aggressive.
        kpi: false
      - name: from_proxy_read_error
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description: "Number of errors for read transactions proxied from another node."
        kpi: false
      - name: from_proxy_read_not_found
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description:
          "Number of read transactions proxied from another node that resulted
          in not found."
        kpi: false
      - name: from_proxy_read_success
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description: "Number of successful read transactions proxied from another node."
        kpi: false
      - name: from_proxy_read_timeout
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description: "Number of timeouts for read transactions proxied from another node."
        kpi: false
      - name: from_proxy_write_error
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of errors for write transactions proxied from another node.
          This includes [`xdr_from_proxy_write_error`](/docs/reference/metrics#xdr_from_proxy_write_error).
        kpi: false
      - name: from_proxy_write_success
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of successful write transactions proxied from another node.
          This includes [`xdr_from_proxy_write_success`](/docs/reference/metrics#xdr_from_proxy_write_success).
        kpi: false
      - name: from_proxy_write_timeout
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of timeouts for write transactions proxied from another node.
          This includes [`xdr_from_proxy_write_timeout`](/docs/reference/metrics#xdr_from_proxy_write_timeout).
        kpi: false
      - name: xdr_from_proxy_write_error
        location: Namespace
        ee-only: true
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of errors for XDR write transactions proxied from another node.
          For the total number of XDR initiated write requests against
          this namespace on this node (destination node), add up the relevant XDR client and from_proxy statistics:
          `xdr_client_write_success`, `xdr_client_write_error`, `xdr_client_write_timeout`,
          `xdr_from_proxy_write_success`, `xdr_from_proxy_write_error`, `xdr_from_proxy_write_timeout`.
        kpi: false
      - name: xdr_from_proxy_write_success
        location: Namespace
        ee-only: true
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of successful XDR write transactions proxied from another node.
          For the total number of XDR initiated write requests against
          this namespace on this node (destination node), add up the relevant XDR client and from_proxy statistics:
          `xdr_client_write_success`, `xdr_client_write_error`, `xdr_client_write_timeout`,
          `xdr_from_proxy_write_success`, `xdr_from_proxy_write_error`, `xdr_from_proxy_write_timeout`.
        kpi: false
      - name: xdr_from_proxy_write_timeout
        location: Namespace
        ee-only: true
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of timeouts for XDR write transactions proxied from another node.
          For the total number of XDR initiated write requests against
          this namespace on this node (destination node), add up the relevant XDR client and from_proxy statistics:
          `xdr_client_write_success`, `xdr_client_write_error`, `xdr_client_write_timeout`,
          `xdr_from_proxy_write_success`, `xdr_from_proxy_write_error`, `xdr_from_proxy_write_timeout`.
        kpi: false
      - name: from_proxy_delete_error
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of errors for delete transactions proxied from another node.
          This includes [`xdr_from_proxy_delete_error`](/docs/reference/metrics#xdr_from_proxy_delete_error).
        kpi: false
      - name: from_proxy_delete_not_found
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of delete transactions proxied from another node that resulted in not found.
          This includes [`xdr_from_proxy_delete_not_found`](/docs/reference/metrics#xdr_from_proxy_delete_not_found).
        kpi: false
      - name: from_proxy_delete_success
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of successful delete transactions proxied from another node.
          This includes [`xdr_from_proxy_delete_success`](/docs/reference/metrics#xdr_from_proxy_delete_success).
        kpi: false
      - name: from_proxy_delete_timeout
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of timeouts for delete transactions proxied from another node.
          This includes [`xdr_from_proxy_delete_timeout`](/docs/reference/metrics#xdr_from_proxy_delete_timeout).
        kpi: false
      - name: xdr_from_proxy_delete_error
        location: Namespace
        ee-only: true
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of errors for XDR delete transactions proxied from another node.
          For the total number of XDR initiated delete requests against
          this namespace on this node (destination node), add up the relevant XDR client and from_proxy statistics:
          `xdr_client_delete_success`, `xdr_client_delete_error`, `xdr_client_delete_timeout`, `xdr_client_delete_not_found`,
          `xdr_from_proxy_delete_success`, `xdr_from_proxy_delete_error`, `xdr_from_proxy_delete_timeout`,
          `xdr_from_proxy_delete_not_found`.
        kpi: false
      - name: xdr_from_proxy_delete_not_found
        location: Namespace
        ee-only: true
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of XDR delete transactions proxied from another node that resulted in not found.
          For the total number of XDR initiated delete requests against
          this namespace on this node (destination node), add up the relevant XDR client and from_proxy statistics:
          `xdr_client_delete_success`, `xdr_client_delete_error`, `xdr_client_delete_timeout`, `xdr_client_delete_not_found`,
          `xdr_from_proxy_delete_success`, `xdr_from_proxy_delete_error`, `xdr_from_proxy_delete_timeout`,
          `xdr_from_proxy_delete_not_found`.
        kpi: false
      - name: xdr_from_proxy_delete_success
        location: Namespace
        ee-only: true
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of successful XDR delete transactions proxied from another node.
          For the total number of XDR initiated delete requests against
          this namespace on this node (destination node), add up the relevant XDR client and from_proxy statistics:
          `xdr_client_delete_success`, `xdr_client_delete_error`, `xdr_client_delete_timeout`, `xdr_client_delete_not_found`,
          `xdr_from_proxy_delete_success`, `xdr_from_proxy_delete_error`, `xdr_from_proxy_delete_timeout`,
          `xdr_from_proxy_delete_not_found`.
        kpi: false
      - name: xdr_from_proxy_delete_timeout
        location: Namespace
        ee-only: true
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of timeouts for XDR delete transactions proxied from another node.
          For the total number of XDR initiated delete requests against
          this namespace on this node (destination node), add up the relevant XDR client and from_proxy statistics:
          `xdr_client_delete_success`, `xdr_client_delete_error`, `xdr_client_delete_timeout`, `xdr_client_delete_not_found`,
          `xdr_from_proxy_delete_success`, `xdr_from_proxy_delete_error`, `xdr_from_proxy_delete_timeout`,
          `xdr_from_proxy_delete_not_found`.
        kpi: false
      - name: from_proxy_udf_complete
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description: "Number of successful udf transactions proxied from another node."
        kpi: false
      - name: from_proxy_udf_error
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description: "Number of errors for udf transactions proxied from another node."
        kpi: false
      - name: from_proxy_udf_timeout
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description: "Number of timeouts for udf transactions proxied from another node."
        kpi: false
      - name: from_proxy_lang_delete_success
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description:
          "Number of successful udf delete transactions proxied from another
          node."
        kpi: false
      - name: from_proxy_lang_error
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description:
          "Number of language (Lua) errors for udf transactions proxied from
          another node."
        kpi: false
      - name: from_proxy_lang_read_success
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description:
          "Number of successful udf read transactions proxied from another
          node."
        kpi: false
      - name: from_proxy_lang_write_success
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description:
          "Number of successful udf write transactions proxied from another
          node."
        kpi: false
      - name: from_proxy_batch_sub_read_error
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description:
          "Number of batch-index read sub transactions proxied from another
          node that failed with an error."
        kpi: false
      - name: from_proxy_batch_sub_read_not_found
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description:
          "Number of batch-index read sub transactions proxied from another
          node that resulted in not found."
        kpi: false
      - name: from_proxy_batch_sub_read_success
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description:
          "Number of records successfully read by batch-index sub transactions
          proxied from another node."
        kpi: false
      - name: from_proxy_batch_sub_read_timeout
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description:
          "Number of batch-index read sub transactions proxied from another
          node that timed out."
        kpi: false
      - name: from_proxy_batch_sub_tsvc_error
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of batch-index read sub transactions proxied from another node that failed with an error in the transaction service,
          before attempting to handle the transaction. For example, protocol errors or security permission mismatch.
          In [`strong-consistency`](/docs/reference/configuration/#strong-consistency) enabled namespaces, this will
          include transactions against [`unavailable_partitions`](/docs/reference/metrics/?show-removed=1#unavailable_partitions) and
          [`dead_partitions`](/docs/reference/metrics/?show-removed=1#dead_partitions).
        kpi: false
      - name: from_proxy_batch_sub_tsvc_timeout
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of batch-index read sub transactions proxied from another node that timed out in the transaction service,
          before attempting to handle the transaction.
        kpi: false
      - name: hwm-breached
        location: Namespace
        cumulative: false
        removed: "3.9"
        description: |
          If true, Aerospike has breached 'high-water-[disk|memory]-pct' for this namespace.
          Replaced with `hwm_breached` as of version 3.9.
        kpi: false
        category: Storage
        usage: |
          **IF** `hwm-breached` is true **THEN** alert operations that memory or
          disk resources are strained, may indicate need to increase cluster
          capacity.
      - name: hwm_breached
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description:
          "If true, Aerospike has breached 'high-water-[disk|memory]-pct'
          for this namespace."
        kpi: true
        category: Storage
        usage: |
          **IF** [`hwm_breached`](/docs/reference/metrics/#hwm_breached) is true **THEN** alert operations that memory or
          disk resources are strained, may indicate need to increase cluster
          capacity.
      - name: index-used-bytes-memory
        location: Namespace
        cumulative: false
        removed: "3.9"
        description:
          "Amount of memory occupied by the index for this namespace. Replaced
          with `memory_used_index_bytes` as of version 3.9."
        kpi: false
      - name: ldt_deletes
        location: Namespace
        cumulative: true
        description: "Number of LDT delete operations."
        kpi: false
      - name: ldt_delete_success
        location: Namespace
        cumulative: true
        description: "Number of successful LDT delete operations."
        kpi: false
      - name: ldt_errors
        location: Namespace
        cumulative: true
        description: "Number of LDT errors."
        kpi: false
      - name: ldt_reads
        location: Namespace
        cumulative: true
        description: "Number of LDT read operations."
        kpi: false
      - name: ldt_read_success
        location: Namespace
        cumulative: true
        description: "Number of successful LDT read operations."
        kpi: false
      - name: ldt_updates
        location: Namespace
        cumulative: true
        description: "Number of LDT update operations."
        kpi: false
      - name: ldt_writes
        location: Namespace
        cumulative: true
        description: "Number of LDT write operations."
        kpi: false
      - name: ldt_write_success
        location: Namespace
        cumulative: true
        description: "Number of successful LDT write operations."
        kpi: false
      - name: master-objects
        location: Namespace
        cumulative: false
        removed: "3.9"
        description: |
          Number of records on this node which are active masters.
          Replaced by `master_objects` as of version 3.9.
        kpi: false
      - name: master_objects
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description: "Number of records on this node which are active masters."
        kpi: false
      - name: master-sub-objects
        location: Namespace
        cumulative: false
        removed: "3.9"
        description: |
          Number of LDT sub-records on this node which are active masters.
          Replaced by `master_sub_objects` as of version 3.9.
        kpi: false
      - name: master_sub_objects
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description: "Number of LDT sub-records on this node which are active masters."
        kpi: false
      - name: master_tombstones
        location: Namespace
        ee-only: true
        cumulative: false
        introduced: "3.10"
        description: "Number of tombstones on this node which are active masters."
        kpi: false
      - name: max-evicted-ttl
        location: Namespace
        cumulative: false
        removed: "Yes"
        description: "The highest record TTL that Aerospike has evicted from this namespace."
        kpi: false
      - name: max-void-time
        location: Namespace
        cumulative: false
        removed: "3.9"
        description: |
          Maximum record TTL ever inserted into this namespace.
          Replaced by `max_void_time` as of version 3.9.
        kpi: false
      - name: max_void_time
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description: "Maximum record TTL ever inserted into this namespace."
        kpi: false
      - name: memory_free_pct
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description: "Percentage of memory capacity free for this namespace."
        kpi: false
      - name: memory_used_bytes
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description:
          "Total bytes of memory used by this namespace on this node. This
          is the metric that is used against the \n[`high-water-memory-pct`](/docs/reference/configuration/#high-water-memory-pct)
          and [`stop-writes-pct`](/docs/reference/configuration/#stop-writes-pct) \nthresholds.
          It represents the sum of the following 3 values:<br>\n[`memory_used_data_bytes`](/docs/reference/metrics/#memory_used_data_bytes)<br>\n[`memory_used_index_bytes`](/docs/reference/metrics/#memory_used_index_bytes)<br>\n[`memory_used_sindex_bytes`](/docs/reference/metrics/#memory_used_sindex_bytes)<br><br>\nRefer
          to [`heap_allocated_kbytes`](/docs/reference/metrics/#heap_allocated_kbytes)
          for the total amount of \nmemory allocated on a node (other than primary index
          shared memory in Enterprise Edition).\n"
        kpi: false
        category: Trend
        usage: |
          Trending `used-bytes-memory` provides operations insight into how memory
          usage changes over time for this namespace.
      - name: memory_used_data_bytes
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description:
          "Amount of memory occupied by data. Refer to [`memory_used_bytes`](/docs/reference/metrics/#memory_used_bytes)
          for the total \nmemory accounted for the namespace.\n"
        kpi: false
      - name: memory_used_index_bytes
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description:
          "Amount of memory occupied by the index for this namespace. This
          will be allocated in shared memory by default\n
          ([`index-type`](/docs/reference/configuration/#index-type) `shmem`)
          for the Enterprise Edition.
          <br>
          If your index is persisted, either in block storage
          ([`index-type`](/docs/reference/configuration/#index-type) `flash`, server 4.3 and above)
          or in persistent memory
          ([`index-type`](/docs/reference/configuration/#index-type) `pmem`, server 4.5 and above),
          refer instead to [`index_flash_used_bytes`](/docs/reference/metrics/#index_flash_used_bytes) or
          [`index_pmem_used_bytes`](/docs/reference/metrics/#index_pmem_used_bytes).\n
          For these persisted index configurations, the value of
          `memory_used_index_bytes` will be `0`.\n
          <br>
          Refer to [`memory_used_bytes`](/docs/reference/metrics/#memory_used_bytes)
          for the total \nmemory accounted for the namespace.\n"
        kpi: false
      - name: memory_used_sindex_bytes
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description:
          "Amount of memory occupied by secondary indexes for this namespace
          on this\nnode. Refer to [`memory_used_bytes`](/docs/reference/metrics/#memory_used_bytes)
          for the total \nmemory accounted for the namespace.\n"
        kpi: false
      - name: index_flash_used_bytes
        location: Namespace
        ee-only: true
        cumulative: false
        introduced: "4.3"
        description:
          "Applies only to Enterprise Version configured with [`index-type`](/docs/reference/configuration/#index-type)
          `flash`. \nTotal bytes in-use on the mount(s) for the primary index used by
          this namespace on this node.\nThis is the same value [`memory_used_index_bytes`](/docs/reference/metrics/#memory_used_index_bytes)
          \nwould have if the index were not persisted.\n"
        kpi: false
      - name: index_flash_used_pct
        location: Namespace
        ee-only: true
        cumulative: false
        introduced: "4.3"
        description:
          "Applies only to Enterprise Edition configured with [`index-type`](/docs/reference/configuration/#index-type)
          `flash`. \nPercentage of the mount(s) in-use for the primary index used by this
          namespace on this node.\nCalculated as ([`index_flash_used_bytes`](/docs/reference/metrics/#index_flash_used_bytes)
          / [`index-type.mounts-size-limit`](/docs/reference/configuration/#mounts-size-limit))
          * 100\n"
        kpi: false
      - name: index_pmem_used_bytes
        location: Namespace
        ee-only: true
        cumulative: false
        introduced: "4.5"
        description:
          "Applies only to Enterprise Version configured with [`index-type`](/docs/reference/configuration/#index-type)
          `pmem`. \nTotal bytes in-use on the mount(s) for the primary index used by
          this namespace on this node.\nThis is the same value [`memory_used_index_bytes`](/docs/reference/metrics/#memory_used_index_bytes)
          \nwould have if the index were not persisted.\n"
        kpi: false
      - name: index_pmem_used_pct
        location: Namespace
        ee-only: true
        cumulative: false
        introduced: "4.5"
        description:
          "Applies only to Enterprise Edition configured with [`index-type`](/docs/reference/configuration/#index-type)
          `pmem`. \nPercentage of the mount(s) in-use for the primary index used by this
          namespace on this node.\nCalculated as ([`index_pmem_used_bytes`](/docs/reference/metrics/#index_pmem_used_bytes)
          / [`index-type.mounts-size-limit`](/docs/reference/configuration/#mounts-size-limit))
          * 100\n"
        kpi: false
      - name: index-type.mount[ix].age
        location: Namespace
        ee-only: true
        cumulative: false
        introduced: "4.3"
        description:
          "Applies only to Enterprise Version configured to [`index-type`](/docs/reference/configuration/#index-type)
          `flash`. \nThis shows the percentage of lifetime (total usage) claimed by OEM
          for underlying device.\nValue will be -1 unless underlying device is NVMe and
          may exceed 100. 'ix' is the device index. For example, storage-engine.file[0]=/opt/aerospike/test0.dat\nand
          storage-engine.file[1]=/opt/aerospike/test2.dat for 2 files specified in the
          configuration.\n"
        kpi: false
      - name: storage-engine.device[ix].used_bytes
        location: Namespace
        cumulative: false
        introduced: "4.3"
        description: |
          Number of bytes used for data on device[ix]. 'ix' is the device index. For example, storage-engine.device[0]=/dev/xvd1
          and storage-engine.device[1]=/dev/xvc1 for 2 devices specified in the configuration.
        kpi: false
      - name: storage-engine.device[ix].free_wblocks
        location: Namespace
        cumulative: false
        introduced: "4.3"
        description: |
          Number of wblocks (write blocks) free on device[ix]. 'ix' is the device index. For example, storage-engine.device[0]=/dev/xvd1
          and storage-engine.device[1]=/dev/xvc1 for 2 devices specified in the configuration.
        kpi: false
      - name: storage-engine.device[ix].write_q
        location: Namespace
        cumulative: false
        introduced: "4.3"
        description: |
          Number of wblocks queued to be written to device[ix]. 'ix' is the device index. For example, storage-engine.device[0]=/dev/xvd1
          and storage-engine.device[1]=/dev/xvc1 for 2 devices specified in the configuration.
        kpi: false
      - name: storage-engine.device[ix].writes
        location: Namespace
        cumulative: true
        introduced: "4.3"
        description: |
          Number of wblocks written to device[ix] since Aerospike started. 'ix' is the device index. For example, storage-engine.device[0]=/dev/xvd1
          and storage-engine.device[1]=/dev/xvc1 for 2 devices specified in the configuration.
        kpi: false
      - name: storage-engine.device[ix].defrag_q
        location: Namespace
        cumulative: false
        introduced: "4.3"
        description: |
          Number of wblocks queued to be defragged on device[ix]. 'ix' is the device index. For example, storage-engine.device[0]=/dev/xvd1
          and storage-engine.device[1]=/dev/xvc1 for 2 devices specified in the configuration.
        kpi: false
      - name: storage-engine.device[ix].defrag_reads
        location: Namespace
        cumulative: true
        introduced: "4.3"
        description: |
          Number of wblocks defrag has read from device[ix]. 'ix' is the device index. For example, storage-engine.device[0]=/dev/xvd1
          and storage-engine.device[1]=/dev/xvc1 for 2 devices specified in the configuration.
        kpi: false
      - name: storage-engine.device[ix].defrag_writes
        location: Namespace
        cumulative: true
        introduced: "4.3"
        description: |
          Number of wblocks defrag has written to device[ix]. 'ix' is the device index. For example, storage-engine.device[0]=/dev/xvd1
          and storage-engine.device[1]=/dev/xvc1 for 2 devices specified in the configuration.
        kpi: false
      - name: storage-engine.device[ix].shadow_write_q
        location: Namespace
        cumulative: false
        introduced: "4.3"
        description: |
          Number of wblocks queued to be written to the shadow device of device[ix]. 'ix' is the device index. For example, storage-engine.device[0]=/dev/xvd1
          and storage-engine.device[1]=/dev/xvc1 for 2 devices specified in the configuration. This statistic is not available in the log ticker.
        kpi: false
      - name: storage-engine.device[ix].age
        location: Namespace
        cumulative: false
        introduced: "4.3"
        description:
          "Shows percentage of lifetime (total usage) claimed by OEM for underlying
          device (may exceed 100). Value will be -1 unless underlying device is NVMe.
          \n'ix' is the device index. For example, storage-engine.device[0]=/dev/xvd1\nand
          storage-engine.device[1]=/dev/xvc1 for 2 devices specified in the configuration.\n"
        kpi: false
      - name: storage-engine.file[ix].used_bytes
        location: Namespace
        cumulative: false
        introduced: "4.3"
        description: |
          Number of bytes used for data on file[ix]. 'ix' is the file index. For example, storage-engine.file[0]=/opt/aerospike/test0.dat
          and storage-engine.file[1]=/opt/aerospike/test2.dat for 2 files specified in the configuration.
        kpi: false
      - name: storage-engine.file[ix].free_wblocks
        location: Namespace
        cumulative: false
        introduced: "4.3"
        description: |
          Number of wblocks (write blocks) free on file[ix]. 'ix' is the file index. For example, storage-engine.file[0]=/opt/aerospike/test0.dat
          and storage-engine.file[1]=/opt/aerospike/test2.dat for 2 files specified in the configuration.
        kpi: false
      - name: storage-engine.file[ix].write_q
        location: Namespace
        cumulative: false
        introduced: "4.3"
        description: |
          Number of wblocks queued to be written to file[ix]. 'ix' is the file index. For example, storage-engine.file[0]=/opt/aerospike/test0.dat
          and storage-engine.file[1]=/opt/aerospike/test2.dat for 2 files specified in the configuration.
        kpi: false
      - name: storage-engine.file[ix].writes
        location: Namespace
        cumulative: true
        introduced: "4.3"
        description: |
          Number of wblocks written to file[ix] since Aerospike started. 'ix' is the file index. For example, storage-engine.file[0]=/opt/aerospike/test0.dat
          and storage-engine.file[1]=/opt/aerospike/test2.dat for 2 files specified in the configuration.
        kpi: false
      - name: storage-engine.file[ix].defrag_q
        location: Namespace
        cumulative: false
        introduced: "4.3"
        description: |
          Number of wblocks queued to be defragged on file[ix]. 'ix' is the file index. For example, storage-engine.file[0]=/opt/aerospike/test0.dat
          and storage-engine.file[1]=/opt/aerospike/test2.dat for 2 files specified in the configuration.
        kpi: false
      - name: storage-engine.file[ix].defrag_reads
        location: Namespace
        cumulative: true
        introduced: "4.3"
        description: |
          Number of wblocks defrag has read from file[ix]. 'ix' is the file index. For example, storage-engine.file[0]=/opt/aerospike/test0.dat
          and storage-engine.file[1]=/opt/aerospike/test2.dat for 2 files specified in the configuration.
        kpi: false
      - name: storage-engine.file[ix].defrag_writes
        location: Namespace
        cumulative: true
        introduced: "4.3"
        description: |
          Number of wblocks defrag has written to file[ix]. 'ix' is the file index. For example, storage-engine.file[0]=/opt/aerospike/test0.dat
          and storage-engine.file[1]=/opt/aerospike/test2.dat for 2 files specified in the configuration.
        kpi: false
      - name: storage-engine.file[ix].shadow_write_q
        location: Namespace
        cumulative: false
        introduced: "4.3"
        description: |
          Number of wblocks queued to be written to the shadow file of file[ix]. 'ix' is the file index. For example, storage-engine.file[0]=/opt/aerospike/test0.dat
          and storage-engine.file[1]=/opt/aerospike/test2.dat for 2 files specified in the configuration. This statistic is not available in the log ticker.
        kpi: false
      - name: storage-engine.file[ix].age
        location: Namespace
        cumulative: false
        introduced: "4.3"
        description:
          "Shows percentage of lifetime (total usage) claimed by OEM for underlying
          device. \nValue will be -1 unless underlying device is NVMe and may exceed 100.
          'ix' is the file index. \nFor example, storage-engine.file[0]=/opt/aerospike/test0.dat\nand
          storage-engine.file[1]=/opt/aerospike/test2.dat for 2 files specified in the
          configuration.\n"
        kpi: false
      - name: pending_quiesce
        location: Namespace
        ee-only: true
        cumulative: false
        description: |
          Reports 'true' when the [`quiesce`](/docs/reference/info/#quiesce) info
          command has been received by a node. When true, the next clustering event
          will cause this node to quiesce. To trigger a clustering event, issue the
          [`recluster`](/docs/reference/info/#recluster) info command. To disable,
          issue the [`quiesce-undo`](/docs/reference/info/#quiesce-undo) info
          command.
        kpi: false
        introduced: 4.3.1
      - name: effective_is_quiesced
        location: Namespace
        ee-only: true
        cumulative: false
        description: |
          Reports 'true' when the namespace has rebalanced after previously
          receiving a [`quiesce`](/docs/reference/info/#quiesce) info request.
        kpi: false
        introduced: 4.3.1
      - name: n_nodes_quiesced
        location: Namespace
        ee-only: true
        cumulative: false
        description:
          "Renamed to [`nodes_quiesced`](/docs/reference/metrics/#nodes_quiesced)
          as of version 4.4. \nThe number of nodes observed to be quiesced as of the most
          recent\nreclustering event. If a single node received the [`quiesce`](/docs/reference/info/#quiesce)
          \ncommand, on the subsequent reclustering event, all nodes will return 1 for
          this metric, \nand when the quiesced node is shutdown, triggering a new reclustering
          event, this metric will \nreturn to 0.\n"
        kpi: false
        introduced: 4.3.1
        removed: "4.4"
      - name: nodes_quiesced
        location: Namespace
        ee-only: true
        cumulative: false
        description:
          "The number of nodes observed to be quiesced as of the most recent\nreclustering
          event. If a single node received the [`quiesce`](/docs/reference/info/#quiesce)
          \ncommand, on the subsequent reclustering event, all nodes will return 1 for
          this metric, \nand when the quiesced node is shutdown, triggering a new reclustering
          event, this metric will \nreturn to 0.\n"
        kpi: false
        introduced: "4.4"
      - name: effective_prefer_uniform_balance
        location: Namespace
        ee-only: true
        cumulative: false
        introduced: "4.3"
        description:
          "Applies only to Enterprise Version. Value can be true or false.
          If Aerospike applied the uniform balance  \nalgorithm for the current cluster
          state, the value returned will be `true`. If any node having this namespace
          isn't\nconfigured with [`prefer-uniform-balance`](/docs/reference/configuration/#prefer-uniform-balance)
          `true`, \nthe value returned will be `false` and uniform balance algorithm will
          be disabled for this namespace on all participating nodes.\n"
        kpi: false
      - name: migrate-record-receives
        location: Namespace
        cumulative: true
        introduced: 3.8.3
        removed: "3.9"
        description: "Number of record insert request received by immigration."
        kpi: false
      - name: migrate_record_receives
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of record insert request received by immigration."
        kpi: false
      - name: migrate-record-retransmits
        location: Namespace
        cumulative: true
        introduced: 3.8.3
        removed: "3.9"
        description: "Number of times emigration has retransmitted records."
        kpi: false
      - name: migrate_record_retransmits
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of times emigration has retransmitted records."
        kpi: false
      - name: migrate-records-skipped
        location: Namespace
        ee-only: true
        cumulative: true
        introduced: 3.8.3
        removed: "3.9"
        description:
          "Number of times emigration did not ship a record because the remote
          node was already up-to-date."
        kpi: false
      - name: migrate_records_skipped
        location: Namespace
        ee-only: true
        cumulative: true
        introduced: "3.9"
        description:
          "Number of times emigration did not ship a record because the remote
          node was already up-to-date."
        kpi: false
      - name: migrate-records-transmitted
        location: Namespace
        cumulative: true
        introduced: 3.8.3
        removed: "3.9"
        description: "Number of records emigration has read and sent."
        kpi: false
      - name: migrate_records_transmitted
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of records emigration has read and sent."
        kpi: false
      - name: migrate-rx-instance-count
        location: Namespace
        cumulative: false
        introduced: 3.8.3
        removed: "3.9"
        description: |
          Replaced with `migrate_rx_instance_count` in version 3.9.
          Number of instance objects managing immigrations. Previous to version 3.8.3, this was called `migrate_rx_objs` and was under server statistics referring to
          number of partitions currently migrating to this node.
        kpi: false
      - name: migrate_rx_instance_count
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description: |
          Number of instance objects managing immigrations. Previous to version 3.8.3, this was called `migrate_rx_objs` and was under server statistics referring to
          number of partitions currently migrating to this node.
        kpi: false
      - name: migrate-rx-partitions-active
        location: Namespace
        cumulative: false
        introduced: 3.8.3
        removed: "3.9"
        description: |
          Replaced with `migrate_rx_partitions_active` in version 3.9.
          Number of partitions currently immigrating to this node. If `migrate-rx-partitions-active` is greater than 0 and cluster is not in
          maintenance, Operations needs to identify why migrations are running. Previous to version 3.8.3, this was called `migrate_progress_recv` and was under server statistics.
        kpi: false
      - name: migrate_rx_partitions_active
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description: |
          Number of partitions currently immigrating to this node. If `migrate_rx_partitions_active` is greater than 0 and cluster is not in
          maintenance, Operations needs to identify why migrations are running. Previous to version 3.8.3, this was called `migrate_progress_recv` and was under server statistics.
        kpi: false
      - name: migrate-rx-partitions-initial
        location: Namespace
        cumulative: false
        description: |
          Total number of migrations this node will receive during the current
          migration cycle for this namespace.
        kpi: false
        introduced: 3.7.0
        removed: "3.9"
      - name: migrate_rx_partitions_initial
        location: Namespace
        cumulative: false
        description: |
          Total number of migrations this node will receive during the current
          migration cycle for this namespace.
        kpi: false
        introduced: "3.9"
      - name: migrate-rx-partitions-remaining
        location: Namespace
        cumulative: false
        description: |
          Number of migrations this node has not yet received during the current
          migration cycle for this namespace.
        kpi: false
        introduced: 3.7.0
        removed: "3.9"
      - name: migrate_rx_partitions_remaining
        location: Namespace
        cumulative: false
        description: |
          Number of migrations this node has not yet received during the current
          migration cycle for this namespace.
        kpi: false
        introduced: "3.9"
      - name: migrate-tx-instance-count
        location: Namespace
        cumulative: false
        introduced: 3.8.3
        removed: "3.9"
        description: |
          Replaced with `migrate_tx_instance_count` in version 3.9.
          Number of instance objects managing emigrations. Previous to version 3.8.3, this was called `migrate_tx_objs` and was under server statistics referring to
          number of partitions pending migration out of this node.
        kpi: false
      - name: migrate_tx_instance_count
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description: |
          Number of instance objects managing emigrations. Previous to version 3.8.3, this was called `migrate_tx_objs` and was under server statistics referring to
          number of partitions pending migration out of this node.
        kpi: false
      - name: migrate-tx-partitions-active
        location: Namespace
        cumulative: false
        introduced: 3.8.3
        removed: "3.9"
        description: |
          Replaced with `migrate_tx_partitions_active` in version 3.9.
          Number of partitions currently emigrating from this node. If `migrate-tx-partitions-active` is greater than 0 and cluster is not in
          maintenance, Operations needs to identify why migrations are running. Previous to version 3.8.3, this was called `migrate_progress_send` and was under server statistics.
        kpi: false
      - name: migrate_tx_partitions_active
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description: |
          Number of partitions currently emigrating from this node. If `migrate_tx_partitions_active` is greater than 0 and cluster is not in
          maintenance, Operations needs to identify why migrations are running. Previous to version 3.8.3, this was called `migrate_progress_send` and was under server statistics.
        kpi: false
      - name: migrate-tx-partitions-imbalance
        location: Namespace
        cumulative: true
        description: |
          Number of partition migrations failures which could lead to partitions
          being imbalanced. For each increment there will also be a warning logged.
        kpi: false
        introduced: 3.7.0
        removed: "3.9"
      - name: migrate_tx_partitions_imbalance
        location: Namespace
        cumulative: true
        description: |
          Number of partition migrations failures which could lead to partitions
          being imbalanced. For each increment there will also be a warning logged.
        kpi: false
        introduced: "3.9"
      - name: migrate-tx-partitions-initial
        location: Namespace
        cumulative: false
        description: |
          Total number of migrations this node will send during the current
          migration cycle for this namespace.
        kpi: false
        introduced: 3.7.0
        removed: "3.9"
      - name: migrate_tx_partitions_initial
        location: Namespace
        cumulative: false
        description: |
          Total number of migrations this node will send during the current
          migration cycle for this namespace.
        kpi: false
        introduced: "3.9"
      - name: migrate_tx_partitions_lead_remaining
        location: Namespace
        ee-only: true
        cumulative: false
        description: |
          Number of initially scheduled emigrations which are not delayed by the
          [`migrate-fill-delay`](/docs/reference/configuration/#migrate-fill-delay)
          configuration. Lead migrations are typically delta-migrations addressing
          non-empty partition replica nodes. Delta-migrations generally consume
          far less storage IO.
        kpi: false
        introduced: 4.3.1
      - name: migrate-tx-partitions-remaining
        location: Namespace
        cumulative: false
        description: |
          Number of migrations this node not yet sent during the current
          migration cycle for this namespace.
        kpi: false
        introduced: 3.7.0
        removed: "3.9"
      - name: migrate_tx_partitions_remaining
        location: Namespace
        cumulative: false
        description: |
          Number of migrations this node not yet sent during the current
          migration cycle for this namespace.
        kpi: false
        introduced: "3.9"
      - name: migrate_signals_active
        location: Namespace
        cumulative: false
        description: |
          For finished partition migrations on this node, number of outstanding "clean-up" signals, sent to participating
          member nodes, waiting for clean-up acknowledgment. Signals are messages that are sent from a partition's master
          node to all other nodes that currently have data for the partition. The signals are used to notify all nodes
          that migrations have completed for this partitions and if they aren't a replica they can now drop the partition.
        kpi: false
        introduced: 3.13.0
      - name: migrate_signals_remaining
        location: Namespace
        cumulative: false
        description: |
          For unfinished partition migrations on this node, number of "clean-up" signals to send to participating
          member nodes, as migration completes. Signals are messages that are sent from a partition's master node
          to all other nodes that currently have data for the partition. The signals are used to notify all nodes
          that migrations have completed for this partitions and if they aren't a replica they can now drop the partition.
        kpi: false
        introduced: 3.13.0
      - name: min-evicted-ttl
        location: Namespace
        cumulative: false
        removed: 3.3.3
        description: "Minimum record TTL ever inserted into this namespace."
        kpi: false
      - name: non-expirable-objects
        location: Namespace
        cumulative: false
        removed: "3.9"
        description: |
          Number of records in this namespace with non-expirable TTLs (TTLs of
          value 0).
        kpi: false
      - name: non_expirable_objects
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description: |
          Number of records in this namespace with non-expirable TTLs (TTLs of
          value 0). Replaced by `non_expirable_objects` as of version 3.9.
        kpi: false
      - name: non_replica_objects
        location: Namespace
        cumulative: false
        introduced: "3.13"
        description: |
          Number of records on this node which are neither master nor replicas. This number is non-zero only during migration,
          representing additional versions or copies of records. Those are records beyond the replication factor line and would be
          potentially used during migrations to duplicate resolve.
        kpi: false
      - name: non_replica_tombstones
        location: Namespace
        ee-only: true
        cumulative: false
        introduced: "3.13"
        description:
          "Number of tombstones on this node which are neither master nor replicas.
          This number is non-zero only during migration."
        kpi: false
      - name: non_replica_sub_objects
        location: Namespace
        cumulative: false
        introduced: "3.13"
        description:
          "Number of LDT sub-records on this node which are neither master
          nor replicas. This number is non-zero only during migration."
        kpi: false
      - name: nsup-cycle-duration
        location: Namespace
        cumulative: false
        removed: "3.9"
        description:
          "Length in millisecond of the last nsup cycle. Replaced with `nsup_cycle_duration`
          as of version 3.9."
        kpi: false
      - name: nsup_cycle_duration
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description: "Length in millisecond of the last nsup cycle."
        kpi: false
      - name: nsup-cycle-sleep-pct
        location: Namespace
        cumulative: false
        removed: "3.9"
        description:
          "Percent time spent sleeping in the last nsup cycle. Replaced with
          `nsup_cycle_sleep_pct` as of version 3.9."
        kpi: false
      - name: nsup_cycle_sleep_pct
        location: Namespace
        cumulative: false
        introduced: "3.9"
        removed: 4.5.1
        description: "Percent time spent sleeping in the last nsup cycle."
        kpi: false
      - name: objects
        location: Namespace
        cumulative: false
        description:
          "Number of records in this namespace for this node. Does not include
          tombstones."
        kpi: false
        category: Trend
        usage: |
          Trending `objects` provides operations insight into this namespace's
          record fluctuations over time.
      - name: prole-objects
        location: Namespace
        cumulative: false
        removed: "3.9"
        description: |
          Number of records on this node which are proles (replicas) on this node.
          Replaced by `prole_objects` as of version 3.9.
        kpi: false
      - name: prole_objects
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description:
          "Number of records on this node which are proles (replicas) on this
          node. Does not include tombstones."
        kpi: false
      - name: prole_tombstones
        location: Namespace
        ee-only: true
        cumulative: false
        introduced: "3.10"
        description:
          "Number of tombstones on this node which are proles (replicas) on
          this node."
        kpi: false
      - name: prole-sub-objects
        location: Namespace
        cumulative: false
        removed: "3.9"
        description: |
          Number of LDT sub records on this node which are proles (replicas) on this node.
          Replaced by `prole_sub_objects` as of version 3.9.
        kpi: false
      - name: prole_sub_objects
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description:
          "Number of LDT sub records on this node which are proles (replicas)
          on this node."
        kpi: false
      - name: query_agg
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of query aggregations attempted on this node."
        kpi: false
      - name: query_agg_abort
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of query aggregations aborted by the user seen by this node."
        kpi: false
      - name: query_agg_avg_rec_count
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description:
          "Average number of records returned by the aggregations underlying
          query."
        kpi: false
      - name: query_agg_error
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of query aggregations errors due to an internal error."
        kpi: false
      - name: query_agg_success
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: |
          Number of query aggregations completed on this node.
          this node.
        kpi: false
      - name: query_fail
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: |
          Number of queries which failed due to an internal error. Those are failures
          not part of query lookup (see `query_lookup_error`), query aggregation
          (see `query_agg_error`) or query background udf (see `query_udf_bg_failure`).
        kpi: false
      - name: query_long_queue_full
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of long running queries queue full errors."
        kpi: false
      - name: query_long_reqs
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description: "Number of long running queries currently in process."
        kpi: false
      - name: query_lookup_abort
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of user aborted secondary index queries."
        kpi: false
      - name: query_lookup_avg_rec_count
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description:
          "Average number of records returned by all secondary index query
          look-ups."
        kpi: false
      - name: query_lookup_error
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of secondary index query look-up errors."
        kpi: false
      - name: query_lookup_success
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of secondary index look-ups which succeeded."
        kpi: false
      - name: query_lookups
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of secondary index lookups attempted on this node."
        kpi: false
      - name: query_reqs
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: |
          Number of query requests ever attempted on this node. Combines `query_agg` and `query_lookups`.
          Even very early failures would be
          counted here, as opposed to `query_short_running` and `query_long_running` which would
          increment a bit later.
        kpi: false
      - name: query_short_queue_full
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of short running queries queue full errors."
        kpi: false
      - name: query_short_reqs
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description: "Number of short running queries currently in process."
        kpi: false
      - name: query_udf_bg_failure
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of udf background queries that failed on this node."
        kpi: false
      - name: query_udf_bg_success
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of udf background queries that completed on this node."
        kpi: false
      - name: re_repl_error
        location: Namespace
        ee-only: true
        cumulative: true
        introduced: "4.0"
        description: |
          Number of re-replication errors which were not timeout.
          Re-replications would happen for namespaces operating under the
          [`strong-consistency`](/docs/reference/configuration#strong-consistency) mode when a record
          does not successfully replicate on the initial attempt.
        kpi: false
      - name: re_repl_success
        location: Namespace
        ee-only: true
        cumulative: true
        introduced: "4.0"
        description: |
          Number of successful re-replications.
          Re-replications would happen for namespaces operating under the
          [`strong-consistency`](/docs/reference/configuration#strong-consistency) mode when a record
          does not successfully replicate on the initial attempt.
        kpi: false
      - name: re_repl_timeout
        location: Namespace
        ee-only: true
        cumulative: true
        introduced: "4.0"
        description: |
          Number of re-replications that ended in timeout.
          Re-replications would happen for namespaces operating under the
          [`strong-consistency`](/docs/reference/configuration#strong-consistency) mode when a record
          does not successfully replicate on the initial attempt.
        kpi: false
      - name: retransmit_client_read_dup_res
        location: Namespace
        cumulative: true
        introduced: 3.10.1
        removed: 4.5.1
        description: |
          Number of retransmits that occurred during read transactions that were being duplicate resolved.
          Replaced with `retransmit_all_read_dup_res` as of version 4.5.1.
        kpi: false
      - name: retransmit_client_write_dup_res
        location: Namespace
        cumulative: true
        introduced: 3.10.1
        removed: 4.5.1
        description: |
          Number of retransmits that occurred during write transactions that were being duplicate resolved.
          Replaced with `retransmit_all_write_dup_res` as of version 4.5.1.
        kpi: false
      - name: retransmit_client_write_repl_write
        location: Namespace
        cumulative: true
        introduced: 3.10.1
        removed: 4.5.1
        description: |
          Number of retransmits that occurred during write transactions that were being replica written.
          Replaced with `retransmit_all_write_repl_write` as of version 4.5.1.
        kpi: false
      - name: retransmit_client_delete_dup_res
        location: Namespace
        cumulative: true
        introduced: 3.10.1
        removed: 4.5.1
        description: |
          Number of retransmits that occurred during delete transactions that were being duplicate resolved.
          Replaced with `retransmit_all_delete_dup_res` as of version 4.5.1.
        kpi: false
      - name: retransmit_client_delete_repl_write
        location: Namespace
        cumulative: true
        introduced: 3.10.1
        removed: 4.5.1
        description: |
          Number of retransmits that occurred during delete transactions that were being replica written.
          Replaced with `retransmit_all_delete_repl_write` as of version 4.5.1.
        kpi: false
      - name: retransmit_client_udf_dup_res
        location: Namespace
        cumulative: true
        introduced: 3.10.1
        removed: 4.5.1
        description: |
          Number of retransmits that occurred during client initiated udf transactions that were being duplicate resolved.
          Replaced with `retransmit_all_udf_dup_res` as of version 4.5.1.
        kpi: false
      - name: retransmit_client_udf_repl_write
        location: Namespace
        cumulative: true
        introduced: 3.10.1
        removed: 4.5.1
        description: |
          Number of retransmits that occurred during client initiated udf transactions that were being replica written.
          Replaced with `retransmit_all_udf_repl_write` as of version 4.5.1.
        kpi: false
      - name: retransmit_batch_sub_dup_res
        location: Namespace
        cumulative: true
        introduced: 3.10.1
        removed: 4.5.1
        description: |
          Number of retransmits that occurred during batch sub transactions that were being duplicate resolved.
          Replaced with `retransmit_all_batch_sub_dup_res` as of version 4.5.1.
        kpi: false
      - name: retransmit_all_read_dup_res
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of retransmits that occurred during read transactions that were being duplicate resolved.
          Note this includes retransmits originating on the client as well as proxying nodes.
        kpi: false
      - name: retransmit_all_write_dup_res
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of retransmits that occurred during write transactions that were being duplicate resolved.
          Note this includes retransmits originating on the client as well as proxying nodes.
        kpi: false
      - name: retransmit_all_write_repl_write
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of retransmits that occurred during write transactions that were being replica written.
          Note this includes retransmits originating on the client as well as proxying nodes.
        kpi: false
      - name: retransmit_all_delete_dup_res
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of retransmits that occurred during delete transactions that were being duplicate resolved.
          Note this includes retransmits originating on the client as well as proxying nodes.
        kpi: false
      - name: retransmit_all_delete_repl_write
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of retransmits that occurred during delete transactions that were being replica written.
          Note this includes retransmits originating on the client as well as proxying nodes.
        kpi: false
      - name: retransmit_all_udf_dup_res
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of retransmits that occurred during client initiated udf transactions that were being duplicate resolved.
          Note this includes retransmits originating on the client as well as proxying nodes.
        kpi: false
      - name: retransmit_all_udf_repl_write
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of retransmits that occurred during client initiated udf transactions that were being replica written.
          Note this includes retransmits originating on the client as well as proxying nodes.
        kpi: false
      - name: retransmit_all_sub_dup_res
        location: Namespace
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of retransmits that occurred during batch sub transactions that were being duplicate resolved.
          Note this includes retransmits originating on the client as well as proxying nodes.
        kpi: false
      - name: retransmit_udf_sub_dup_res
        location: Namespace
        cumulative: true
        introduced: 3.10.1
        description:
          "Number of retransmits that occurred during udf sub transactions
          of scan/query background udf jobs that were being duplicate resolved."
        kpi: false
      - name: retransmit_udf_sub_repl_write
        location: Namespace
        cumulative: true
        introduced: 3.10.1
        description:
          "Number of retransmits that occurred during udf sub transactions
          of scan/query background udf jobs that were being replica written."
        kpi: false
      - name: retransmit_nsup_repl_write
        location: Namespace
        cumulative: true
        introduced: 3.10.1
        description:
          "Number of retransmits that occurred during nsup initiated delete
          transactions that were being replica written."
        kpi: false
      - name: scan_aggr_abort
        location: Namespace
        introduced: "3.9"
        cumulative: true
        description: "Number of scan aggregations that were aborted."
        kpi: false
      - name: scan_aggr_complete
        location: Namespace
        introduced: "3.9"
        cumulative: true
        description: "Number of scan aggregations that completed."
        kpi: false
      - name: scan_aggr_error
        location: Namespace
        introduced: "3.9"
        cumulative: true
        description: "Number of scan aggregations that failed."
      - name: scan_basic_abort
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of basic scans that were aborted."
        kpi: false
      - name: scan_basic_complete
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of basic scans that completed."
        kpi: false
      - name: scan_basic_error
        location: Namespace
        introduced: "3.9"
        cumulative: true
        description: "Number of basic scans that failed."
      - name: scan_udf_bg_abort
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of udf background scans that were aborted."
        kpi: false
      - name: scan_udf_bg_complete
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of udf background scans that completed."
        kpi: false
      - name: scan_udf_bg_error
        location: Namespace
        introduced: "3.9"
        cumulative: true
        description: "Number of udf background scans that failed."
      - name: set-deleted-objects
        location: Namespace
        cumulative: true
        removed: "3.9"
        description:
          "Number of records deleted by a set. Renamed to `set_deleted_objects`
          as of version 3.9."
        kpi: false
      - name: set_deleted_objects
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: "Number of records deleted by a set."
        kpi: false
      - name: set-evicted-objects
        location: Namespace
        cumulative: true
        removed: "Yes"
        description: "Number of records evicted by a set."
        kpi: false
      - name: sindex-used-bytes-memory
        location: Namespace
        cumulative: false
        removed: "3.9"
        description: |
          Amount of memory occupied by secondary indexes for this namespace on this
          node. Replaced with `memory_used_sindex_bytes` as of version 3.9.
        kpi: false
      - name: stop-writes
        location: Namespace
        cumulative: false
        removed: "3.9"
        description:
          "If true this namespace is currently not allowing writes. Replaced
          with `stop_writes` as of version 3.9."
        kpi: false
        category: Storage
        usage: |
          **IF** `stop-writes` is true **THEN** critical alert to operations, system
          has entered stop-writes mode, until cause is reverted system will reject
          all writes from the Application.
      - name: stop_writes
        location: Namespace
        cumulative: false
        introduced: "3.9"
        description: |
          If true this namespace is currently not allowing writes. Error code 22 will be returned. Note that migration writes as well as
          prole writes will still be allowed. Only client originated writes will be denied. This will happen if either one of the following is
          breached: [`min-avail-pct`](/docs/reference/configuration#min-avail-pct), [`stop-writes-pct`](/docs/reference/configuration/#stop-writes-pct) or
          [`xdr-min-digestlog-free-pct`](/docs/reference/configuration/#xdr-min-digestlog-free-pct).
        kpi: true
        category: Storage
        usage: |
          **IF** [`stop_writes`](/docs/reference/metrics/#stop_writes) is true **THEN** critical alert to operations, system
          has entered stop-writes mode, until cause is reverted system will reject
          all writes from the Application.
      - name: sub_objects
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description:
          "Number of LDT sub objects. Also aggregated at the service statistic
          level under the same name."
        kpi: false
      - name: tombstones
        location: Namespace
        ee-only: true
        cumulative: false
        introduced: "3.10"
        description: "Total number tombstones in this namespace on this node."
        kpi: false
      - name: total-bytes-disk
        location: Namespace
        cumulative: false
        removed: "3.9"
        description: |
          Total bytes of disk space allocated to this namespace on this node.
          Refer to the `device_total_bytes` stat as of 3.9.
        kpi: false
      - name: total-bytes-memory
        location: Namespace
        cumulative: false
        removed: "3.9"
        description: |
          Total bytes of memory allocated to this namespace on this node.
          Refer to the `memory-size` configuration parameter.
        kpi: false
      - name: truncate_lut
        location: Namespace
        cumulative: false
        introduced: "3.12"
        description:
          'The "most covering" truncate_lut for this namespace. See [truncate](/docs/reference/info/index.html#truncate)
          or [truncate-namespace](/docs/reference/info/index.html#truncate-namespace).'
        kpi: false
      - name: truncated_records
        location: Namespace
        cumulative: true
        introduced: "3.12"
        description: |
          The total number of records deleted by truncation for this namespace (includes set truncations).
          See [truncate](/docs/reference/info/index.html#truncate) or [truncate-namespace](/docs/reference/info/index.html#truncate-namespace).
        kpi: false
      - name: udf_sub_lang_delete_success
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: |
          Number of successful udf delete sub-transactions (for scan/query background udf jobs).
          Refer to the `udf_sub_udf_*` statistics for the containing udf operation statuses.
        kpi: false
      - name: udf_sub_lang_error
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: |
          Number of udf sub-transactions errors (for scan/query background udf jobs).
          Refer to the `udf_sub_udf_*` statistics for the containing udf operation statuses.
        kpi: false
      - name: udf_sub_lang_read_success
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: |
          Number of successful udf read sub-transactions (for scan/query background udf jobs).
          Refer to the `udf_sub_udf_*` statistics for the containing udf operation statuses.
        kpi: false
      - name: udf_sub_lang_write_success
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: |
          Number of successful udf write sub-transactions (for scan/query background udf jobs).
          Refer to the `udf_sub_udf_*` statistics for the containing udf operation statuses.
        kpi: false
      - name: udf_sub_tsvc_error
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description:
          "Number of udf sub transactions that failed with an error in the
          transaction service,\nbefore attempting to handle the transaction (for scan/query
          background udf jobs).\nFor example protocol errors or security permission mismatch.
          Does not include\ntimeouts on the transaction queue. \nIn [`strong-consistency`](/docs/reference/configuration/#strong-consistency)
          enabled namespaces, this will \ninclude transactions against [`unavailable_partitions`](/docs/reference/metrics/?show-removed=1#unavailable_partitions)
          and \n[`dead_partitions`](/docs/reference/metrics/?show-removed=1#dead_partitions).\n"
        kpi: false
      - name: udf_sub_tsvc_timeout
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: |
          Number of udf sub transactions that timed out in the transaction service,
          before attempting to handle the transaction (for scan/query background udf jobs).
        kpi: false
      - name: udf_sub_udf_complete
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: |
          Number of completed udf sub-transactions (for scan/query background udf jobs).
          Refer to the `udf_sub_lang_*` statistics for the underlying operation statuses.
        kpi: false
      - name: udf_sub_udf_error
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: |
          Number of failed udf sub-transactions (for scan/query background udf jobs).
          Does not include timeouts.
          Refer to the `udf_sub_lang_*` statistics for the underlying operation statuses.
        kpi: false
      - name: udf_sub_udf_timeout
        location: Namespace
        cumulative: true
        introduced: "3.9"
        description: |
          Number of udf sub-transactions that timed out (for scan/query background udf jobs).
          Refer to the `udf_sub_lang_*` statistics for the underlying operation statuses.
        kpi: false
      - name: unavailable_partitions
        location: Namespace
        ee-only: true
        cumulative: false
        introduced: "4.0"
        description: |
          Number of unavailable partitions for this namespace (when using [`strong-consistency`](/docs/reference/configuration#strong-consistency)).
          This is the number of partitions that are unavailable when roster nodes are missing. Will turn into
          [`dead_partitions`](/docs/reference/metrics#dead_partitions) if still unavailable when all roster nodes are present.
        category: Service
        kpi: true
        usage:
          "**IF** [`unavailable_partitions`](/docs/reference/metrics/#unavailable_partitions)
          non 0 **THEN** critical alert to operations. \nCheck for network issues and
          make sure cluster forms properly.\n"
        extra-note:
          "Some partitions would typically be unvailable under some cluster
          split situations or when removing more than \n[`replication-factor`](/docs/reference/configuration/#replication-factor)
          number of nodes from a \n[`strong-consistency`](/docs/reference/configuration#strong-consistency)
          enabled namespace. \nRefer to the [Configuring Strong Consistency](/docs/operations/configure/consistency/index.html)
          and\n[Consistency Management](/docs/operations/manage/consistency/index.html)
          pages for further details.\n"
      - name: used-bytes-disk
        location: Namespace
        cumulative: false
        removed: "3.9"
        description:
          "Total bytes of disk space used by this namespace on this node. Replaced
          with `device_used_bytes` as of version 3.9."
        kpi: false
        category: Trend
        usage: |
          Trending `used-bytes-disk` provides operations insight into how disk usage
          changes over time for this namespace.
      - name: used-bytes-memory
        location: Namespace
        cumulative: false
        removed: "3.9"
        description:
          "Total bytes of memory used by this namespace on this node. Replaced
          with `memory_used_bytes` as of 3.9."
        kpi: false
        category: Trend
        usage: |
          Trending `used-bytes-memory` provides operations insight into how memory
          usage changes over time for this namespace.
      - name: write-smoothing-period
        location: Namespace
        cumulative: false
        removed: "Yes"
        description: "Removed"
        kpi: false
      - name: xdr_write_error
        location: Namespace
        ee-only: true
        cumulative: true
        introduced: "3.9"
        removed: 4.5.1
        description: |
          Number of write requests initiated by XDR that failed on the namespace on this node.
          For the total number of XDR initiated write requests against
          this namespace on this node (destination node), sum up the `xdr_write_success`,
          `xdr_write_timeout` and `xdr_write_error` statistics.
          Replaced with `xdr_client_write_error` as of version 4.5.1.
        kpi: false
      - name: xdr_client_write_error
        location: Namespace
        ee-only: true
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of write requests initiated by XDR that failed on the namespace on this node.
          For the total number of XDR initiated write requests against
          this namespace on this node (destination node), add up the relevant XDR client and from_proxy statistics:
          `xdr_client_write_success`, `xdr_client_write_error`, `xdr_client_write_timeout`,
          `xdr_from_proxy_write_success`, `xdr_from_proxy_write_error`, `xdr_from_proxy_write_timeout`.
        kpi: false
      - name: xdr_write_success
        location: Namespace
        ee-only: true
        cumulative: true
        introduced: "3.9"
        removed: 4.5.1
        description: |
          Number of write requests initiated by XDR that succeeded on the namespace on this node.
          For the total number of XDR initiated write requests against
          this namespace on this node (destination node), sum up the `xdr_write_success`,
          `xdr_write_timeout` and `xdr_write_error` statistics.
          Replaced with `xdr_client_write_success` as of version 4.5.1.
        kpi: false
      - name: xdr_client_write_success
        location: Namespace
        ee-only: true
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of write requests initiated by XDR that succeeded on the namespace on this node.
          For the total number of XDR initiated write requests against
          this namespace on this node (destination node), add up the relevant XDR client and from_proxy statistics:
          `xdr_client_write_success`, `xdr_client_write_error`, `xdr_client_write_timeout`,
          `xdr_from_proxy_write_success`, `xdr_from_proxy_write_error`, `xdr_from_proxy_write_timeout`.
        kpi: false
      - name: xdr_write_timeout
        location: Namespace
        ee-only: true
        cumulative: true
        introduced: "3.9"
        removed: 4.5.1
        description: |
          Number of write requests initiated by XDR that timed out on the namespace on this node.
          For the total number of XDR initiated write requests against
          this namespace on this node (destination node), sum up the `xdr_write_success`,
          `xdr_write_timeout` and `xdr_write_error` statistics.
          Replaced with `xdr_client_write_timeout` as of version 4.5.1.
        kpi: false
      - name: xdr_client_write_timeout
        location: Namespace
        ee-only: true
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of write requests initiated by XDR that timed out on the namespace on this node.
          For the total number of XDR initiated write requests against
          this namespace on this node (destination node), add up the relevant XDR client and from_proxy statistics:
          `xdr_client_write_success`, `xdr_client_write_error`, `xdr_client_write_timeout`,
          `xdr_from_proxy_write_success`, `xdr_from_proxy_write_error`, `xdr_from_proxy_write_timeout`.
        kpi: false
      - name: xdr_client_delete_error
        location: Namespace
        ee-only: true
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of delete requests initiated by XDR that failed on the namespace on this node.
          For the total number of XDR initiated delete requests against
          this namespace on this node (destination node), add up the relevant XDR client and from_proxy statistics:
          `xdr_client_delete_success`, `xdr_client_delete_error`, `xdr_client_delete_timeout`, `xdr_client_delete_not_found`,
          `xdr_from_proxy_delete_success`, `xdr_from_proxy_delete_error`, `xdr_from_proxy_delete_timeout`,
          `xdr_from_proxy_delete_not_found`.
        kpi: false
      - name: xdr_client_delete_not_found
        location: Namespace
        ee-only: true
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of delete requests initiated by XDR that failed on the namespace on this node due to the
          record not being found.
          For the total number of XDR initiated delete requests against
          this namespace on this node (destination node), add up the relevant XDR client and from_proxy statistics:
          `xdr_client_delete_success`, `xdr_client_delete_error`, `xdr_client_delete_timeout`, `xdr_client_delete_not_found`,
          `xdr_from_proxy_delete_success`, `xdr_from_proxy_delete_error`, `xdr_from_proxy_delete_timeout`,
          `xdr_from_proxy_delete_not_found`.
        kpi: false
      - name: xdr_client_delete_success
        location: Namespace
        ee-only: true
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of delete requests initiated by XDR that succeeded on the namespace on this node.
          For the total number of XDR initiated delete requests against
          this namespace on this node (destination node), add up the relevant XDR client and from_proxy statistics:
          `xdr_client_delete_success`, `xdr_client_delete_error`, `xdr_client_delete_timeout`, `xdr_client_delete_not_found`,
          `xdr_from_proxy_delete_success`, `xdr_from_proxy_delete_error`, `xdr_from_proxy_delete_timeout`,
          `xdr_from_proxy_delete_not_found`.
        kpi: false
      - name: xdr_client_delete_timeout
        location: Namespace
        ee-only: true
        cumulative: true
        introduced: 4.5.1
        description: |
          Number of delete requests initiated by XDR that timed out on the namespace on this node.
          For the total number of XDR initiated delete requests against
          this namespace on this node (destination node), add up the relevant XDR client and from_proxy statistics:
          `xdr_client_delete_success`, `xdr_client_delete_error`, `xdr_client_delete_timeout`, `xdr_client_delete_not_found`,
          `xdr_from_proxy_delete_success`, `xdr_from_proxy_delete_error`, `xdr_from_proxy_delete_timeout`,
          `xdr_from_proxy_delete_not_found`.
        kpi: false
  - location: Sets
    metrics:
      - name: memory_data_bytes
        location: Sets
        cumulative: false
        introduced: "3.9"
        description: |
          Memory used by this set in bytes, for the data part (does not include index part).
          Value will be 0 if data is not stored in memory. Refer to the set level
          [object size histogram](/docs/reference/info#hist-dump) for size used on disk.
        kpi: false
      - name: ns
        location: Sets
        cumulative: false
        description: "Namespace name this set belongs to."
        kpi: false
      - name: n_objects
        location: Sets
        cumulative: false
        removed: "3.9"
        description:
          "Total number of objects (master and all replicas) in this set on
          this node."
        kpi: false
      - name: n_bytes-memory
        location: Sets
        cumulative: false
        removed: "3.9"
        description: "Memory used by this set, in bytes."
        kpi: false
      - name: objects
        location: Sets
        cumulative: false
        introduced: "3.9"
        description:
          "Total number of objects (master and all replicas) in this set on
          this node."
        kpi: false
      - name: set-delete
        location: Sets
        cumulative: false
        removed: 3.14.0
        description: |
          If enabled nsup will remove all records in this set on its next run and
          continue to do so on subsequent run until there is nothing further to
          delete, after which this value will return to false.
        kpi: false
      - name: set
        location: Sets
        cumulative: false
        description: "The name of this set."
        kpi: false
      - name: tombstones
        location: Sets
        ee-only: true
        cumulative: false
        introduced: "3.10"
        description:
          "Total number of tombstones (master and all replicas) in this set
          on this node."
        kpi: false
      - name: truncate_lut
        location: Sets
        cumulative: false
        introduced: "3.12"
        description:
          'The "most covering" truncate_lut for this set. See [truncate](/docs/reference/info/index.html#truncate)
          or [truncate-namespace](/docs/reference/info/index.html#truncate-namespace).'
        kpi: false
  - location: Bins
    metrics:
      - name: bin_names
        location: Bins
        cumulative: false
        introduced: "3.9"
        description: "Number of bin names used for the namespace."
        kpi: false
      - name: bin_names_quota
        location: Bins
        cumulative: false
        introduced: "3.9"
        description: |
          Quota of bin names for the namespace (32,768). See `available_bin_names` for the number of available
          bin names remaining for the namespace (`bin_names_quota` - `bin_names`).
        kpi: false
      - name: bin-names-quota
        location: Bins
        cumulative: false
        removed: "3.9"
        description:
          "Quota of bin names for the namespace (32,768). Replaced by `bin_names_quota`
          as of version 3.9."
        kpi: false
      - name: num-bin-names
        location: Bins
        cumulative: false
        removed: "3.9"
        description:
          "Number of bin names used for the namespace. Replaced by `bin_names`
          as of version 3.9."
        kpi: false
  - location: Sindex
    metrics:
      - name: delete_error
        location: Sindex
        cumulative: true
        introduced: "3.9"
        description:
          "Number of errors while processing a delete transaction for this
          secondary index."
        kpi: false
      - name: delete_success
        location: Sindex
        cumulative: true
        introduced: "3.9"
        description:
          "Number of successful delete transactions processed for this secondary
          index."
        kpi: false
      - name: entries
        location: Sindex
        cumulative: false
        description: |
          Number of secondary index entries for this secondary index. This is the number of
          records that have been indexed by this secondary index.
        kpi: false
      - name: ibtr_memory_used
        location: Sindex
        cumulative: false
        description: |
          Amount of memory, in bytes, the secondary index is consuming for the keys, as opposed to `nbtr_memory_used` which
          is the amount of memory the secondary index is consuming for the entries. The total being reported by
          `si_accounted_memory`.
        kpi: false
      - name: keys
        location: Sindex
        cumulative: false
        description: "Number of secondary keys for this secondary index."
        kpi: false
      - name: load_pct
        location: Sindex
        cumulative: false
        description: "Progress in percentage of the creation of secondary index."
        kpi: false
      - name: loadtime
        location: Sindex
        cumulative: false
        description: "Time it took for the secondary index to be fully created."
        kpi: false
      - name: nbtr_memory_used
        location: Sindex
        cumulative: false
        description: |
          Amount of memory, in  bytes, the secondary index is consuming for the entries, as opposed to `ibtr_memory_used` which
          is the amount of memory the secondary index is consuming for the keys. The total being reported by
          `si_accounted_memory`.
        kpi: false
      - name: query_agg
        location: Sindex
        cumulative: true
        description:
          "Number of query aggregations attempted for this secondary index
          on this node."
        kpi: false
      - name: query_agg_avg_rec_count
        location: Sindex
        cumulative: false
        description:
          "Average number of records returned by the aggregations underlying
          queries against this secondary index."
        kpi: false
      - name: query_agg_avg_record_size
        location: Sindex
        cumulative: false
        description:
          "Average size of the records returned by the aggregations underlying
          queries against this secondary index."
        kpi: false
      - name: query_avg_rec_count
        location: Sindex
        cumulative: false
        description: |
          Average number of records returned by the all queries against this secondary index (combines
          `query_agg_avg_rec_count` and `query_lookup_avg_rec_count`).
        kpi: false
      - name: query_avg_record_size
        location: Sindex
        cumulative: false
        description: |
          Average size of the records returned by all the queries against this secondary index (combines
            `query_agg_avg_record_size` and `query_lookup_avg_record_size`)
        kpi: false
      - name: query_lookup_avg_rec_count
        location: Sindex
        cumulative: false
        description:
          "Average number of records returned by the lookup queries against
          this secondary index."
        kpi: false
      - name: query_lookup_avg_record_size
        location: Sindex
        cumulative: false
        description:
          "Average size of the records returned by the lookup queries against
          this secondary index."
        kpi: false
      - name: query_lookups
        location: Sindex
        cumulative: true
        description:
          "Number of lookup queries ever attempted for this secondary index
          on this node."
        kpi: false
      - name: query_reqs
        location: Sindex
        cumulative: true
        description: |
          Number of query requests ever attempted for this secondary index on this node (combines
            `query_lookups` and `query_agg`).
        kpi: false
      - name: si_accounted_memory
        location: Sindex
        cumulative: false
        description:
          "Amount of memory, in bytes, the secondary index is consuming. This
          is the sum of `ibtr_memory_used` and `nbtr_memory_used`."
        kpi: false
      - name: stat_delete_errs
        location: Sindex
        cumulative: true
        removed: "3.9"
        description: |
          Number of errors while processing a delete transaction for this secondary index.
          Replaced by `delete_error` as of version 3.9.
        kpi: false
      - name: stat_delete_reqs
        location: Sindex
        cumulative: true
        removed: "3.9"
        description: |
          Number of attempts to process delete transactions for this secondary index.
          Refer to `delete_success` and `delete_error` stats as of version 3.9.
        kpi: false
      - name: stat_delete_success
        location: Sindex
        cumulative: true
        removed: "3.9"
        description: |
          Number of successful delete transactions processed for this secondary index.
          Replaced by `delete_success` as of version 3.9.
        kpi: false
      - name: stat_gc_recs
        location: Sindex
        cumulative: true
        description: |
          Number of records that have been garbage collected out of the secondary index memory.
          Refer to `si-gc-period` and `si-gc-max-units` configuration parameters for tuning the
          secondary index garbage collection.
        kpi: false
      - name: stat_gc_time
        location: Sindex
        cumulative: true
        description: |
          Amount of time spent processing garbage collection for the secondary index.
          Refer to `si-gc-period` and `si-gc-max-units` configuration parameters for tuning the
          secondary index garbage collection.
        kpi: false
      - name: stat_write_errs
        location: Sindex
        cumulative: true
        removed: "3.9"
        description: |
          Number of errors while processing a write transaction for this secondary index.
          Replaced by `write_error` as of version 3.9.
        kpi: false
      - name: stat_write_reqs
        location: Sindex
        cumulative: true
        removed: "3.9"
        description: |
          Number of attempts to process write transactions for this secondary index.
          Refer to `write_success` and `write_error` stats as of version 3.9.
        kpi: false
      - name: stat_write_success
        location: Sindex
        cumulative: true
        removed: "3.9"
        description: |
          Number of successful write transactions processed for this secondary index.
          Replaced by `write_success` as of version 3.9.
        kpi: false
      - name: write_error
        location: Sindex
        cumulative: true
        introduced: "3.9"
        description:
          "Number of errors while processing a write transaction for this secondary
          index."
        kpi: false
      - name: write_success
        location: Sindex
        cumulative: true
        introduced: "3.9"
        description:
          "Number of successful write transactions processed for this secondary
          index."
        kpi: false
  - location: XDR
    metrics:
      - name: cur_throughput
        location: XDR
        ee-only: true
        cumulative: false
        description:
          "Records per second throughput XDR is currently able to ship. Replaced
          by `xdr_throughput` as of version 3.9."
        introduced: 3.2.7
        removed: "3.9"
        kpi: false
        category: Network
        usage: |
          **IF** `cur_throughput` drops below expected XDR throughput **THEN**
          alert operations, may indicate a problem with inter-cluster connectivity.
      - name: dlog_free_pct
        location: XDR
        ee-only: true
        cumulative: false
        description: "Percentage of the digest log free and available for use."
        introduced: "3.9"
        kpi: false
      - name: dlog_logged
        location: XDR
        ee-only: true
        cumulative: true
        description: "Number of records logged into digest log."
        introduced: "3.9"
        kpi: false
        category: Trend
        usage: |
          Trending `stat_recs_logged` allows operations insight into how many
          records are being enqueued for shipment over time.
      - name: dlog_overwritten_error
        location: XDR
        ee-only: true
        cumulative: true
        description: "Number of digest log entries that got overwritten."
        introduced: "3.9"
        kpi: false
      - name: dlog_processed_linkdown
        location: XDR
        ee-only: true
        cumulative: true
        description: "Number of linkdown that were processed."
        introduced: "3.9"
        kpi: false
      - name: dlog_processed_main
        location: XDR
        ee-only: true
        cumulative: true
        description: "Number of records processed on the local Aerospike server."
        introduced: "3.9"
        kpi: false
      - name: dlog_processed_replica
        location: XDR
        ee-only: true
        cumulative: true
        description: |
          Number of records processed for a node in the cluster that is not the
          local node.
        introduced: "3.9"
        kpi: false
      - name: dlog_relogged
        location: XDR
        ee-only: true
        cumulative: true
        description: |
          Number of records relogged by this node into the digest log due to temporary
          issues when attempting to ship.
          A relogged digest log entry would be caused by one of three potential conditions:
          - An issue with the local client when attempting to ship (tracked by [`xdr_ship_source_error`](/docs/reference/metrics#xdr_ship_source_error)).
          - An issue with the network or the destination cluster itself (tracked by [`xdr_ship_destination_error`](/docs/reference/metrics#xdr_ship_destination_error)).
          - An issue when reading the record on the local node(tracked by [`xdr_read_error`](/docs/reference/metrics#xdr_read_error)), but those would actually
          end up relogged on the node now owning the record (see [`xdr_relogged_outgoing`](/docs/reference/metrics#xdr_relogged_outgoing)).
        detail: |
          The XDR component typically processes only master record's digest log entries on a given node (the exception being during failed node processing,
          when a node on the source cluster has failed). When relogging such master record's dlog entry, the corresponding prole copy would also be relogged
          on the respective node holding the replicas. This would increment the [`xdr_relogged_outgoing`](/docs/reference/metrics#xdr_relogged_outgoing) statistic
          on the current node and the [`xdr_relogged_incoming`](/docs/reference/metrics#xdr_relogged_incoming) on the receiving node. It is therefore expected
          to see the `dlog_relogged` and [`xdr_relogged_outgoing`](/docs/reference/metrics#xdr_relogged_outgoing) statistics matching for clusters that are stable (no migrations).<br><br>
          The relogs happening due to master partition ownership changes (migrations) are also tracked through [`xdr_relogged_incoming`](/docs/reference/metrics#xdr_relogged_incoming)
          and [`xdr_relogged_outgoing`](/docs/reference/metrics#xdr_relogged_outgoing).<br><br>
          Permanent errors will not be relogged but will have a WARNING log message at the destination cluster (for example, to name a few, invalid namespace, record too big if mismatched
          write-block-size between source and destination, authentication or permission error).<br><br>
          Some Permanent Errors: AEROSPIKE_ERR_RECORD_TOO_BIG, AEROSPIKE_ERR_REQUEST_INVALID, AEROSPIKE_ERR_ALWAYS_FORBIDDEN.<br>
          Some Transient Errors: AEROSPIKE_ERR_SERVER, AEROSPIKE_ERR_CLUSTER_CHANGE, AEROSPIKE_ERR_SERVER_FULL, AEROSPIKE_ERR_CLUSTER, 
          AEROSPIKE_ERR_RECORD_BUSY, AEROSPIKE_ERR_DEVICE_OVERLOAD, AEROSPIKE_ERR_FAIL_FORBIDDEN.<br><br>
          Refer to the [C client errors](https://www.aerospike.com/apidocs/c/dc/d42/as__status_8h.html) for the exhaustive list.
        introduced: "3.9"
        kpi: false
      - name: dlog_used_objects
        location: XDR
        ee-only: true
        cumulative: false
        description: "Total number of records slots used in the digest log."
        introduced: "3.9"
        kpi: false
      - name: err_ship_client
        location: XDR
        ee-only: true
        cumulative: true
        removed: "3.9"
        description: |
          Replaced with `xdr_ship_source_error` as of version 3.9.
          Number of client layer errors while shipping records.
          Errors include timeout, bad network fd, etc.
        introduced: 3.2.7
        kpi: false
      - name: err_ship_server
        location: XDR
        ee-only: true
        cumulative: true
        removed: "3.9"
        description: |
          Replaced with `xdr_ship_destination_error` as of version 3.9.
          Number of errors from the remote cluster(s) while shipping records.
          Errors include out-of-space, key-busy, etc.
        introduced: 3.2.7
        kpi: false
      - name: esmt-bytes-shipped
        location: XDR
        ee-only: true
        cumulative: true
        description: |
          Estimated number of bytes XDR has shipped to remote clusters. Renamed to `xdr_ship_bytes`
          as of version 3.9.
        introduced: 3.2.7
        removed: "3.9"
        kpi: false
      - name: esmt-bytes-shipped-compression
        location: XDR
        ee-only: true
        cumulative: true
        description: "Estimated number of bytes shipped in compressed format."
        introduced: 3.2.7
        removed: 3.8.1
        kpi: false
      - name: esmt-ship-compression
        location: XDR
        ee-only: true
        cumulative: true
        description: |
          Estimated compression ratio used to determine how beneficial compression
          is (higher is better). Refer to `xdr_ship_compression_avg_pct` as of version 3.9.
        introduced: 3.2.7
        removed: 3.8.1
        kpi: false
      - name: free-dlog-pct
        location: XDR
        ee-only: true
        cumulative: false
        description:
          "Percentage of the digest log free and available for use. Replaced
          by `dlog_free_pct` as of version 3.9."
        introduced: 3.2.7
        removed: "3.9"
        kpi: false
      - name: latency_avg_dlogread
        location: XDR
        ee-only: true
        cumulative: false
        description: "Moving average latency in milliseconds to read from the digest log."
        introduced: 3.2.7
        removed: "3.9"
        kpi: false
      - name: latency_avg_dlogwrite
        location: XDR
        ee-only: true
        cumulative: false
        description: "Moving average latency in milliseconds to write to the digest log."
        introduced: 3.2.7
        removed: "3.9"
        kpi: false
      - name: latency_avg_ship
        location: XDR
        ee-only: true
        cumulative: false
        removed: "3.9"
        description: |
          Replaced with `xdr_ship_latency_avg` as of version 3.9.
          Moving average latency in milliseconds to ship a record to remote Aerospike
          clusters.
        introduced: 3.2.7
        kpi: false
      - name: local_recs_error
        location: XDR
        ee-only: true
        cumulative: true
        description:
          "Number of records fetched from local Aerospike server. Refer to
          `xdr_read_error` as of version 3.9."
        introduced: 3.2.7
        removed: "3.9"
        kpi: false
      - name: local_recs_fetch_avg_latency
        location: XDR
        ee-only: true
        cumulative: false
        description: |
          Moving average latency in milliseconds to read a record/batch of records from
          local Aerospike server. Refer to `xdr_read_latency_avg` as of version 3.9.
        introduced: 3.2.7
        removed: "3.9"
        kpi: false
      - name: local_recs_fetched
        location: XDR
        ee-only: true
        cumulative: true
        description:
          "Number of records fetched from local Aerospike server. Refer to
          `xdr_read_success` as of version 3.9."
        introduced: 3.2.7
        removed: "3.9"
        kpi: false
      - name: local_recs_migration_retry
        location: XDR
        ee-only: true
        cumulative: true
        description: |
          Number of records missing in a batch call, generally a result of
          migrations, but can also be caused by expiration and eviction.
        introduced: 3.2.7
        kpi: false
      - name: local_recs_notfound
        location: XDR
        ee-only: true
        cumulative: true
        description: |
          Number of record fetch attempts to the local Aerospike server that
          resulted in 'Not Found' response code. Refer to `xdr_read_notfound` as of version 3.9.
        introduced: 3.2.7
        removed: "3.9"
        kpi: false
      - name: noship_recs_expired
        location: XDR
        ee-only: true
        cumulative: true
        description: |
          Number of records not shipped because the record expired before XDR was
          able to ship it.
        introduced: 3.2.7
        removed: "3.9"
        kpi: false
      - name: noship_recs_genmismatch
        location: XDR
        ee-only: true
        cumulative: true
        removed: 3.8.1
        description: |
          Replaced by `noship_recs_hotkey` and `noship_recs_hotkey_timeout` as of 3.8.1. Number of records not shipped to remote Aerospike cluster because of a Generation Mismatch
          between the digestlog and the local Aerospike server (controlled by [xdr-hotkey-maxskip](/docs/reference/configuration/#xdr-hotkey-maxskip)).
        introduced: 3.2.7
        kpi: false
      - name: noship_recs_dup_intrabatch
        location: XDR
        ee-only: true
        cumulative: true
        removed: 3.8.1
        description: |
          Replaced by `noship_recs_hotkey` and `noship_recs_hotkey_timeout` as of 3.8.1. If there are hot keys in the system (same record updated quite frequently), xdr optimizes by not shipping all the updates.
          First level of optimization is to find the duplicate digests in a read batch. This counter indicates how many such skips were done.
          A second level of optimization is done across read batches and can be configured using the [xdr-hotkey-maxskip](/docs/reference/configuration/#xdr-hotkey-maxskip)
          configuration parameter.
        introduced: 3.5.0
        kpi: false
      - name: noship_recs_hotkey
        location: XDR
        ee-only: true
        cumulative: true
        introduced: 3.8.1
        removed: "3.9"
        description: |
          Replaces `noship_recs_dup_intrabatch` and `noship_recs_genmismatch`. Renamed to `xdr_hotkey_skip` as of version 3.9.
          If there are hot keys in the system (same record updated quite frequently), xdr optimizes by not shipping all the updates.
          This stat represents the number of record's digests that are skipped due to an already existing entry in the reader's thread
          cache (meaning a version of this record was just shipped). Should be interpreted in conjunction with
          `noship_recs_hotkey_timeout`. The timeout of the cache entries is controlled by [xdr-hotkey-time-ms](/docs/reference/configuration/#xdr-hotkey-time-ms).
        kpi: false
      - name: noship_recs_hotkey_timeout
        location: XDR
        ee-only: true
        cumulative: true
        introduced: 3.8.1
        removed: 3.8.3
        description: |
          Replaces `noship_recs_dup_intrabatch` and `noship_recs_genmismatch`. Replaced by `hotkeys_fetched` in 3.8.3. If there are hot keys in the system (same record updated quite frequently), xdr optimizes by not shipping all the updates.
          This stat represents the number of record's digest that are actually shipped because their cache entries expired and were dirty. Should be interpreted in conjunction with `noship_recs_hotkey`.
          The timeout of the cache entries is controlled by [xdr-hotkey-time-ms](/docs/reference/configuration/#xdr-hotkey-time-ms).
        kpi: false
      - name: hotkeys_fetched
        location: XDR
        ee-only: true
        cumulative: true
        introduced: 3.8.3
        removed: "3.9"
        description: |
          Should be interpreted in conjunction with `noship_recs_hotkey`. Renamed to `xdr_hotkey_fetch` as of version 3.9.
          Replaces `noship_recs_hotkey_timeout`. If there are hot keys in the system (same record updated quite frequently),
          xdr optimizes by not shipping all the updates. This stat represents the number of record's digest that are actually shipped
          because their cache entries expired and were dirty. Should be interpreted in conjunction with `noship_recs_hotkey`.
          The timeout of the cache entries is controlled by [xdr-hotkey-time-ms](/docs/reference/configuration/#xdr-hotkey-time-ms).
        kpi: false
      - name: noship_recs_notmaster
        location: XDR
        ee-only: true
        cumulative: true
        description: |
          Number of records in the digest log that were not shipped because the
          local node is not the master node for these records.
        introduced: 3.2.7
        removed: "3.9"
        kpi: false
      - name: noship_recs_uninitialized_destination
        location: XDR
        ee-only: true
        cumulative: true
        description: |
          Replaced with `xdr_uninitialized_destination_error` as of version 3.9.
          Number of records in the digest log not shipped because the destination
          cluster has not been initialized.
        removed: "3.9"
        kpi: false
      - name: noship_recs_unknown_namespace
        location: XDR
        ee-only: true
        cumulative: true
        description: |
          Replaced with `xdr_unknown_namespace_error` as of version 3.9.
          Number of records in the digest log not shipped because they belong to an
          unknown namespace (should never happen).
        introduced: 3.2.7
        removed: "3.9"
        kpi: false
      - name: perdc_timediff_lastship_cur_secs
        location: XDR
        ee-only: true
        cumulative: false
        description: |
          Time lag of each remote DC compared to the local cluster represented as a
          comma separated list of values. Replaced by dc_timelag in DC stats as of version 3.8.1.
        introduced: 3.2.7
        removed: 3.8.1
        kpi: false
      - name: stat_dlog_fread
        location: XDR
        ee-only: true
        cumulative: true
        description: "Number of fread calls on digest log."
        introduced: 3.2.7
        removed: "3.9"
        kpi: false
      - name: stat_dlog_fseek
        location: XDR
        ee-only: true
        cumulative: true
        description: "Number of fseek calls on digest log."
        introduced: 3.2.7
        removed: "3.9"
        kpi: false
      - name: stat_dlog_fwrite
        location: XDR
        ee-only: true
        cumulative: true
        description: "Number of fwrite calls on digest log."
        introduced: 3.2.7
        removed: "3.9"
        kpi: false
      - name: stat_dlog_read
        location: XDR
        ee-only: true
        cumulative: true
        description: "Number of logical reads from digest log."
        introduced: 3.2.7
        removed: "3.9"
        kpi: false
      - name: stat_dlog_write
        location: XDR
        ee-only: true
        cumulative: true
        description: "Number of logical writes to the digest log."
        introduced: 3.2.7
        removed: "3.9"
        kpi: false
      - name: stat_pipe_reads_diginfo
        location: XDR
        ee-only: true
        cumulative: true
        description: "Number of digest information read from the named pipe."
        introduced: 3.2.7
        kpi: false
      - name: stat_recs_dropped
        location: XDR
        ee-only: true
        cumulative: true
        description: |
          Number of log records read from named pipe but couldn't be written to
          digest log because the writer's queue is full.
        introduced: 3.2.7
        removed: "3.9"
        kpi: false
      - name: stat_recs_localprocessed
        location: XDR
        ee-only: true
        cumulative: true
        description: |
          Number of records processed on the local Aerospike server. Renamed to
          `dlog_processed_main` as of version 3.9.
        introduced: 3.2.7
        removed: "3.9"
        kpi: false
      - name: stat_recs_logged
        location: XDR
        ee-only: true
        cumulative: true
        description: |
          Number of records logged into digest log. Renamed to `dlog_logged`
          as of version 3.9.
        introduced: 3.2.7
        removed: "3.9"
        kpi: false
        category: Trend
        usage: |
          Trending `stat_recs_logged` allows operations insight into how many
          records are being enqueued for shipment over time.
      - name: stat_recs_outstanding
        location: XDR
        ee-only: true
        cumulative: false
        description: |
          Number of outstanding records not yet processed by the main thread.
          Renamed to `xdr_ship_outstanding_objects` as of version 3.9.
        introduced: 3.2.7
        removed: "3.9"
        kpi: false
      - name: stat_recs_relogged
        location: XDR
        ee-only: true
        cumulative: true
        description: |
          Number of records relogged by this node into the digest log due to temporary
          issues when attempting to ship. Renamed to `dlog_relogged` as of version 3.9.
        introduced: 3.2.7
        removed: "3.9"
        kpi: false
      - name: stat_recs_relogged_incoming
        location: XDR
        ee-only: true
        cumulative: true
        description: |
          Renamed to `xdr_relogged_incoming`. Number of records relogged into this node's digest log by another node. This
          happens during migrations at the source cluster, when there are outstanding
          digests for which the node local node is now owner of their master partition.
        introduced: 3.8.1
        removed: "3.9"
        kpi: false
      - name: stat_recs_relogged_outgoing
        location: XDR
        ee-only: true
        cumulative: true
        description: |
          Renamed to `xdr_relogged_outgoing`. Number of records relogged to another node's digest log. This
          happens during migrations at the source cluster, when there are outstanding
          digests for which the node owning their master partition has changed and is not
          the local node anymore.
        introduced: 3.8.1
        removed: "3.9"
        kpi: false
      - name: stat_recs_replprocessed
        location: XDR
        ee-only: true
        cumulative: true
        description: |
          Number of records processed for a node in the cluster that is not the
          local node. Renamed to `dlog_processed_replica` as of version 3.9.
        introduced: 3.2.7
        removed: "3.9"
        kpi: false
      - name: stat_recs_shipped
        location: XDR
        ee-only: true
        cumulative: true
        removed: "3.9"
        description: |
          Refer to [`xdr_ship_success`](/docs/reference/metrics/#xdr_ship_success), [`xdr_ship_source_error`](/docs/reference/metrics/#xdr_ship_source_error)
          and [`xdr_ship_destination_error`](/docs/reference/metrics/#xdr_ship_destination_error)
          as of version 3.9 for the total number of records attempted to be shipped.
          Number of records shipped to remote Aerospike clusters. Includes errors. See [stat_recs_shipped_ok](/docs/reference/configuration/#stat_recs_shipped_ok)
          for successfully shipped records.
        introduced: 3.2.7
        kpi: false
      - name: stat_recs_shipped_ok
        location: XDR
        ee-only: true
        cumulative: true
        description: |
          Replaced with [`xdr_ship_success`](/docs/reference/metrics/#xdr_ship_success) as of version 3.9.
          Number of records successfully shipped to remote Aerospike clusters.
        introduced: 3.8.3
        removed: "3.9"
        kpi: false
      - name: stat_recs_shipping
        location: XDR
        ee-only: true
        cumulative: false
        description:
          "Number of records XDR is currently shipping to remote Aerospike
          clusters."
        introduced: 3.2.7
        removed: "3.9"
        kpi: false
      - name: stat_recs_shipped_binlevel
        location: XDR
        ee-only: true
        cumulative: false
        description: |
          Refer to `xdr_ship_full_record` as of version 3.9.
          Number of records that took advantage of bin level shipping (see [xdr-ship-bins](/docs/reference/configuration/#xdr-ship-bins)).
        introduced: 3.8.3
        removed: "3.9"
        kpi: false
      - name: timediff_lastship_cur_secs
        location: XDR
        ee-only: true
        cumulative: true
        description: |
          Maximum of time lag of each remote DC. Number of seconds it took since the last shipment was logged to when it
          was finally sent to remote cluster. This is an approximation of latency
          between what has been committed locally to what has been shipped. Replaced
          by xdr_timelag as of version 3.8.1.
        introduced: 3.2.7
        removed: 3.8.1
        kpi: false
      - name: total-recs-dlog
        location: XDR
        ee-only: true
        cumulative: false
        description: |
          Total number of record slots in digest log. Refer to the digest log total allocated size
          in the configuration. Each entry in the digest log occupies 80 bytes.
        introduced: 3.2.7
        removed: "3.9"
        kpi: false
      - name: used-recs-dlog
        location: XDR
        ee-only: true
        cumulative: false
        description: |
          Total number of records slots used in the digest log. Renamed to `dlog_used_objects`
          as of version 3.9.
        introduced: 3.2.7
        removed: "3.9"
        kpi: false
      - name: xdr_deletes_canceled
        location: XDR
        ee-only: true
        cumulative: true
        description: |
          Number of delete operations that were not shipped because the record
          reappeared on the local server.
        introduced: 3.2.7
        removed: "3.9"
        kpi: false
      - name: xdr_deletes_relogged
        location: XDR
        ee-only: true
        cumulative: true
        removed: 3.8.3
        description: "Number of delete operations that were relogged."
        introduced: 3.2.7
        kpi: false
      - name: xdr_deletes_shipped
        location: XDR
        ee-only: true
        cumulative: true
        description: |
          Replaced by `xdr_ship_delete_success` as of version 3.9.
          Number of delete operations that were successfully shipped.
        introduced: 3.2.7
        removed: "3.9"
        kpi: false
      - name: xdr_active_failed_node_sessions
        location: XDR
        ee-only: true
        cumulative: false
        description: |
          Number of active failed node sessions pending. A failed node session keeps track
          of node at the local cluster that have left the cluster and need other
          nodes to ship on their behalf until they join back.
        introduced: "3.9"
        kpi: false
      - name: xdr_active_link_down_sessions
        location: XDR
        ee-only: true
        cumulative: false
        description: |
          Number of active link down sessions pending. A link down session keeps track
          of destination clusters that are not reachable for a given time window.
        introduced: "3.9"
        kpi: false
      - name: xdr_hotkey_skip
        location: XDR
        ee-only: true
        cumulative: true
        introduced: "3.9"
        description: |
          Replaces `noship_recs_dup_intrabatch` and `noship_recs_genmismatch`.
          If there are hot keys in the system (same record updated quite frequently), XDR optimizes by not shipping all the updates.
          This stat represents the number of record's digests that are skipped due to an already existing entry in the reader's thread
          cache (meaning a version of this record was just shipped). Should be interpreted in conjunction with
          `xdr_hotkey_fetch`. The timeout of the cache entries is controlled by [xdr-hotkey-time-ms](/docs/reference/configuration/#xdr-hotkey-time-ms).
        kpi: false
      - name: xdr_global_lastshiptime
        location: XDR
        ee-only: true
        cumulative: false
        introduced: "3.10"
        description: |
          The minimum last ship time in millisecond (epoch) for XDR for across the cluster.
          This is used to know until what point can slots in the digest log be reclaimed,
          by keeping track of the oldest last ship time across all nodes in the cluster.
        kpi: false
      - name: xdr_hotkey_fetch
        location: XDR
        ee-only: true
        cumulative: true
        introduced: "3.9"
        description: |
          If there are hot keys in the system (same record updated quite frequently),
          XDR optimizes by not shipping all the updates. This stat represents the number of record's digest that are actually shipped
          because their cache entries expired and were dirty. Should be interpreted in conjunction with `xdr_hotkey_skip`.
          The timeout of the cache entries is controlled by [xdr-hotkey-time-ms](/docs/reference/configuration/#xdr-hotkey-time-ms).
        kpi: false
      - name: xdr_min_lastshipinfo
        location: XDR
        ee-only: true
        cumulative: false
        introduced: "3.9"
        removed: "3.10"
        description: |
          The minimum last ship time in millisecond (epoch) for XDR for across the cluster.
          This is used to know until what point can slots in the digest log be reclaimed,
          by keeping track of the oldest last ship time across all nodes in the cluster.
          Replaced by [`xdr_global_lastshiptime`](/docs/reference/metrics#xdr_global_lastshiptime) as of version 3.10.
        kpi: false
      - name: xdr_queue_overflow_error
        location: XDR
        ee-only: true
        cumulative: true
        introduced: "3.9"
        description: |
          Number of XDR queue overflow errors. Typically happens when there are no physical space available
          on the storage holding the digest log, or if the writes are happening at such a rate that elements
          are not written fast enough to the digest log. The number of entries this queue can hold is 1 million.
        kpi: false
      - name: xdr_read_active_avg_pct
        location: XDR
        ee-only: true
        cumulative: false
        introduced: "3.9"
        description: |
          This statistics reflects how busy the XDR read threads are by calculating, the average
          time in percent of total time that the XDR read
          threads spend actually processing something vs. waiting for a new
          digest log entry to arrive on their queues from the dlogreader / failed node shippers / window shippers.
        kpi: false
      - name: xdr_read_error
        location: XDR
        ee-only: true
        cumulative: true
        introduced: "3.9"
        description: |
          Number of read requests initiated by XDR that failed. Those are rare, but if present, would
          typically be caused by reservation failures (node lost master and/or prole ownership of the partition
          the record belonged to during migrations). This will cause the record's digest log entry to be
          relogged to the node now owning the partition (tracked under [`xdr_relogged_outgoing`](/docs/reference/metrics#xdr_relogged_outgoing)).
          Other rare cases would be for example when running out of memory or failure to access the storage layer.
          For the total number of XDR initiated read requests, sum up the [`xdr_read_success`](/docs/reference/metrics/#xdr_read_success),
          [`xdr_read_notfound`](/docs/reference/metrics/#xdr_read_notfound) and [`xdr_read_error`](/docs/reference/metrics/#xdr_read_error) statistics.
        kpi: false
      - name: xdr_read_idle_avg_pct
        location: XDR
        ee-only: true
        cumulative: false
        introduced: "3.9"
        description: |
          This is a sister statistic to `xdr_read_active_avg_pct` and represents the average
          time in percent of total time that the XDR read
          threads waits for a new digest log entry to arrive on their queues from the dlogreader
          / failed node shippers / window shippers.
        kpi: false
      - name: xdr_read_latency_avg
        location: XDR
        ee-only: true
        cumulative: false
        description: "Moving average latency in milliseconds for XDR to read a record."
        introduced: "3.9"
        kpi: false
      - name: xdr_read_notfound
        location: XDR
        ee-only: true
        cumulative: true
        introduced: "3.9"
        description: |
          Number of read requests initiated by XDR that were not found. Those do not get relogged. This would typically happen
          if a record is updated and then deleted, but a lag caused the entry to for the record update to be processed after the
          record has been deleted.
          For the total number of XDR initiated read requests, sum up the [`xdr_read_success`](/docs/reference/metrics/#xdr_read_success),
          [`xdr_read_notfound`](/docs/reference/metrics/#xdr_read_notfound) and [`xdr_read_error`](/docs/reference/metrics/#xdr_read_error) statistics.
        kpi: false
      - name: xdr_read_reqq_used
        location: XDR
        ee-only: true
        cumulative: false
        introduced: "3.9"
        description: |
          How many digest log entries are currently in the XDR read threads queues. Each XDR read thread
          has an in-memory queue with a capacity of 1,000 log entries associated with it. See also related
          statistic [`xdr_read_reqq_used_pct`](/docs/reference/metrics/#xdr_read_reqq_used_pct). When the dlogreader / failed node shipper / window shipper
          cannot write to a queue, because the queue is full, it blocks, until there's space in the queue again.
        kpi: false
      - name: xdr_read_reqq_used_pct
        location: XDR
        ee-only: true
        cumulative: false
        introduced: "3.9"
        description: |
          Sister statistic to [`xdr_read_reqq_used`](/docs/reference/metrics/#xdr_read_reqq_used) to
          represent how full in percent the XDR read request queues are.
        kpi: false
      - name: xdr_read_respq_used
        location: XDR
        ee-only: true
        cumulative: false
        introduced: "3.9"
        description: |
          How many entries are being used in the XDR read response queues. Those queues are used to hand back
          records after they have been locally fetched. Those queues are similar to the queues referred to in
          the [`xdr_read_reqq_used`](/docs/reference/metrics/#xdr_read_reqq_used) stat except for the fact that they are not bounded. The throttling would
          happen at the XDR read request queues.
        kpi: false
      - name: xdr_read_success
        location: XDR
        ee-only: true
        cumulative: true
        introduced: "3.9"
        description: |
          Number of read requests initiated by XDR that succeeded.
          For the total number of XDR initiated read requests, sum up the [`xdr_read_success`](/docs/reference/metrics/#xdr_read_success),
          [`xdr_read_notfound`](/docs/reference/metrics/#xdr_read_notfound) and [`xdr_read_error`](/docs/reference/metrics/#xdr_read_error) statistics.
        kpi: false
      - name: xdr_read_txnq_used
        location: XDR
        ee-only: true
        cumulative: false
        introduced: "3.9"
        description: |
          Number of XDR read transactions that are in flight in the local transaction queue. XDR limits
          to 10,000 the number of outstanding XDR read requests in the transaction queue (which is also used
          for regular client transactions). Refer to `xdr_read_txnq_used_pct` for the percent used in this queue.
        kpi: false
      - name: xdr_read_txnq_used_pct
        location: XDR
        ee-only: true
        cumulative: false
        introduced: "3.9"
        description: |
          Percent used of the XDR read transactions that are in flight (out of a maximum allowed of 10,000)
          in the transaction queue (which is also used for regular client transactions).
          Refer to `xdr_read_txnq_used` for the number of XDR issued reads that are in flight.
        kpi: false
      - name: xdr_relogged_incoming
        location: XDR
        ee-only: true
        cumulative: true
        description: |
          Number of records relogged into this node's digest log by another node. This typically
          happens during the following situations:<br>
          - migrations at the source cluster, when there are outstanding
          digest log entries and the partition ownership changes by the time they are processed, if the local node
          does not own master or prole copy of the partition such record belongs to, the node now owning the master copy
          of the partition would get an incoming digest log entry relogged to it.<br>
          - when a node relogs record's digest log entries to itself ([`dlog_relogged`](/docs/reference/metrics#dlog_relogged)),
          it will also relog those for the node owning the prole counterpart.
        introduced: "3.9"
        kpi: false
        detail: |
          The sending node will then have its [`xdr_relogged_outgoing`](/docs/reference/metrics#xdr_relogged_outgoing)
          statistic incremented.
      - name: xdr_relogged_outgoing
        location: XDR
        ee-only: true
        cumulative: true
        description: |
          Number of records relogged to another node's digest log. This typically
          happens during the following situations:<br>
          - migrations at the source cluster, when there are outstanding digest log entries for which the local node
          does not own either master or prole partition for the record anymore ([`xdr_read_error`](/docs/reference/metrics#xdr_read_error))<br>
          - when a node relogs record's digest log entries to itself ([`dlog_relogged`](/docs/reference/metrics#dlog_relogged)),
          it will also relog those for the node owning the prole counterpart.
        introduced: "3.9"
        kpi: false
        detail: |
          The receiving node will then have its [`xdr_relogged_incoming`](/docs/reference/metrics#xdr_relogged_incoming)
          statistic incremented.
      - name: xdr_ship_bytes
        location: XDR
        ee-only: true
        cumulative: true
        description: "Estimated number of bytes XDR has shipped to remote clusters."
        introduced: "3.9"
        kpi: false
      - name: xdr_ship_compression_avg_pct
        location: XDR
        ee-only: true
        cumulative: false
        description: "Used to determine how beneficial compression is (higher is better)."
        introduced: "3.9"
        kpi: false
      - name: xdr_ship_delete_success
        location: XDR
        ee-only: true
        cumulative: true
        description: "Number of delete operations that were successfully shipped."
        introduced: "3.9"
        kpi: false
      - name: xdr_ship_destination_error
        location: XDR
        ee-only: true
        cumulative: true
        introduced: "3.9"
        description:
          "Number of errors from the remote cluster(s) while shipping records.\nErrors
          include out-of-space, key-busy, etc. Those would be typically relogged, except\nin
          case of permanent error (tracked under [`xdr_ship_destination_permanent_error`](/docs/reference/metrics/#xdr_ship_destination_permanent_error)
          \n-- for example records too big or some bad namespace configuration), in\nwhich
          case they will trigger a WARNING log message at the destination. For the total
          number of records XDR\nattempted to ship, sum up [`xdr_ship_success`](/docs/reference/metrics/#xdr_ship_success),\n[`xdr_ship_source_error`](/docs/reference/metrics/#xdr_ship_source_error)\nand
          [`xdr_ship_destination_error`](/docs/reference/metrics/#xdr_ship_destination_error).
          Those\ndo not count errors while attempting to read the record locally, but
          only errors after a record\nto be shipped has been passed to XDR's underlying
          C client. For errors reading records locally,\nrefer to [`xdr_read_error`](/docs/reference/metrics/#xdr_read_error).\n"
        kpi: false
      - name: xdr_ship_destination_permanent_error
        location: XDR
        ee-only: true
        cumulative: true
        introduced: 4.4.0.4
        description:
          "Number of permanent errors from the remote cluster(s) while shipping
          records.\nExample errors include records too big or some bad namespace configuration,\nin
          which case they will trigger a WARNING log message at the destination and will
          not be relogged. Those\ndo not count errors while attempting to read the record
          locally, but only errors after a record\nto be shipped has been passed to XDR's
          underlying C client. For errors reading records locally,        \nrefer to [`xdr_read_error`](/docs/reference/metrics/#xdr_read_error).
          For all errors while shipping to a \ndestination, refer to [`xdr_ship_destination_error`](/docs/reference/metrics/#xdr_ship_destination_error).\n"
        kpi: false
      - name: xdr_ship_full_record
        location: XDR
        ee-only: true
        cumulative: false
        description: |
          Number of records that did not take advantage of bin level shipping
          (see [xdr-ship-bins](/docs/reference/configuration/#xdr-ship-bins)).
        introduced: "3.9"
        kpi: false
      - name: xdr_ship_inflight_objects
        location: XDR
        ee-only: true
        cumulative: false
        description: |
          Number of objects that are inflight (which have been shipped but for which a response from the remote
          DC has not yet been received).
        introduced: "3.9"
        kpi: false
      - name: xdr_ship_latency_avg
        location: XDR
        ee-only: true
        cumulative: false
        introduced: "3.9"
        description: |
          Moving average latency in milliseconds to ship a record to remote Aerospike
          clusters. This is computed by dividing time into 1 second intervals.
        detail: |
          The average is calculated over each 1 second interval separately and then thrown into the exponential moving average.
          The exponential moving average is actually a moving average of independent 1-second averages. This is
          done to avoid having some time intervals where there is a much higher volume of transactions having
          a heavier weight compared to time intervals with much fewer transactions.
        kpi: false
      - name: xdr_ship_outstanding_objects
        location: XDR
        ee-only: true
        cumulative: false
        description: |
          Number of outstanding records not yet processed. This only applies to
          the main thread and will not account for digest log entries pending window shipper
          or failed node processing. It represents the difference between the write pointer
          position and the read pointer position. It also does not account for entries pending
          in the queue prior to being flushed to the digest log, which can go up to 100 entries
          or 500ms if not full by that time (configurable through [`xdr-digestlog-iowait-ms`](/docs/reference/configuration#xdr-digestlog-iowait-ms)).
        introduced: "3.9"
        kpi: false
        category: Trend
        usage: |
          Trending `xdr_ship_outstanding_objects` allows operations insight into how the
          XDR record transmit queue size changes over time.
      - name: xdr_ship_source_error
        location: XDR
        ee-only: true
        cumulative: true
        introduced: "3.9"
        description: |
          Number of client layer errors while shipping records.
          Errors include timeout, bad network fd, etc. For the total number of records XDR
          attempted to ship, sum up [`xdr_ship_success`](/docs/reference/metrics/#xdr_ship_success),
          [`xdr_ship_source_error`](/docs/reference/metrics/#xdr_ship_source_error)
          and [`xdr_ship_destination_error`](/docs/reference/metrics/#xdr_ship_destination_error). Those
          do not count errors while attempting to read the record locally, but only errors after a record
          to be shipped has been passed to XDR's underlying C client. For errors reading records locally,
          refer to [`xdr_read_error`](/docs/reference/metrics/#xdr_read_error).
        kpi: false
      - name: xdr_ship_success
        location: XDR
        ee-only: true
        cumulative: true
        description: |
          Number of records successfully shipped to remote Aerospike clusters (across all datacenters configured,
          meaning one record successfully shipped to 3 different datacenters will increment this counter by 3).
          Includes [`xdr_ship_delete_success`](/docs/reference/metrics/#xdr_ship_delete_success). For the total number of records XDR
          attempted to ship, sum up [`xdr_ship_success`](/docs/reference/metrics/#xdr_ship_success),
          [`xdr_ship_source_error`](/docs/reference/metrics/#xdr_ship_source_error)
          and [`xdr_ship_destination_error`](/docs/reference/metrics/#xdr_ship_destination_error). Those
          do not count errors while attempting to read the record locally, but only errors after a record
          to be shipped has been passed to XDR's underlying C client. For errors reading records locally,
          refer to [`xdr_read_error`](/docs/reference/metrics/#xdr_read_error).
        introduced: "3.9"
        kpi: false
      - name: xdr_timelag
        location: XDR
        ee-only: true
        cumulative: false
        description: |
          The timelag represents the time (in seconds) it took the latest shipped record from the moment
          it was first written at the source until it was attempted to be shipped to the destination cluster (how long
          its digestlog entry waited in the digestlog before being processed). Another way
          of saying this is the difference between the current time and the times stamp of the record which was last
          attempted to be shipped (each record written at the source is time stamped as it get written into the XDR digestlog).
        detail: |
          When having multiple destination DCs, this represents the maximum time lag across all the remote DCs that are not in the
          CLUSTER_INACTIVE or CLUSTER_DOWN states (see [`dc_state`](/docs/reference/metrics/#dc_state)). Under
          normal operations, though, the timelag for each DC that are in the CLUSTER_UP state will be the same, given that XDR ships records in lock-step. The
          timelag at each DC would be different when a DC is in the CLUSTER_DOWN or in the CLUSTER_WINDOW_SHIP state. This does
          not represent the time it will take for XDR to 'catch up', nor does it
          necessarily relate to the number of outstanding digests in the
          digest log still to be processed. For per DC time lag, see [`dc_timelag`](/docs/reference/metrics/#dc_timelag). Replaces
          `timediff_lastship_cur_secs` as of version 3.8.1.
        introduced: 3.8.1
        kpi: true
        category: Service
        usage: |
          **IF** [`xdr_timelag`](/docs/reference/metrics/#xdr_timelag) consistently greater than a few seconds **THEN** may indicate network 
          connectivity issues or errors writing at a destination cluster. The knowledge base article on [XDR throttling](https://discuss.aerospike.com/t/faq-what-can-cause-xdr-throttling/3482) 
          may be helpful.

      - name: xdr_throughput
        location: XDR
        ee-only: true
        cumulative: false
        description: |
          Records per second throughput XDR is currently able to ship. This actually represents the number of
          records written per second across all datacenters configured.
        introduced: "3.9"
        kpi: false
        category: Network
        usage: |
          **IF** `cur_throughput` drops below expected XDR throughput **THEN**
          alert operations, may indicate a problem with inter-cluster connectivity.
      - name: xdr_uninitialized_destination_error
        location: XDR
        ee-only: true
        cumulative: true
        description: |
          Number of records in the digest log not shipped because the destination
          cluster has not been initialized for a DC that is configured for a namespace.
          This should not happen. Those errors are not counted as `xdr_ship_*_error`.
        introduced: "3.9"
        kpi: false
      - name: xdr_unknown_namespace_error
        location: XDR
        ee-only: true
        cumulative: true
        description: |
          Number of records in the digest log not shipped because they belong to an
          unknown namespace, on the source cluster. One situation where this would
          happen is if a namespace is removed (or the order of namespaces is changed
          in the configuration) while there are some entries in the digest log not
          processed yet. This should not happen in most cases. Those errors are not
          counted as `xdr_ship_*_error`.
        introduced: "3.9"
        kpi: false
      - name: xdr_uptime
        location: XDR
        ee-only: true
        cumulative: false
        description: "Time in seconds the XDR process has been running."
        introduced: 3.2.7
        removed: 3.11.1.1
        kpi: false
        category: Service
        usage: |
          Number of seconds XDR has been running. Removed as of 3.11.1.1, use
          the overall uptime metric instead.

          **IF** `xdr-uptime` is below 300 and the cluster is not undergoing
          maintenance
          **THEN** This XDR on this node was restarted within the last 5 minutes.
  - location: XDR - DC
    metrics:
      - name: dc_deletes_shipped
        location: XDR - DC
        ee-only: true
        cumulative: true
        description: |
          Replaced with `dc_ship_delete_success` as of version 3.9.
          Number of delete transactions that have been successfully shipped.
        introduced: 3.8.1
        removed: "3.9"
        kpi: false
      - name: dc_esmt_bytes_shipped
        location: XDR - DC
        ee-only: true
        cumulative: true
        description: |
          Replaced with `xdr_ship_bytes` as of version 3.9.
          Number of bytes shipped for this DC.
        introduced: 3.8.1
        removed: "3.9"
        kpi: false
      - name: dc_esmt_ship_avg_comp_pct
        location: XDR - DC
        ee-only: true
        cumulative: false
        description: "Used to determine how beneficial compression is (higher is better)."
        introduced: 3.8.1
        removed: "3.9"
        kpi: false
      - name: dc_err_ship_client
        location: XDR - DC
        ee-only: true
        cumulative: true
        introduced: 3.8.1
        removed: "3.9"
        description: |
          Replaced with [`dc_ship_source_error`]((/docs/reference/metrics/#dc_ship_source_error)) as of version 3.9.
          Number of client layer errors while shipping records for this DC.
          Errors include timeout, bad network fd, etc.
        kpi: false
      - name: dc_err_ship_server
        location: XDR - DC
        ee-only: true
        cumulative: true
        introduced: 3.8.1
        removed: "3.9"
        description: |
          Replaced with [`dc_ship_destination_error`](/docs/reference/metrics/#dc_ship_destination_error) as of version 3.9.
          Number of errors from the remote cluster(s) while shipping records for this DC.
          Errors include out-of-space, key-busy, etc.
        kpi: false
      - name: dc_latency_avg_ship
        location: XDR - DC
        ee-only: true
        cumulative: false
        description: |
          Replaced with [`dc_ship_latency_avg`](/docs/reference/metrics/#xdr_ship_latency_avg) as of version 3.9.
          Moving average of shipping latency for the specific DC.
        introduced: 3.8.1
        removed: "3.9"
        kpi: false
      - name: dc_open_conn
        location: XDR - DC
        ee-only: true
        cumulative: false
        description: |
          Number of open connection to the DC. If the DC accepts pipeline writes, there will
          be 64 connections per destination node.
          Renamed to [`dc_as_open_conn`](/docs/reference/metrics/#dc_as_open_conn) as of version 4.4.
        introduced: 3.8.1
        removed: "4.4"
        kpi: false
      - name: dc_as_open_conn
        location: XDR - DC
        ee-only: true
        cumulative: false
        description: |
          Number of open connection to the Aerospike DC. If the DC accepts pipeline writes, there will
          be 64 connections per destination node.
          Replaced [`dc_open_conn`](/docs/reference/metrics/?show-removed=1#dc_open_conn) as of version 4.4.
        introduced: "4.4"
        kpi: false
      - name: dc_recs_inflight
        location: XDR - DC
        ee-only: true
        cumulative: false
        description: |
          Replaced with `dc_ship_inflight_objects` as of version 3.9.
          Number of records that are inflight (which have been shipped but for which a response from the remote
          DC has not yet been received).
        introduced: 3.8.1
        removed: "3.9"
        kpi: false
      - name: dc_recs_shipped
        location: XDR - DC
        ee-only: true
        cumulative: true
        description: |
          Replaced with `dc_ship_attempt` as of version 3.9.
          Number of records that have been attempted to be shipped, but could have resulted in either success or error.
        introduced: 3.8.1
        removed: "3.9"
        kpi: false
      - name: dc_recs_shipped_ok
        location: XDR - DC
        ee-only: true
        cumulative: true
        description: |
          Replaced with `dc_ship_success` as of version 3.9.
          Number of records that have been successfully shipped.
        introduced: 3.8.1
        removed: "3.9"
        kpi: false
      - name: dc_remote_ship_avg_sleep
        location: XDR - DC
        ee-only: true
        cumulative: false
        description: |
          Replaced with `dc_ship_idle_avg` as of version 3.9.
          Average number of ms of sleep for each record being shipped. 0.000 if there is no throttling.
          Throttling will occur if the set throughput limit has been reached or in case of unexpected
          slowdown at the destination cluster.
        introduced: 3.8.1
        removed: "3.9"
        kpi: false
        category: Service
      - name: dc_ship_attempt
        location: XDR - DC
        ee-only: true
        cumulative: true
        description: |
          Number of records that have been attempted to be shipped, but could have resulted in either success or error.
          Refer to [`dc_ship_success`](/docs/reference/metrics/#dc_ship_success) for successfully shipped records.
        introduced: "3.9"
        kpi: false
      - name: dc_ship_bytes
        location: XDR - DC
        ee-only: true
        cumulative: true
        description: "Number of bytes shipped for this DC."
        introduced: "3.9"
        kpi: false
      - name: dc_ship_delete_success
        location: XDR - DC
        ee-only: true
        cumulative: true
        description: |
          Number of delete transactions that have been successfully shipped. This is the per DC statistic
          for [`xdr_ship_delete_success`](/docs/reference/metrics/#xdr_ship_delete_success).
        introduced: "3.9"
        kpi: false
      - name: dc_ship_destination_error
        location: XDR - DC
        ee-only: true
        cumulative: true
        introduced: "3.9"
        description: |
          Number of errors from the remote cluster(s) while shipping records for this DC.
          Errors include out-of-space, key-busy, etc. This is the per DC statistic
          for [`xdr_ship_destination_error`](/docs/reference/metrics/#xdr_ship_destination_error).
        kpi: false
      - name: dc_ship_idle_avg
        location: XDR - DC
        ee-only: true
        cumulative: false
        description: |
          Average number of ms of sleep for each record being shipped. 0.000 if there is no throttling.
          Throttling will occur if the set throughput limit (`xdr-max-ship-throughput`) has been reached
          or in case of unexpected slowdown at the destination cluster. This is part of the `rsas` entry
          in the logs (xdr context).
        introduced: "3.9"
        kpi: false
      - name: dc_ship_idle_avg_pct
        location: XDR - DC
        ee-only: true
        cumulative: false
        description: |
          Representation in percent of total time spent for `dc_ship_idle_avg`.
          This is part of the `rsas` entry in the logs (xdr context).
        introduced: "3.9"
        kpi: false
      - name: dc_ship_inflight_objects
        location: XDR - DC
        ee-only: true
        cumulative: false
        description: |
          Number of records that are inflight (which have been shipped but for which a response from the remote
          DC has not yet been received).
        introduced: "3.9"
        kpi: false
      - name: dc_ship_latency_avg
        location: XDR - DC
        ee-only: true
        cumulative: false
        description: "Moving average of shipping latency for the specific DC."
        introduced: "3.9"
        kpi: false
      - name: dc_ship_source_error
        location: XDR - DC
        ee-only: true
        cumulative: true
        introduced: "3.9"
        description: |
          Number of client layer errors while shipping records for this DC.
          Errors include timeout, bad network fd, etc. This is the per DC statistic
          for [`xdr_ship_source_error`](/docs/reference/metrics/#xdr_ship_source_error).
        kpi: false
      - name: dc_ship_success
        location: XDR - DC
        ee-only: true
        cumulative: true
        description: |
          Number of records that have been successfully shipped. This is the per DC statistic
          for [`xdr_ship_success`](/docs/reference/metrics/#xdr_ship_success).
        introduced: "3.9"
        kpi: false
      - name: dc_size
        location: XDR - DC
        ee-only: true
        cumulative: false
        description: |
          The cluster size of the destination DC.
          Renamed to [`dc_as_size`](/docs/reference/metrics/#dc_as_size) as of version 4.4.
        introduced: 3.8.1
        removed: "4.4"
        kpi: false
      - name: dc_as_size
        location: XDR - DC
        ee-only: true
        cumulative: false
        description: |
          The cluster size of the destination Aerospike DC.
          Replaced by [`dc_size`](/docs/reference/metrics/?show-removed=1#dc_size) as of version 4.4.
        introduced: "4.4"
        kpi: false
      - name: dc_state
        location: XDR - DC
        ee-only: true
        cumulative: false
        description: |
          State of the DC. Here are the different statuses: `CLUSTER_INACTIVE`, `CLUSTER_UP`, `CLUSTER_DOWN`, `CLUSTER_WINDOW_SHIP`. <br>
          - The `CLUSTER_INACTIVE` state is for a DC that has not been seeded (configured) in the XDR stanza and would be a place
          holder for a future dynamic seeding. <br>
          - The `CLUSTER_UP` state is the normal state for a DC that is able to receive records from an XDR client and is currently not
          having any records being shipped to it from a previous window where it was down (which would be the `CLUSTER_WINDOW_SHIP` state).<br>
          - A cluster will be in `CLUSTER_DOWN` when the source (XDR client) cannot connect to it for over 30 seconds. This would prevent
          the entries in the digestlog to be reclaimed. The XDR client will periodically try to reconnect and upon succeeding, will spawn a
          window shipper to 'catch up' then entries in the digestlog that were missed. The DC
          specific lag ([dc_timelag](/docs/reference/metrics/#dc_timelag)) will increase in such state but will not be accounted for in the overall XDR timelag
          ([xdr_timelag](/docs/reference/metrics/#xdr_timelag)).<br>
          - A cluster states switches to `CLUSTER_WINDOW_SHIP` when it can be re-connected to after being in `CLUSTER_DOWN` state. The DC
          specific lag ([dc_timelag](/docs/reference/metrics/#dc_timelag)) will be accounted for in the overall XDR timelag
          ([xdr_timelag](/docs/reference/metrics/#xdr_timelag)).
        introduced: 3.8.1
        kpi: false
      - name: dc_timelag
        location: XDR - DC
        ee-only: true
        cumulative: false
        description: |
          Time lag for this specific DC. Replace `perdc_timediff_lastship_cur_secs` as of version 3.8.1. See [xdr_timelag](/docs/reference/metrics/#xdr_timelag)
          for details of how this is calculated.
        introduced: 3.8.1
        kpi: false
      - name: dc_http_locations
        location: XDR - DC
        ee-only: true
        cumulative: false
        description:
          "Number of URLs configured for the HTTP destination. \nPart of the
          [Change Notification Framework](/docs/architecture/change-notification.html).\n"
        introduced: "4.4"
        kpi: false
      - name: dc_http_good_locations
        location: XDR - DC
        ee-only: true
        cumulative: false
        description: |
          Number of URLs that are considered healthy and being used by the change notification system.
          Part of the [Change Notification Framework](/docs/architecture/change-notification.html).
        introduced: "4.4"
        kpi: false
